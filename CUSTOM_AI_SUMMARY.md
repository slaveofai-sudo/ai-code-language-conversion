# ğŸ‰ V2.3 æ–°åŠŸèƒ½ï¼šè‡ªå®šä¹‰AIæ¨¡å‹ç³»ç»Ÿ

## ğŸ“– æ¦‚è¿°

ç°åœ¨æ‚¨å¯ä»¥**æ·»åŠ ä»»ä½•AIæ¨¡å‹**åˆ°å¹³å°ä¸­ï¼Œæ— éœ€ä¿®æ”¹ä»£ç ï¼ç³»ç»Ÿæ”¯æŒå®Œå…¨è‡ªå®šä¹‰çš„AIæ¨¡å‹é…ç½®ï¼Œè®©æ‚¨å¯ä»¥ä½¿ç”¨ä»»ä½•LLMæœåŠ¡ã€‚

---

## âœ¨ æ ¸å¿ƒåŠŸèƒ½

### 1. é›¶ä»£ç æ·»åŠ æ¨¡å‹ â•

é€šè¿‡ç®€å•çš„APIè°ƒç”¨å³å¯æ·»åŠ æ–°çš„AIæ¨¡å‹ï¼š

```bash
curl -X POST http://localhost:8000/api/v1/ai-models \
  -H "Content-Type: application/json" \
  -d '{
    "model_id": "my-llm",
    "model_name": "My LLM",
    "provider": "custom",
    "api_base_url": "https://api.example.com/v1",
    "api_key_env_var": "MY_API_KEY",
    "request_format": "openai"
  }'
```

### 2. æ”¯æŒå¤šç§APIæ ¼å¼ ğŸ”§

- âœ… **OpenAIæ ¼å¼** - GPTã€DeepSeekã€é€šä¹‰åƒé—®ç­‰
- âœ… **Anthropicæ ¼å¼** - Claudeç³»åˆ—
- âœ… **Googleæ ¼å¼** - Geminiç³»åˆ—
- âœ… **å®Œå…¨è‡ªå®šä¹‰æ ¼å¼** - ä»»ä½•å…¶ä»–API

### 3. ä¸€é”®æµ‹è¯• ğŸ§ª

```bash
curl -X POST "http://localhost:8000/api/v1/ai-models/my-llm/test"
```

è¿”å›ï¼š
```json
{
  "success": true,
  "response": "Hello! How can I help?",
  "latency_ms": 234.56
}
```

### 4. é…ç½®åˆ†äº« ğŸ“¤ğŸ“¥

**å¯¼å‡º**ï¼š
```bash
curl -X POST http://localhost:8000/api/v1/ai-models/my-llm/export > config.json
```

**å¯¼å…¥**ï¼š
```bash
curl -X POST http://localhost:8000/api/v1/ai-models/import -d @config.json
```

---

## ğŸŒ æ”¯æŒçš„AIæ¨¡å‹

### å›½å†…AI

| æ¨¡å‹ | æä¾›å•† | é…ç½®éš¾åº¦ |
|------|--------|---------|
| æ™ºè°±AI GLM-4 | æ™ºè°±AI | â­ |
| ç™¾åº¦æ–‡å¿ƒä¸€è¨€ | ç™¾åº¦ | â­â­ |
| é˜¿é‡Œé€šä¹‰åƒé—® | é˜¿é‡Œäº‘ | â­ |
| å­—èŠ‚è±†åŒ… | å­—èŠ‚è·³åŠ¨ | â­ |
| è®¯é£æ˜Ÿç« | ç§‘å¤§è®¯é£ | â­â­ |

### å›½é™…AI

| æ¨¡å‹ | æä¾›å•† | é…ç½®éš¾åº¦ |
|------|--------|---------|
| GPT-4/4o | OpenAI | â­ |
| Claude 3.5 | Anthropic | â­ |
| Gemini Pro | Google | â­ |
| Command R+ | Cohere | â­ |
| Mixtral | Mistral AI | â­ |

### æœ¬åœ°éƒ¨ç½²

| å·¥å…· | è¯´æ˜ | é…ç½®éš¾åº¦ |
|------|------|---------|
| Ollama | æœ€ç®€å•çš„æœ¬åœ°éƒ¨ç½² | â­ |
| vLLM | é«˜æ€§èƒ½æ¨ç† | â­â­â­ |
| LocalAI | OpenAIå…¼å®¹ | â­â­ |
| llama.cpp | è½»é‡çº§ | â­â­ |

---

## ğŸš€ å¿«é€Ÿå¼€å§‹

### ç¤ºä¾‹1: æ·»åŠ Ollamaæœ¬åœ°æ¨¡å‹

```bash
# 1. å¯åŠ¨Ollama (å‡è®¾å·²å®‰è£…)
ollama serve

# 2. æ·»åŠ æ¨¡å‹åˆ°å¹³å°
curl -X POST http://localhost:8000/api/v1/ai-models \
  -H "Content-Type: application/json" \
  -d '{
    "model_id": "ollama-llama3",
    "model_name": "Ollama Llama 3",
    "provider": "ollama",
    "api_base_url": "http://localhost:11434/api",
    "api_key_env_var": "OLLAMA_KEY",
    "request_format": "openai",
    "description": "æœ¬åœ°Llama 3æ¨¡å‹"
  }'

# 3. æµ‹è¯•
curl -X POST "http://localhost:8000/api/v1/ai-models/ollama-llama3/test"

# 4. ä½¿ç”¨
curl -X POST http://localhost:8000/api/v1/convert \
  -d '{
    "source_language": "java",
    "target_language": "python",
    "ai_model": "ollama-llama3"
  }'
```

### ç¤ºä¾‹2: æ·»åŠ æ™ºè°±AI

```bash
# 1. æ·»åŠ æ¨¡å‹
curl -X POST http://localhost:8000/api/v1/ai-models \
  -H "Content-Type: application/json" \
  -d '{
    "model_id": "zhipu-glm-4",
    "model_name": "æ™ºè°±GLM-4",
    "provider": "zhipu",
    "api_base_url": "https://open.bigmodel.cn/api/paas/v4",
    "api_key_env_var": "ZHIPU_API_KEY",
    "request_format": "openai",
    "description": "æ™ºè°±AI GLM-4"
  }'

# 2. è®¾ç½®APIå¯†é’¥
export ZHIPU_API_KEY="your-api-key"

# 3. æµ‹è¯•
curl -X POST "http://localhost:8000/api/v1/ai-models/zhipu-glm-4/test"
```

### ç¤ºä¾‹3: å¤šAIååŒï¼ˆæ··åˆä½¿ç”¨ï¼‰

```bash
curl -X POST http://localhost:8000/api/v1/optimize-code \
  -H "Content-Type: application/json" \
  -d '{
    "file_path": "./app.py",
    "use_multi_ai": true,
    "ai_models": [
      "gpt-4o",              # OpenAIå®˜æ–¹
      "ollama-llama3",        # æœ¬åœ°æ¨¡å‹
      "zhipu-glm-4",          # å›½äº§æ¨¡å‹
      "claude-3.5-sonnet"     # Anthropic
    ],
    "consensus_threshold": 2
  }'
```

---

## ğŸ“Š å®Œæ•´APIåˆ—è¡¨

| ç«¯ç‚¹ | æ–¹æ³• | åŠŸèƒ½ |
|------|------|------|
| `/api/v1/ai-models` | GET | åˆ—å‡ºæ‰€æœ‰æ¨¡å‹ |
| `/api/v1/ai-models` | POST | æ·»åŠ æ–°æ¨¡å‹ |
| `/api/v1/ai-models/{id}` | GET | è·å–æ¨¡å‹è¯¦æƒ… |
| `/api/v1/ai-models/{id}` | PUT | æ›´æ–°æ¨¡å‹é…ç½® |
| `/api/v1/ai-models/{id}` | DELETE | åˆ é™¤æ¨¡å‹ |
| `/api/v1/ai-models/{id}/test` | POST | æµ‹è¯•æ¨¡å‹ |
| `/api/v1/ai-models/{id}/export` | POST | å¯¼å‡ºé…ç½® |
| `/api/v1/ai-models/import` | POST | å¯¼å…¥é…ç½® |

---

## ğŸ¯ ä½¿ç”¨åœºæ™¯

### åœºæ™¯1: æˆæœ¬ä¼˜åŒ– ğŸ’°

```python
# ä½¿ç”¨ä¾¿å®œçš„æœ¬åœ°æ¨¡å‹å¤„ç†ç®€å•ä»»åŠ¡
simple_tasks_model = "ollama-llama3"

# ä½¿ç”¨å¼ºå¤§çš„äº‘ç«¯æ¨¡å‹å¤„ç†å¤æ‚ä»»åŠ¡
complex_tasks_model = "gpt-4o"

# æ ¹æ®ä»»åŠ¡éš¾åº¦åŠ¨æ€é€‰æ‹©
if task_complexity < 5:
    model = simple_tasks_model
else:
    model = complex_tasks_model
```

### åœºæ™¯2: æ•°æ®éšç§ ğŸ”’

```python
# æ•æ„Ÿä»£ç ä½¿ç”¨æœ¬åœ°æ¨¡å‹
if is_sensitive_code:
    model = "ollama-llama3"  # ä¸ç¦»å¼€æœ¬åœ°
else:
    model = "gpt-4o"  # äº‘ç«¯å¤„ç†
```

### åœºæ™¯3: å¤šåŒºåŸŸéƒ¨ç½² ğŸŒ

```python
# å›½å†…ç”¨æˆ·ä½¿ç”¨å›½äº§æ¨¡å‹ï¼ˆæ›´å¿«ï¼‰
if user_region == "CN":
    models = ["zhipu-glm-4", "qwen-coder"]
else:
    models = ["gpt-4o", "claude-3.5-sonnet"]
```

### åœºæ™¯4: A/Bæµ‹è¯• ğŸ§ª

```python
# æµ‹è¯•ä¸åŒæ¨¡å‹çš„æ•ˆæœ
models_to_test = [
    "gpt-4o",
    "claude-3.5-sonnet",
    "my-fine-tuned-model"
]

for model in models_to_test:
    result = convert_code(model=model)
    evaluate_quality(result)
```

---

## ğŸ’¡ é«˜çº§åŠŸèƒ½

### è‡ªå®šä¹‰è¯·æ±‚æ ¼å¼

å¯¹äºéæ ‡å‡†APIï¼Œå¯ä»¥ä½¿ç”¨è‡ªå®šä¹‰æ¨¡æ¿ï¼š

```json
{
  "model_id": "custom-api",
  "request_format": "custom",
  "request_template": {
    "input": {
      "text": "{{prompt}}",
      "config": {
        "model": "{{model}}",
        "max_length": 1000
      }
    }
  },
  "response_path": "output.result.text"
}
```

### è‡ªå®šä¹‰è¯·æ±‚å¤´

```json
{
  "model_id": "enterprise-llm",
  "custom_headers": {
    "X-API-Version": "v2",
    "X-Tenant-ID": "my-company"
  }
}
```

---

## âš™ï¸ é…ç½®æŒä¹…åŒ–

æ‰€æœ‰è‡ªå®šä¹‰æ¨¡å‹é…ç½®è‡ªåŠ¨ä¿å­˜åœ¨ï¼š
```
data/ai_models.json
```

ç³»ç»Ÿå¯åŠ¨æ—¶è‡ªåŠ¨åŠ è½½ï¼Œæ— éœ€æ‰‹åŠ¨é…ç½®ï¼

---

## ğŸ“š å®Œæ•´æ–‡æ¡£

è¯¦ç»†æ–‡æ¡£è¯·æŸ¥çœ‹ï¼š
- **`CUSTOM_AI_MODELS_GUIDE.md`** - å®Œæ•´ä½¿ç”¨æŒ‡å— (8000+å­—)
- **APIæ–‡æ¡£** - http://localhost:8000/docs
- **README.md** - å¿«é€Ÿå¼€å§‹

---

## ğŸ å†…ç½®æ¨¡å‹é…ç½®

ç³»ç»Ÿå†…ç½®ä»¥ä¸‹æ¨¡å‹é…ç½®ï¼ˆå¯ç›´æ¥ä½¿ç”¨ï¼‰ï¼š

1. âœ… **GPT-4o** (OpenAI)
2. âœ… **Claude 3.5 Sonnet** (Anthropic)
3. âœ… **Gemini Pro** (Google)
4. âœ… **DeepSeek Coder** (DeepSeek)

åªéœ€è®¾ç½®ç›¸åº”çš„APIå¯†é’¥å³å¯ä½¿ç”¨ï¼

---

## ğŸ†š å¯¹æ¯”

### ä¹‹å‰ âŒ

```python
# è¦æ·»åŠ æ–°æ¨¡å‹ï¼Œéœ€è¦ï¼š
1. ä¿®æ”¹æºä»£ç 
2. æ·»åŠ æ–°çš„translatorç±»
3. é‡æ–°éƒ¨ç½²
4. åªèƒ½ä½¿ç”¨é¢„å®šä¹‰çš„å‡ ä¸ªæ¨¡å‹
```

### ç°åœ¨ âœ…

```bash
# æ·»åŠ æ–°æ¨¡å‹ï¼Œåªéœ€ï¼š
curl -X POST /api/v1/ai-models -d '{...}'

# 1ç§’é’Ÿå®Œæˆï¼Œç«‹å³å¯ç”¨ï¼
```

---

## ğŸ‰ å¼€å§‹ä½¿ç”¨

```bash
# 1. æŸ¥çœ‹ç°æœ‰æ¨¡å‹
curl http://localhost:8000/api/v1/ai-models

# 2. æ·»åŠ æ‚¨çš„ç¬¬ä¸€ä¸ªè‡ªå®šä¹‰æ¨¡å‹
curl -X POST http://localhost:8000/api/v1/ai-models \
  -H "Content-Type: application/json" \
  -d @my_model_config.json

# 3. æµ‹è¯•æ¨¡å‹
curl -X POST "http://localhost:8000/api/v1/ai-models/my-model/test"

# 4. å¼€å§‹ä½¿ç”¨
curl -X POST http://localhost:8000/api/v1/convert \
  -d '{"ai_model": "my-model", ...}'
```

---

**ğŸš€ ç°åœ¨æ‚¨å¯ä»¥ä½¿ç”¨ä»»ä½•AIæ¨¡å‹äº†ï¼æ— é™å¯èƒ½ï¼**

---

*ğŸ“… åˆ›å»ºæ—¥æœŸ: 2025-10-25*  
*âœ¨ åŠŸèƒ½çŠ¶æ€: âœ… å®Œæ•´å®ç°å¹¶å¯ç”¨*  
*ğŸ“– è¯¦ç»†æ–‡æ¡£: CUSTOM_AI_MODELS_GUIDE.md*

