# ğŸ¤– è‡ªå®šä¹‰AIæ¨¡å‹å®Œå…¨æŒ‡å—

## ğŸ“– ç›®å½•

- [åŠŸèƒ½æ¦‚è¿°](#åŠŸèƒ½æ¦‚è¿°)
- [å¿«é€Ÿå¼€å§‹](#å¿«é€Ÿå¼€å§‹)
- [APIæ¥å£è¯´æ˜](#apiæ¥å£è¯´æ˜)
- [æ”¯æŒçš„è¯·æ±‚æ ¼å¼](#æ”¯æŒçš„è¯·æ±‚æ ¼å¼)
- [æ·»åŠ ç¤ºä¾‹](#æ·»åŠ ç¤ºä¾‹)
- [æµ‹è¯•æ¨¡å‹](#æµ‹è¯•æ¨¡å‹)
- [å¯¼å…¥å¯¼å‡º](#å¯¼å…¥å¯¼å‡º)
- [æœ€ä½³å®è·µ](#æœ€ä½³å®è·µ)
- [å¸¸è§é—®é¢˜](#å¸¸è§é—®é¢˜)

---

## ğŸ¯ åŠŸèƒ½æ¦‚è¿°

**è‡ªå®šä¹‰AIæ¨¡å‹ç³»ç»Ÿ**å…è®¸æ‚¨æ·»åŠ ä»»ä½•AIæ¨¡å‹åˆ°å¹³å°ä¸­ï¼Œæ— éœ€ä¿®æ”¹ä»£ç ï¼

### âœ¨ æ ¸å¿ƒåŠŸèƒ½

| åŠŸèƒ½ | è¯´æ˜ |
|------|------|
| ğŸ†• **æ·»åŠ è‡ªå®šä¹‰æ¨¡å‹** | é€šè¿‡APIæ·»åŠ ä»»ä½•AIæ¨¡å‹ |
| ğŸ”„ **æ›´æ–°æ¨¡å‹é…ç½®** | éšæ—¶ä¿®æ”¹æ¨¡å‹å‚æ•° |
| ğŸ—‘ï¸ **åˆ é™¤æ¨¡å‹** | ç§»é™¤ä¸éœ€è¦çš„è‡ªå®šä¹‰æ¨¡å‹ |
| ğŸ§ª **æµ‹è¯•æ¨¡å‹** | éªŒè¯æ¨¡å‹è¿æ¥å’Œå“åº” |
| ğŸ“¤ **å¯¼å‡ºé…ç½®** | åˆ†äº«æ¨¡å‹é…ç½®ç»™ä»–äºº |
| ğŸ“¥ **å¯¼å…¥é…ç½®** | å¯¼å…¥ä»–äººåˆ†äº«çš„é…ç½® |
| ğŸ“‹ **åˆ—å‡ºæ‰€æœ‰æ¨¡å‹** | æŸ¥çœ‹å†…ç½®å’Œè‡ªå®šä¹‰æ¨¡å‹ |

### ğŸŒŸ ç‰¹è‰²

- âœ… **é›¶ä»£ç é…ç½®**: æ— éœ€ä¿®æ”¹æºä»£ç 
- âœ… **çƒ­åŠ è½½**: æ·»åŠ åç«‹å³å¯ç”¨
- âœ… **æŒä¹…åŒ–**: é…ç½®è‡ªåŠ¨ä¿å­˜
- âœ… **çµæ´»æ€§**: æ”¯æŒå¤šç§APIæ ¼å¼
- âœ… **å®‰å…¨æ€§**: APIå¯†é’¥é€šè¿‡ç¯å¢ƒå˜é‡ç®¡ç†
- âœ… **å¯å…±äº«**: è½»æ¾å¯¼å‡ºå¯¼å…¥é…ç½®

---

## ğŸš€ å¿«é€Ÿå¼€å§‹

### 1. åˆ—å‡ºç°æœ‰æ¨¡å‹

```bash
curl http://localhost:8000/api/v1/ai-models
```

å“åº”ç¤ºä¾‹:
```json
{
  "status": "success",
  "total": 4,
  "models": [
    {
      "model_id": "gpt-4o",
      "model_name": "GPT-4o",
      "provider": "openai",
      "model_type": "chat",
      "description": "OpenAI's GPT-4o model",
      "tags": ["openai", "gpt", "chat"],
      "enabled": true,
      "is_builtin": true
    },
    ...
  ]
}
```

### 2. æ·»åŠ è‡ªå®šä¹‰æ¨¡å‹

```bash
curl -X POST http://localhost:8000/api/v1/ai-models \
  -H "Content-Type: application/json" \
  -d '{
    "model_id": "my-custom-model",
    "model_name": "My Custom AI",
    "provider": "custom",
    "api_base_url": "https://api.example.com/v1",
    "api_key_env_var": "MY_CUSTOM_API_KEY",
    "model_type": "chat",
    "request_format": "openai",
    "description": "My custom AI model",
    "tags": ["custom", "experimental"]
  }'
```

### 3. è®¾ç½®APIå¯†é’¥

```bash
# Linux/Mac
export MY_CUSTOM_API_KEY="your-api-key-here"

# Windows PowerShell
$env:MY_CUSTOM_API_KEY="your-api-key-here"

# æˆ–æ·»åŠ åˆ° .env æ–‡ä»¶
echo "MY_CUSTOM_API_KEY=your-api-key-here" >> .env
```

### 4. æµ‹è¯•æ¨¡å‹

```bash
curl -X POST "http://localhost:8000/api/v1/ai-models/my-custom-model/test?test_prompt=Hello"
```

å“åº”ç¤ºä¾‹:
```json
{
  "status": "success",
  "test_result": {
    "model_id": "my-custom-model",
    "success": true,
    "response": "Hello! How can I help you today?",
    "error": null,
    "latency_ms": 234.56
  }
}
```

### 5. ä½¿ç”¨è‡ªå®šä¹‰æ¨¡å‹

```bash
# åœ¨ä»£ç è½¬æ¢ä¸­ä½¿ç”¨
curl -X POST http://localhost:8000/api/v1/convert \
  -d '{
    "source_code": "...",
    "source_language": "java",
    "target_language": "python",
    "ai_model": "my-custom-model"
  }'

# åœ¨ä»£ç ä¼˜åŒ–ä¸­ä½¿ç”¨
curl -X POST http://localhost:8000/api/v1/optimize-code \
  -d '{
    "file_path": "./app.py",
    "use_multi_ai": true,
    "ai_models": ["gpt-4o", "my-custom-model", "claude-3.5-sonnet"]
  }'
```

---

## ğŸ“¡ APIæ¥å£è¯´æ˜

### GET /api/v1/ai-models

**åˆ—å‡ºæ‰€æœ‰å¯ç”¨çš„AIæ¨¡å‹**

**æŸ¥è¯¢å‚æ•°**:
- `include_builtin` (boolean, default: true) - åŒ…å«å†…ç½®æ¨¡å‹
- `include_custom` (boolean, default: true) - åŒ…å«è‡ªå®šä¹‰æ¨¡å‹
- `enabled_only` (boolean, default: false) - åªè¿”å›å¯ç”¨çš„æ¨¡å‹

**ç¤ºä¾‹**:
```bash
# åªåˆ—å‡ºè‡ªå®šä¹‰æ¨¡å‹
curl "http://localhost:8000/api/v1/ai-models?include_builtin=false"

# åªåˆ—å‡ºå¯ç”¨çš„æ¨¡å‹
curl "http://localhost:8000/api/v1/ai-models?enabled_only=true"
```

### GET /api/v1/ai-models/{model_id}

**è·å–ç‰¹å®šæ¨¡å‹çš„è¯¦ç»†ä¿¡æ¯**

**ç¤ºä¾‹**:
```bash
curl http://localhost:8000/api/v1/ai-models/gpt-4o
```

### POST /api/v1/ai-models

**æ·»åŠ æ–°çš„è‡ªå®šä¹‰AIæ¨¡å‹**

**å¿…éœ€å‚æ•°**:
- `model_id` (string) - å”¯ä¸€æ ‡è¯†ç¬¦
- `model_name` (string) - æ˜¾ç¤ºåç§°
- `provider` (string) - æä¾›å•†åç§°
- `api_base_url` (string) - APIåŸºç¡€URL
- `api_key_env_var` (string) - APIå¯†é’¥ç¯å¢ƒå˜é‡å
- `model_type` (string) - æ¨¡å‹ç±»å‹ (chat/completion/custom)

**å¯é€‰å‚æ•°**:
- `max_tokens` (int, default: 4096) - æœ€å¤§tokenæ•°
- `temperature` (float, default: 0.3) - æ¸©åº¦å‚æ•°
- `top_p` (float, default: 1.0) - Top På‚æ•°
- `custom_headers` (object) - è‡ªå®šä¹‰HTTPè¯·æ±‚å¤´
- `request_format` (string, default: "openai") - è¯·æ±‚æ ¼å¼
- `request_template` (object) - è‡ªå®šä¹‰è¯·æ±‚æ¨¡æ¿
- `response_path` (string) - å“åº”æå–è·¯å¾„
- `description` (string) - æ¨¡å‹æè¿°
- `tags` (array) - æ ‡ç­¾
- `enabled` (boolean, default: true) - æ˜¯å¦å¯ç”¨

### PUT /api/v1/ai-models/{model_id}

**æ›´æ–°è‡ªå®šä¹‰AIæ¨¡å‹é…ç½®**

æ‰€æœ‰å‚æ•°éƒ½æ˜¯å¯é€‰çš„ï¼Œåªæ›´æ–°æä¾›çš„å­—æ®µã€‚

**ç¤ºä¾‹**:
```bash
curl -X PUT http://localhost:8000/api/v1/ai-models/my-custom-model \
  -H "Content-Type: application/json" \
  -d '{
    "temperature": 0.5,
    "description": "Updated description",
    "enabled": true
  }'
```

### DELETE /api/v1/ai-models/{model_id}

**åˆ é™¤è‡ªå®šä¹‰AIæ¨¡å‹**

æ³¨æ„: ä¸èƒ½åˆ é™¤å†…ç½®æ¨¡å‹ã€‚

**ç¤ºä¾‹**:
```bash
curl -X DELETE http://localhost:8000/api/v1/ai-models/my-custom-model
```

### POST /api/v1/ai-models/{model_id}/test

**æµ‹è¯•AIæ¨¡å‹è¿æ¥å’Œå“åº”**

**æŸ¥è¯¢å‚æ•°**:
- `test_prompt` (string, default: "Hello, how are you?") - æµ‹è¯•æç¤ºè¯

**ç¤ºä¾‹**:
```bash
curl -X POST "http://localhost:8000/api/v1/ai-models/my-custom-model/test?test_prompt=Tell%20me%20a%20joke"
```

### POST /api/v1/ai-models/{model_id}/export

**å¯¼å‡ºAIæ¨¡å‹é…ç½®ç”¨äºåˆ†äº«**

**ç¤ºä¾‹**:
```bash
curl -X POST http://localhost:8000/api/v1/ai-models/my-custom-model/export
```

### POST /api/v1/ai-models/import

**å¯¼å…¥AIæ¨¡å‹é…ç½®**

**ç¤ºä¾‹**:
```bash
curl -X POST http://localhost:8000/api/v1/ai-models/import \
  -H "Content-Type: application/json" \
  -d @exported_model.json
```

---

## ğŸ”§ æ”¯æŒçš„è¯·æ±‚æ ¼å¼

### 1. OpenAIæ ¼å¼ (request_format: "openai")

æœ€å¸¸è§çš„æ ¼å¼ï¼Œå…¼å®¹OpenAI APIã€‚

**æ”¯æŒçš„æ¨¡å‹**:
- OpenAI GPTç³»åˆ—
- DeepSeek
- é€šä¹‰åƒé—®
- è®¸å¤šOpenAIå…¼å®¹çš„API

**ç¤ºä¾‹é…ç½®**:
```json
{
  "model_id": "my-openai-compatible-model",
  "model_name": "My OpenAI Compatible Model",
  "provider": "custom",
  "api_base_url": "https://api.example.com/v1",
  "api_key_env_var": "MY_API_KEY",
  "model_type": "chat",
  "request_format": "openai"
}
```

### 2. Anthropicæ ¼å¼ (request_format: "anthropic")

ç”¨äºClaudeç³»åˆ—æ¨¡å‹ã€‚

**ç¤ºä¾‹é…ç½®**:
```json
{
  "model_id": "claude-custom",
  "model_name": "Custom Claude",
  "provider": "anthropic",
  "api_base_url": "https://api.anthropic.com/v1",
  "api_key_env_var": "ANTHROPIC_API_KEY",
  "model_type": "chat",
  "request_format": "anthropic"
}
```

### 3. Googleæ ¼å¼ (request_format: "google")

ç”¨äºGeminiç³»åˆ—æ¨¡å‹ã€‚

**ç¤ºä¾‹é…ç½®**:
```json
{
  "model_id": "gemini-custom",
  "model_name": "Custom Gemini",
  "provider": "google",
  "api_base_url": "https://generativelanguage.googleapis.com/v1",
  "api_key_env_var": "GOOGLE_API_KEY",
  "model_type": "chat",
  "request_format": "google"
}
```

### 4. è‡ªå®šä¹‰æ ¼å¼ (request_format: "custom")

ç”¨äºå®Œå…¨è‡ªå®šä¹‰çš„APIæ ¼å¼ã€‚

**éœ€è¦æä¾›**:
- `request_template`: è¯·æ±‚æ¨¡æ¿
- `response_path`: å“åº”æå–è·¯å¾„

**ç¤ºä¾‹é…ç½®**:
```json
{
  "model_id": "fully-custom-model",
  "model_name": "Fully Custom Model",
  "provider": "custom",
  "api_base_url": "https://api.custom.com/generate",
  "api_key_env_var": "CUSTOM_API_KEY",
  "model_type": "custom",
  "request_format": "custom",
  "request_template": {
    "input": {
      "text": "{{prompt}}",
      "model_name": "{{model}}"
    },
    "parameters": {
      "max_length": 1000
    }
  },
  "response_path": "output.generated_text"
}
```

---

## ğŸ“ æ·»åŠ ç¤ºä¾‹

### ç¤ºä¾‹1: æ·»åŠ Ollamaæœ¬åœ°æ¨¡å‹

```bash
curl -X POST http://localhost:8000/api/v1/ai-models \
  -H "Content-Type: application/json" \
  -d '{
    "model_id": "ollama-llama3",
    "model_name": "Ollama Llama 3",
    "provider": "ollama",
    "api_base_url": "http://localhost:11434/api",
    "api_key_env_var": "OLLAMA_API_KEY",
    "model_type": "chat",
    "request_format": "openai",
    "description": "æœ¬åœ°Ollamaè¿è¡Œçš„Llama 3æ¨¡å‹",
    "tags": ["local", "ollama", "llama"],
    "max_tokens": 2048
  }'

# Ollamaé€šå¸¸ä¸éœ€è¦APIå¯†é’¥ï¼Œè®¾ç½®ä¸€ä¸ªè™šæ‹Ÿå€¼å³å¯
export OLLAMA_API_KEY="not-needed"
```

### ç¤ºä¾‹2: æ·»åŠ Azure OpenAI

```bash
curl -X POST http://localhost:8000/api/v1/ai-models \
  -H "Content-Type: application/json" \
  -d '{
    "model_id": "azure-gpt-4",
    "model_name": "Azure GPT-4",
    "provider": "azure",
    "api_base_url": "https://your-resource.openai.azure.com",
    "api_key_env_var": "AZURE_OPENAI_KEY",
    "model_type": "chat",
    "request_format": "openai",
    "custom_headers": {
      "api-key": "${AZURE_OPENAI_KEY}"
    },
    "description": "Azure OpenAI GPT-4",
    "tags": ["azure", "gpt", "enterprise"]
  }'
```

### ç¤ºä¾‹3: æ·»åŠ æ™ºè°±AI (GLM)

```bash
curl -X POST http://localhost:8000/api/v1/ai-models \
  -H "Content-Type: application/json" \
  -d '{
    "model_id": "zhipu-glm-4",
    "model_name": "æ™ºè°± GLM-4",
    "provider": "zhipu",
    "api_base_url": "https://open.bigmodel.cn/api/paas/v4",
    "api_key_env_var": "ZHIPU_API_KEY",
    "model_type": "chat",
    "request_format": "openai",
    "description": "æ™ºè°±AI GLM-4æ¨¡å‹",
    "tags": ["zhipu", "glm", "chinese"],
    "max_tokens": 4096
  }'
```

### ç¤ºä¾‹4: æ·»åŠ ç™¾åº¦æ–‡å¿ƒä¸€è¨€

```bash
curl -X POST http://localhost:8000/api/v1/ai-models \
  -H "Content-Type: application/json" \
  -d '{
    "model_id": "ernie-bot-4",
    "model_name": "æ–‡å¿ƒä¸€è¨€ 4.0",
    "provider": "baidu",
    "api_base_url": "https://aip.baidubce.com/rpc/2.0/ai_custom/v1/wenxinworkshop/chat",
    "api_key_env_var": "BAIDU_API_KEY",
    "model_type": "chat",
    "request_format": "custom",
    "request_template": {
      "messages": [
        {"role": "user", "content": "{{prompt}}"}
      ]
    },
    "response_path": "result",
    "description": "ç™¾åº¦æ–‡å¿ƒä¸€è¨€4.0",
    "tags": ["baidu", "ernie", "chinese"]
  }'
```

### ç¤ºä¾‹5: æ·»åŠ Hugging Faceæ¨¡å‹

```bash
curl -X POST http://localhost:8000/api/v1/ai-models \
  -H "Content-Type: application/json" \
  -d '{
    "model_id": "hf-codegen",
    "model_name": "HuggingFace CodeGen",
    "provider": "huggingface",
    "api_base_url": "https://api-inference.huggingface.co/models/Salesforce/codegen-16B-mono",
    "api_key_env_var": "HF_API_KEY",
    "model_type": "completion",
    "request_format": "custom",
    "request_template": {
      "inputs": "{{prompt}}",
      "parameters": {
        "max_new_tokens": 1000,
        "temperature": 0.7
      }
    },
    "response_path": "0.generated_text",
    "description": "HuggingFace CodeGenæ¨¡å‹",
    "tags": ["huggingface", "codegen"]
  }'
```

---

## ğŸ§ª æµ‹è¯•æ¨¡å‹

### åŸºæœ¬æµ‹è¯•

```bash
curl -X POST "http://localhost:8000/api/v1/ai-models/my-model/test"
```

### è‡ªå®šä¹‰æç¤ºè¯æµ‹è¯•

```bash
curl -X POST "http://localhost:8000/api/v1/ai-models/my-model/test?test_prompt=Write%20a%20Python%20function%20to%20sort%20a%20list"
```

### Pythonæµ‹è¯•è„šæœ¬

```python
import requests

def test_model(model_id, test_prompts):
    """æµ‹è¯•AIæ¨¡å‹"""
    results = []
    
    for prompt in test_prompts:
        response = requests.post(
            f'http://localhost:8000/api/v1/ai-models/{model_id}/test',
            params={'test_prompt': prompt}
        )
        
        result = response.json()
        results.append({
            'prompt': prompt,
            'success': result['test_result']['success'],
            'latency_ms': result['test_result'].get('latency_ms', 0),
            'error': result['test_result'].get('error')
        })
    
    return results

# ä½¿ç”¨
test_prompts = [
    "Hello, how are you?",
    "Write a Python function to calculate factorial",
    "Explain machine learning in simple terms"
]

results = test_model('my-custom-model', test_prompts)

for r in results:
    if r['success']:
        print(f"âœ… {r['prompt'][:50]}... ({r['latency_ms']}ms)")
    else:
        print(f"âŒ {r['prompt'][:50]}... Error: {r['error']}")
```

---

## ğŸ“¤ğŸ“¥ å¯¼å…¥å¯¼å‡º

### å¯¼å‡ºæ¨¡å‹é…ç½®

```bash
curl -X POST http://localhost:8000/api/v1/ai-models/my-model/export > my_model.json
```

### å¯¼å…¥æ¨¡å‹é…ç½®

```bash
# 1. ç¼–è¾‘å¯¼å‡ºçš„JSONæ–‡ä»¶ï¼Œè®¾ç½®æ‚¨è‡ªå·±çš„api_key_env_var
vi my_model.json

# 2. å¯¼å…¥
curl -X POST http://localhost:8000/api/v1/ai-models/import \
  -H "Content-Type: application/json" \
  -d @my_model.json
```

### æ‰¹é‡å¯¼å…¥

```python
import requests
import json

def import_models_from_file(file_path):
    """ä»æ–‡ä»¶æ‰¹é‡å¯¼å…¥æ¨¡å‹"""
    with open(file_path, 'r') as f:
        models = json.load(f)
    
    for model_config in models:
        response = requests.post(
            'http://localhost:8000/api/v1/ai-models/import',
            json=model_config
        )
        
        if response.status_code == 200:
            print(f"âœ… å¯¼å…¥æˆåŠŸ: {model_config['model_name']}")
        else:
            print(f"âŒ å¯¼å…¥å¤±è´¥: {model_config['model_name']} - {response.text}")

# ä½¿ç”¨
import_models_from_file('models_collection.json')
```

---

## ğŸ’¡ æœ€ä½³å®è·µ

### 1. APIå¯†é’¥ç®¡ç†

**æ¨èæ–¹å¼**:
```bash
# ä½¿ç”¨ .env æ–‡ä»¶
echo "MY_MODEL_API_KEY=xxx" >> .env

# æˆ–ä½¿ç”¨ç¯å¢ƒå˜é‡
export MY_MODEL_API_KEY="xxx"
```

**ä¸æ¨è**:
- âŒ ç¡¬ç¼–ç åœ¨ä»£ç ä¸­
- âŒ ç›´æ¥åœ¨é…ç½®ä¸­æš´éœ²

### 2. æ¨¡å‹å‘½å

**æ¨è**:
```json
{
  "model_id": "provider-model-version",
  "model_name": "Provider Model Version"
}
```

**ç¤ºä¾‹**:
- `openai-gpt-4o` â†’ "OpenAI GPT-4o"
- `anthropic-claude-3.5` â†’ "Anthropic Claude 3.5"
- `local-llama-3-8b` â†’ "Local Llama 3 8B"

### 3. ä½¿ç”¨æ ‡ç­¾

```json
{
  "tags": [
    "provider-name",
    "model-type",
    "capability",
    "language"
  ]
}
```

**ç¤ºä¾‹**:
```json
{
  "tags": ["openai", "gpt", "chat", "general"]
}
```

### 4. æµ‹è¯•æµç¨‹

```
1. æ·»åŠ æ¨¡å‹
   â†“
2. æµ‹è¯•åŸºæœ¬å“åº” (Hello test)
   â†“
3. æµ‹è¯•ä»£ç ç”Ÿæˆ (ç®€å•ä»»åŠ¡)
   â†“
4. æµ‹è¯•å®é™…ä½¿ç”¨åœºæ™¯
   â†“
5. æ€§èƒ½ç›‘æ§
```

### 5. é”™è¯¯å¤„ç†

```python
def add_model_safely(config):
    """å®‰å…¨æ·»åŠ æ¨¡å‹"""
    try:
        # 1. éªŒè¯å¿…éœ€å­—æ®µ
        required_fields = ['model_id', 'model_name', 'api_base_url', 'api_key_env_var']
        for field in required_fields:
            if not config.get(field):
                print(f"âŒ ç¼ºå°‘å¿…éœ€å­—æ®µ: {field}")
                return False
        
        # 2. éªŒè¯APIå¯†é’¥å­˜åœ¨
        import os
        if not os.getenv(config['api_key_env_var']):
            print(f"âš ï¸  è­¦å‘Š: ç¯å¢ƒå˜é‡ {config['api_key_env_var']} æœªè®¾ç½®")
        
        # 3. æ·»åŠ æ¨¡å‹
        response = requests.post(
            'http://localhost:8000/api/v1/ai-models',
            json=config
        )
        
        if response.status_code == 200:
            print(f"âœ… æ¨¡å‹æ·»åŠ æˆåŠŸ: {config['model_name']}")
            
            # 4. æµ‹è¯•æ¨¡å‹
            test_response = requests.post(
                f'http://localhost:8000/api/v1/ai-models/{config["model_id"]}/test'
            )
            
            if test_response.json()['test_result']['success']:
                print(f"âœ… æ¨¡å‹æµ‹è¯•æˆåŠŸ")
            else:
                print(f"âš ï¸  æ¨¡å‹æµ‹è¯•å¤±è´¥: {test_response.json()['test_result']['error']}")
            
            return True
        else:
            print(f"âŒ æ·»åŠ å¤±è´¥: {response.text}")
            return False
    
    except Exception as e:
        print(f"âŒ å¼‚å¸¸: {e}")
        return False
```

---

## â“ å¸¸è§é—®é¢˜

### Q1: å¦‚ä½•çŸ¥é“æˆ‘çš„APIä½¿ç”¨çš„æ˜¯ä»€ä¹ˆæ ¼å¼ï¼Ÿ

A: å¤§å¤šæ•°ç°ä»£AI APIéµå¾ªä»¥ä¸‹æ ¼å¼ä¹‹ä¸€ï¼š

1. **OpenAIæ ¼å¼** (æœ€å¸¸è§):
   - å¦‚æœAPIæ–‡æ¡£æåˆ° "chat/completions" ç«¯ç‚¹
   - è¯·æ±‚æ ¼å¼: `{"model": "...", "messages": [...]}`

2. **Anthropicæ ¼å¼**:
   - Claudeæ¨¡å‹ä¸“ç”¨
   - ä½¿ç”¨ `x-api-key` å¤´éƒ¨

3. **Googleæ ¼å¼**:
   - Geminiæ¨¡å‹
   - APIå¯†é’¥åœ¨URLå‚æ•°ä¸­

4. **è‡ªå®šä¹‰æ ¼å¼**:
   - å¦‚æœä»¥ä¸Šéƒ½ä¸åŒ¹é…ï¼Œä½¿ç”¨ `custom` æ ¼å¼å¹¶æä¾›æ¨¡æ¿

### Q2: APIå¯†é’¥å¦‚ä½•å®‰å…¨å­˜å‚¨ï¼Ÿ

A: ç³»ç»Ÿä¸å­˜å‚¨APIå¯†é’¥æœ¬èº«ï¼Œåªå­˜å‚¨ç¯å¢ƒå˜é‡åã€‚å®é™…å¯†é’¥åº”è¯¥:
- è®¾ç½®ä¸ºç¯å¢ƒå˜é‡
- æˆ–æ·»åŠ åˆ° `.env` æ–‡ä»¶ (ä¸è¦æäº¤åˆ°Git)
- ä½¿ç”¨å¯†é’¥ç®¡ç†æœåŠ¡ (ç”Ÿäº§ç¯å¢ƒ)

### Q3: å¯ä»¥æ·»åŠ å¤šå°‘ä¸ªè‡ªå®šä¹‰æ¨¡å‹ï¼Ÿ

A: æ²¡æœ‰ç¡¬æ€§é™åˆ¶ï¼Œä½†å»ºè®®:
- æ—¥å¸¸ä½¿ç”¨: 5-10ä¸ªæ¨¡å‹
- æµ‹è¯•ç¯å¢ƒ: 20+ä¸ªæ¨¡å‹
- æ ¹æ®å®é™…éœ€æ±‚æ·»åŠ 

### Q4: å†…ç½®æ¨¡å‹å¯ä»¥ä¿®æ”¹å—ï¼Ÿ

A: ä¸å¯ä»¥ã€‚å†…ç½®æ¨¡å‹æ˜¯åªè¯»çš„ï¼Œä½†æ‚¨å¯ä»¥:
- åŸºäºå†…ç½®æ¨¡å‹åˆ›å»ºè‡ªå®šä¹‰ç‰ˆæœ¬
- å¯¼å‡ºå†…ç½®æ¨¡å‹é…ç½®åä¿®æ”¹å¹¶å¯¼å…¥ä¸ºæ–°æ¨¡å‹

### Q5: æ¨¡å‹æ·»åŠ åå¤šä¹…ç”Ÿæ•ˆï¼Ÿ

A: ç«‹å³ç”Ÿæ•ˆï¼ç³»ç»Ÿä½¿ç”¨çƒ­åŠ è½½ï¼Œæ— éœ€é‡å¯ã€‚

### Q6: å¦‚ä½•å¤„ç†APIé€Ÿç‡é™åˆ¶ï¼Ÿ

A: å»ºè®®:
1. åœ¨æ¨¡å‹é…ç½®ä¸­æ·»åŠ é€‚å½“çš„`max_tokens`
2. è°ƒæ•´`temperature`ä»¥æ§åˆ¶è¾“å‡ºé•¿åº¦
3. ä½¿ç”¨å¤šä¸ªAPIå¯†é’¥å¹¶æ·»åŠ ä¸ºä¸åŒçš„æ¨¡å‹å®ä¾‹
4. åˆ©ç”¨å¤šAIç­–ç•¥ä¸­çš„"è´Ÿè½½å‡è¡¡"æ¨¡å¼

### Q7: æµ‹è¯•å¤±è´¥æ€ä¹ˆåŠï¼Ÿ

A: æ£€æŸ¥æ¸…å•:
- âœ… APIå¯†é’¥æ˜¯å¦æ­£ç¡®è®¾ç½®ï¼Ÿ
- âœ… `api_base_url` æ˜¯å¦æ­£ç¡®ï¼Ÿ
- âœ… `request_format` æ˜¯å¦åŒ¹é…ï¼Ÿ
- âœ… ç½‘ç»œè¿æ¥æ˜¯å¦æ­£å¸¸ï¼Ÿ
- âœ… æŸ¥çœ‹é”™è¯¯ä¿¡æ¯ä¸­çš„å…·ä½“åŸå› 

### Q8: å¯ä»¥ä½¿ç”¨æœ¬åœ°æ¨¡å‹å—ï¼Ÿ

A: å¯ä»¥ï¼æ”¯æŒ:
- Ollama (æ¨è)
- vLLM
- LocalAI
- å…¶ä»–æ”¯æŒOpenAIå…¼å®¹APIçš„æœ¬åœ°æœåŠ¡

ç¤ºä¾‹è§ä¸Šæ–¹"æ·»åŠ Ollamaæœ¬åœ°æ¨¡å‹"ã€‚

---

## ğŸ‰ å¼€å§‹ä½¿ç”¨

ç°åœ¨æ‚¨å·²ç»äº†è§£äº†å¦‚ä½•æ·»åŠ è‡ªå®šä¹‰AIæ¨¡å‹ï¼

**ä¸‹ä¸€æ­¥**:
1. åˆ—å‡ºç°æœ‰æ¨¡å‹: `GET /api/v1/ai-models`
2. æ·»åŠ æ‚¨çš„ç¬¬ä¸€ä¸ªè‡ªå®šä¹‰æ¨¡å‹
3. æµ‹è¯•æ¨¡å‹: `POST /api/v1/ai-models/{model_id}/test`
4. åœ¨å®é™…ä»»åŠ¡ä¸­ä½¿ç”¨

**éœ€è¦å¸®åŠ©ï¼Ÿ**
- æŸ¥çœ‹APIæ–‡æ¡£: http://localhost:8000/docs
- æŸ¥çœ‹ç¤ºä¾‹: æœ¬æ–‡æ¡£çš„"æ·»åŠ ç¤ºä¾‹"éƒ¨åˆ†
- æissue: GitHub Issues

---

*ğŸ“… åˆ›å»ºæ—¥æœŸ: 2025-10-25*  
*ğŸ¤– AI Code Migration Platform Team*

