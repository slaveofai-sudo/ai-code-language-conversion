"""
Cache Manager / ç¼“å­˜ç®¡ç†å™¨

Provides caching functionality for translation results using Redis.
ä½¿ç”¨Redisä¸ºç¿»è¯‘ç»“æœæä¾›ç¼“å­˜åŠŸèƒ½ã€‚

Features / åŠŸèƒ½:
- Translation result caching / ç¿»è¯‘ç»“æœç¼“å­˜
- Automatic expiration / è‡ªåŠ¨è¿‡æœŸ
- Cache statistics / ç¼“å­˜ç»Ÿè®¡
- Cache invalidation / ç¼“å­˜å¤±æ•ˆ
"""

import hashlib
import json
from typing import Optional, Any, Dict
from functools import wraps
import asyncio
from loguru import logger

try:
    import redis.asyncio as redis
    REDIS_AVAILABLE = True
except ImportError:
    REDIS_AVAILABLE = False
    logger.warning("Redis not available, caching will be disabled")


class CacheManager:
    """
    Cache Manager for translation results / ç¿»è¯‘ç»“æœç¼“å­˜ç®¡ç†å™¨
    
    Uses Redis for high-performance caching with automatic expiration.
    ä½¿ç”¨Redisè¿›è¡Œé«˜æ€§èƒ½ç¼“å­˜ï¼Œæ”¯æŒè‡ªåŠ¨è¿‡æœŸã€‚
    """
    
    def __init__(
        self,
        redis_url: str = "redis://localhost:6379/0",
        default_ttl: int = 3600  # 1 hour
    ):
        """
        Initialize cache manager / åˆå§‹åŒ–ç¼“å­˜ç®¡ç†å™¨
        
        Args:
            redis_url: Redis connection URL / Redisè¿æ¥URL
            default_ttl: Default cache TTL in seconds / é»˜è®¤ç¼“å­˜TTLï¼ˆç§’ï¼‰
        """
        self.redis_url = redis_url
        self.default_ttl = default_ttl
        self.redis_client = None
        self.stats = {
            "hits": 0,
            "misses": 0,
            "sets": 0,
            "errors": 0
        }
        
        if REDIS_AVAILABLE:
            try:
                self.redis_client = redis.from_url(redis_url, decode_responses=True)
                logger.info(f"âœ… Redis cache initialized: {redis_url}")
            except Exception as e:
                logger.error(f"âŒ Failed to connect to Redis: {e}")
                self.redis_client = None
        else:
            logger.warning("âš ï¸ Redis not installed, using in-memory fallback cache")
            self._memory_cache: Dict[str, Any] = {}
    
    def _generate_cache_key(
        self,
        source_code: str,
        source_language: str,
        target_language: str,
        ai_model: str,
        **kwargs
    ) -> str:
        """
        Generate unique cache key / ç”Ÿæˆå”¯ä¸€çš„ç¼“å­˜é”®
        
        Uses SHA256 hash of code content and parameters.
        ä½¿ç”¨ä»£ç å†…å®¹å’Œå‚æ•°çš„SHA256å“ˆå¸Œã€‚
        
        Args:
            source_code: Source code / æºä»£ç 
            source_language: Source language / æºè¯­è¨€
            target_language: Target language / ç›®æ ‡è¯­è¨€
            ai_model: AI model name / AIæ¨¡å‹åç§°
            **kwargs: Additional parameters / é¢å¤–å‚æ•°
            
        Returns:
            str: Cache key / ç¼“å­˜é”®
        """
        # Create a unique string from all parameters / ä»æ‰€æœ‰å‚æ•°åˆ›å»ºå”¯ä¸€å­—ç¬¦ä¸²
        key_data = f"{source_code}:{source_language}:{target_language}:{ai_model}"
        
        # Add additional parameters / æ·»åŠ é¢å¤–å‚æ•°
        for key, value in sorted(kwargs.items()):
            key_data += f":{key}:{value}"
        
        # Generate hash / ç”Ÿæˆå“ˆå¸Œ
        hash_obj = hashlib.sha256(key_data.encode('utf-8'))
        cache_key = f"translation:{hash_obj.hexdigest()}"
        
        return cache_key
    
    async def get(self, cache_key: str) -> Optional[str]:
        """
        Get cached value / è·å–ç¼“å­˜å€¼
        
        Args:
            cache_key: Cache key / ç¼“å­˜é”®
            
        Returns:
            Cached value or None / ç¼“å­˜å€¼æˆ–None
        """
        try:
            if self.redis_client:
                # Get from Redis / ä»Redisè·å–
                value = await self.redis_client.get(cache_key)
                if value:
                    self.stats["hits"] += 1
                    logger.debug(f"âœ… Cache HIT: {cache_key[:16]}...")
                    return value
                else:
                    self.stats["misses"] += 1
                    logger.debug(f"âŒ Cache MISS: {cache_key[:16]}...")
                    return None
            else:
                # Fallback to in-memory cache / å›é€€åˆ°å†…å­˜ç¼“å­˜
                value = self._memory_cache.get(cache_key)
                if value:
                    self.stats["hits"] += 1
                    return value
                else:
                    self.stats["misses"] += 1
                    return None
                    
        except Exception as e:
            logger.error(f"âŒ Cache get error: {e}")
            self.stats["errors"] += 1
            return None
    
    async def set(
        self,
        cache_key: str,
        value: str,
        ttl: Optional[int] = None
    ) -> bool:
        """
        Set cache value / è®¾ç½®ç¼“å­˜å€¼
        
        Args:
            cache_key: Cache key / ç¼“å­˜é”®
            value: Value to cache / è¦ç¼“å­˜çš„å€¼
            ttl: Time to live in seconds / ç”Ÿå­˜æ—¶é—´ï¼ˆç§’ï¼‰
            
        Returns:
            bool: Success status / æˆåŠŸçŠ¶æ€
        """
        try:
            ttl = ttl or self.default_ttl
            
            if self.redis_client:
                # Set in Redis with expiration / åœ¨Redisä¸­è®¾ç½®å¹¶å¸¦è¿‡æœŸæ—¶é—´
                await self.redis_client.setex(cache_key, ttl, value)
                self.stats["sets"] += 1
                logger.debug(f"ğŸ’¾ Cache SET: {cache_key[:16]}... (TTL: {ttl}s)")
                return True
            else:
                # Fallback to in-memory cache / å›é€€åˆ°å†…å­˜ç¼“å­˜
                self._memory_cache[cache_key] = value
                self.stats["sets"] += 1
                # Schedule cleanup (simple approach) / å®‰æ’æ¸…ç†
                asyncio.create_task(self._cleanup_memory_cache(cache_key, ttl))
                return True
                
        except Exception as e:
            logger.error(f"âŒ Cache set error: {e}")
            self.stats["errors"] += 1
            return False
    
    async def _cleanup_memory_cache(self, key: str, ttl: int):
        """Clean up expired memory cache entries / æ¸…ç†è¿‡æœŸçš„å†…å­˜ç¼“å­˜æ¡ç›®"""
        await asyncio.sleep(ttl)
        if key in self._memory_cache:
            del self._memory_cache[key]
    
    async def delete(self, cache_key: str) -> bool:
        """
        Delete cache entry / åˆ é™¤ç¼“å­˜æ¡ç›®
        
        Args:
            cache_key: Cache key / ç¼“å­˜é”®
            
        Returns:
            bool: Success status / æˆåŠŸçŠ¶æ€
        """
        try:
            if self.redis_client:
                await self.redis_client.delete(cache_key)
            else:
                if cache_key in self._memory_cache:
                    del self._memory_cache[cache_key]
            return True
        except Exception as e:
            logger.error(f"âŒ Cache delete error: {e}")
            return False
    
    async def clear_all(self) -> bool:
        """
        Clear all cache entries / æ¸…ç©ºæ‰€æœ‰ç¼“å­˜æ¡ç›®
        
        Returns:
            bool: Success status / æˆåŠŸçŠ¶æ€
        """
        try:
            if self.redis_client:
                # Delete all translation keys / åˆ é™¤æ‰€æœ‰ç¿»è¯‘é”®
                cursor = 0
                while True:
                    cursor, keys = await self.redis_client.scan(
                        cursor,
                        match="translation:*",
                        count=100
                    )
                    if keys:
                        await self.redis_client.delete(*keys)
                    if cursor == 0:
                        break
            else:
                self._memory_cache.clear()
            
            logger.info("ğŸ§¹ Cache cleared successfully")
            return True
        except Exception as e:
            logger.error(f"âŒ Cache clear error: {e}")
            return False
    
    def get_stats(self) -> Dict[str, Any]:
        """
        Get cache statistics / è·å–ç¼“å­˜ç»Ÿè®¡
        
        Returns:
            dict: Cache statistics / ç¼“å­˜ç»Ÿè®¡
        """
        total_requests = self.stats["hits"] + self.stats["misses"]
        hit_rate = (self.stats["hits"] / total_requests * 100) if total_requests > 0 else 0
        
        return {
            "hits": self.stats["hits"],
            "misses": self.stats["misses"],
            "sets": self.stats["sets"],
            "errors": self.stats["errors"],
            "total_requests": total_requests,
            "hit_rate_percent": round(hit_rate, 2),
            "cache_backend": "redis" if self.redis_client else "memory"
        }
    
    async def get_cache_size(self) -> int:
        """
        Get total number of cached items / è·å–ç¼“å­˜é¡¹æ€»æ•°
        
        Returns:
            int: Number of cached items / ç¼“å­˜é¡¹æ•°é‡
        """
        try:
            if self.redis_client:
                cursor = 0
                count = 0
                while True:
                    cursor, keys = await self.redis_client.scan(
                        cursor,
                        match="translation:*",
                        count=100
                    )
                    count += len(keys)
                    if cursor == 0:
                        break
                return count
            else:
                return len(self._memory_cache)
        except Exception as e:
            logger.error(f"âŒ Error getting cache size: {e}")
            return 0
    
    async def close(self):
        """Close Redis connection / å…³é—­Redisè¿æ¥"""
        if self.redis_client:
            await self.redis_client.close()
            logger.info("Redis connection closed")


def cache_translation(cache_manager: CacheManager, ttl: Optional[int] = None):
    """
    Decorator to cache translation results / è£…é¥°å™¨ç”¨äºç¼“å­˜ç¿»è¯‘ç»“æœ
    
    Usage / ä½¿ç”¨æ–¹æ³•:
    ```python
    @cache_translation(cache_manager, ttl=3600)
    async def translate_code(source_code, source_lang, target_lang, ai_model):
        # Translation logic here
        return translated_code
    ```
    
    Args:
        cache_manager: CacheManager instance / CacheManagerå®ä¾‹
        ttl: Cache TTL in seconds / ç¼“å­˜TTLï¼ˆç§’ï¼‰
    """
    def decorator(func):
        @wraps(func)
        async def wrapper(source_code: str, source_language: str, target_language: str, ai_model: str, *args, **kwargs):
            # Generate cache key / ç”Ÿæˆç¼“å­˜é”®
            cache_key = cache_manager._generate_cache_key(
                source_code,
                source_language,
                target_language,
                ai_model,
                **kwargs
            )
            
            # Try to get from cache / å°è¯•ä»ç¼“å­˜è·å–
            cached_result = await cache_manager.get(cache_key)
            if cached_result:
                logger.info(f"ğŸ¯ Using cached translation (saved API call)")
                return cached_result
            
            # Execute translation / æ‰§è¡Œç¿»è¯‘
            logger.info(f"ğŸ”„ No cache, executing translation...")
            result = await func(source_code, source_language, target_language, ai_model, *args, **kwargs)
            
            # Store in cache / å­˜å…¥ç¼“å­˜
            if result:
                await cache_manager.set(cache_key, result, ttl)
            
            return result
        return wrapper
    return decorator


# Global cache manager instance / å…¨å±€ç¼“å­˜ç®¡ç†å™¨å®ä¾‹
_cache_manager_instance = None

def get_cache_manager() -> CacheManager:
    """
    Get global cache manager instance / è·å–å…¨å±€ç¼“å­˜ç®¡ç†å™¨å®ä¾‹
    
    Returns:
        CacheManager: Cache manager instance / ç¼“å­˜ç®¡ç†å™¨å®ä¾‹
    """
    global _cache_manager_instance
    if _cache_manager_instance is None:
        import os
        redis_url = os.getenv("REDIS_URL", "redis://localhost:6379/0")
        _cache_manager_instance = CacheManager(redis_url=redis_url)
    return _cache_manager_instance

