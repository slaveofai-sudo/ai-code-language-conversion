"""
Learning Document Generator / å­¦ä¹ æ–‡æ¡£ç”Ÿæˆå™¨

Generates comprehensive learning documentation for code projects.
ä¸ºä»£ç é¡¹ç›®ç”Ÿæˆå…¨é¢çš„å­¦ä¹ æ–‡æ¡£ã€‚

Features / åŠŸèƒ½:
- Learning roadmap / å­¦ä¹ è·¯çº¿å›¾
- Difficulty analysis / éš¾åº¦åˆ†æ
- Design pattern explanation / è®¾è®¡æ¨¡å¼è§£é‡Š
- Implementation flow / å®ç°æµç¨‹
- Detailed code analysis / è¯¦ç»†ä»£ç åˆ†æ
"""

from pathlib import Path
from typing import Dict, Any, List, Optional
from loguru import logger
from datetime import datetime
import json


class LearningDocGenerator:
    """
    Learning Document Generator / å­¦ä¹ æ–‡æ¡£ç”Ÿæˆå™¨
    
    Generates detailed learning documentation based on code inspection results.
    åŸºäºä»£ç æ£€æµ‹ç»“æœç”Ÿæˆè¯¦ç»†çš„å­¦ä¹ æ–‡æ¡£ã€‚
    """
    
    def __init__(self):
        self.difficulty_descriptions = {
            "easy": {
                "zh": "åˆçº§ - é€‚åˆç¼–ç¨‹æ–°æ‰‹",
                "en": "Beginner - Suitable for programming newcomers",
                "learning_time": "1-2 å¤©",
                "prerequisites": "åŸºæœ¬ç¼–ç¨‹æ¦‚å¿µ"
            },
            "medium": {
                "zh": "ä¸­çº§ - éœ€è¦ä¸€å®šç¼–ç¨‹ç»éªŒ",
                "en": "Intermediate - Requires some programming experience",
                "learning_time": "3-5 å¤©",
                "prerequisites": "ç†Ÿæ‚‰åŸºæœ¬è¯­æ³•å’Œæ•°æ®ç»“æ„"
            },
            "hard": {
                "zh": "é«˜çº§ - éœ€è¦æ‰å®çš„ç¼–ç¨‹åŸºç¡€",
                "en": "Advanced - Requires solid programming foundation",
                "learning_time": "1-2 å‘¨",
                "prerequisites": "ç†Ÿæ‚‰è®¾è®¡æ¨¡å¼å’Œé«˜çº§æ¦‚å¿µ"
            },
            "expert": {
                "zh": "ä¸“å®¶çº§ - éœ€è¦ä¸°å¯Œçš„å®æˆ˜ç»éªŒ",
                "en": "Expert - Requires extensive practical experience",
                "learning_time": "2-4 å‘¨",
                "prerequisites": "æ·±å…¥ç†è§£æ¶æ„å’Œæœ€ä½³å®è·µ"
            }
        }
        
        self.pattern_explanations = {
            "singleton": {
                "zh": "å•ä¾‹æ¨¡å¼ - ç¡®ä¿ä¸€ä¸ªç±»åªæœ‰ä¸€ä¸ªå®ä¾‹",
                "en": "Singleton Pattern - Ensures a class has only one instance",
                "use_case": "å…¨å±€é…ç½®ã€æ•°æ®åº“è¿æ¥æ± ",
                "difficulty": "easy"
            },
            "factory": {
                "zh": "å·¥å‚æ¨¡å¼ - åˆ›å»ºå¯¹è±¡çš„æ¥å£",
                "en": "Factory Pattern - Interface for creating objects",
                "use_case": "å¯¹è±¡åˆ›å»ºé€»è¾‘å¤æ‚æ—¶",
                "difficulty": "medium"
            },
            "observer": {
                "zh": "è§‚å¯Ÿè€…æ¨¡å¼ - å®šä¹‰å¯¹è±¡é—´çš„ä¸€å¯¹å¤šä¾èµ–",
                "en": "Observer Pattern - Defines one-to-many dependency",
                "use_case": "äº‹ä»¶å¤„ç†ã€æ¶ˆæ¯è®¢é˜…",
                "difficulty": "medium"
            },
            "strategy": {
                "zh": "ç­–ç•¥æ¨¡å¼ - å®šä¹‰ç®—æ³•æ—å¹¶å¯äº’æ¢",
                "en": "Strategy Pattern - Defines family of algorithms",
                "use_case": "ä¸åŒç®—æ³•å®ç°å¯æ›¿æ¢",
                "difficulty": "medium"
            },
            "decorator": {
                "zh": "è£…é¥°å™¨æ¨¡å¼ - åŠ¨æ€æ·»åŠ åŠŸèƒ½",
                "en": "Decorator Pattern - Adds functionality dynamically",
                "use_case": "åœ¨ä¸ä¿®æ”¹åŸä»£ç æƒ…å†µä¸‹æ‰©å±•åŠŸèƒ½",
                "difficulty": "medium"
            },
            "repository": {
                "zh": "ä»“å‚¨æ¨¡å¼ - å°è£…æ•°æ®è®¿é—®é€»è¾‘",
                "en": "Repository Pattern - Encapsulates data access",
                "use_case": "æ•°æ®æŒä¹…åŒ–å±‚",
                "difficulty": "medium"
            },
            "mvc": {
                "zh": "MVCæ¨¡å¼ - æ¨¡å‹-è§†å›¾-æ§åˆ¶å™¨åˆ†ç¦»",
                "en": "MVC Pattern - Model-View-Controller separation",
                "use_case": "Webåº”ç”¨æ¶æ„",
                "difficulty": "hard"
            }
        }
    
    def generate_learning_doc(
        self,
        inspection_results: Dict[str, Any],
        project_path: Path,
        output_format: str = "markdown"
    ) -> str:
        """
        Generate comprehensive learning documentation.
        ç”Ÿæˆå…¨é¢çš„å­¦ä¹ æ–‡æ¡£ã€‚
        
        Args:
            inspection_results: Results from CodeInspector.
                               ä»£ç æ£€æµ‹å™¨çš„ç»“æœã€‚
            project_path: Path to the project.
                         é¡¹ç›®è·¯å¾„ã€‚
            output_format: Output format (markdown, html, json).
                          è¾“å‡ºæ ¼å¼ã€‚
        
        Returns:
            Generated documentation string.
            ç”Ÿæˆçš„æ–‡æ¡£å­—ç¬¦ä¸²ã€‚
        """
        logger.info(f"å¼€å§‹ç”Ÿæˆå­¦ä¹ æ–‡æ¡£: {project_path}")
        
        if output_format == "markdown":
            return self._generate_markdown_doc(inspection_results, project_path)
        elif output_format == "json":
            return json.dumps(self._generate_json_doc(inspection_results, project_path), indent=2, ensure_ascii=False)
        else:
            raise ValueError(f"Unsupported output format: {output_format}")
    
    def _generate_markdown_doc(self, results: Dict[str, Any], project_path: Path) -> str:
        """Generate Markdown format documentation"""
        project_metrics = results['project_metrics']
        file_metrics = results['file_metrics']
        architecture = results['architecture']
        tech_stack = results['tech_stack']
        summary = results['summary']
        
        doc = []
        
        # Title and metadata
        # æ ‡é¢˜å’Œå…ƒæ•°æ®
        doc.append(f"# ğŸ“š {project_metrics['project_name']} - å­¦ä¹ æ–‡æ¡£")
        doc.append("")
        doc.append(f"**ç”Ÿæˆæ—¶é—´**: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
        doc.append(f"**é¡¹ç›®è·¯å¾„**: `{project_path}`")
        doc.append("")
        doc.append("---")
        doc.append("")
        
        # Table of Contents
        # ç›®å½•
        doc.append("## ğŸ“– ç›®å½•")
        doc.append("")
        doc.append("1. [é¡¹ç›®æ¦‚è§ˆ](#é¡¹ç›®æ¦‚è§ˆ)")
        doc.append("2. [å­¦ä¹ è·¯çº¿å›¾](#å­¦ä¹ è·¯çº¿å›¾)")
        doc.append("3. [éš¾åº¦åˆ†æ](#éš¾åº¦åˆ†æ)")
        doc.append("4. [æŠ€æœ¯æ ˆåˆ†æ](#æŠ€æœ¯æ ˆåˆ†æ)")
        doc.append("5. [æ¶æ„è®¾è®¡](#æ¶æ„è®¾è®¡)")
        doc.append("6. [è®¾è®¡æ¨¡å¼](#è®¾è®¡æ¨¡å¼)")
        doc.append("7. [ä»£ç å¤æ‚åº¦](#ä»£ç å¤æ‚åº¦)")
        doc.append("8. [æ–‡ä»¶ç»“æ„åˆ†æ](#æ–‡ä»¶ç»“æ„åˆ†æ)")
        doc.append("9. [å­¦ä¹ å»ºè®®](#å­¦ä¹ å»ºè®®)")
        doc.append("10. [ä»£ç è´¨é‡æŠ¥å‘Š](#ä»£ç è´¨é‡æŠ¥å‘Š)")
        doc.append("")
        doc.append("---")
        doc.append("")
        
        # 1. Project Overview
        # é¡¹ç›®æ¦‚è§ˆ
        doc.append("## ğŸ¯ é¡¹ç›®æ¦‚è§ˆ")
        doc.append("")
        doc.append("### åŸºæœ¬ä¿¡æ¯")
        doc.append("")
        doc.append(f"- **é¡¹ç›®åç§°**: {project_metrics['project_name']}")
        doc.append(f"- **ä»£ç æ–‡ä»¶æ•°**: {project_metrics['total_files']} ä¸ª")
        doc.append(f"- **ä»£ç æ€»è¡Œæ•°**: {project_metrics['total_lines']:,} è¡Œ")
        doc.append(f"- **å‡½æ•°æ•°é‡**: {project_metrics['total_functions']} ä¸ª")
        doc.append(f"- **ç±»æ•°é‡**: {project_metrics['total_classes']} ä¸ª")
        doc.append(f"- **æ•´ä½“éš¾åº¦**: {project_metrics['overall_difficulty'].upper()}")
        doc.append(f"- **å¥åº·åˆ†æ•°**: {summary['health_score']}/100 {'ğŸŸ¢' if summary['health_score'] >= 80 else 'ğŸŸ¡' if summary['health_score'] >= 60 else 'ğŸ”´'}")
        doc.append("")
        
        # Language distribution
        # è¯­è¨€åˆ†å¸ƒ
        doc.append("### ç¼–ç¨‹è¯­è¨€åˆ†å¸ƒ")
        doc.append("")
        doc.append("| è¯­è¨€ | ä»£ç è¡Œæ•° | å æ¯” |")
        doc.append("|------|---------|------|")
        
        total_lines = sum(project_metrics['languages'].values())
        for lang, lines in sorted(project_metrics['languages'].items(), key=lambda x: x[1], reverse=True):
            percentage = (lines / total_lines * 100) if total_lines > 0 else 0
            doc.append(f"| {lang.title()} | {lines:,} | {percentage:.1f}% |")
        
        doc.append("")
        doc.append("---")
        doc.append("")
        
        # 2. Learning Roadmap
        # å­¦ä¹ è·¯çº¿å›¾
        doc.append("## ğŸ—ºï¸ å­¦ä¹ è·¯çº¿å›¾")
        doc.append("")
        doc.append(self._generate_learning_roadmap(project_metrics, file_metrics))
        doc.append("")
        doc.append("---")
        doc.append("")
        
        # 3. Difficulty Analysis
        # éš¾åº¦åˆ†æ
        doc.append("## ğŸ“Š éš¾åº¦åˆ†æ")
        doc.append("")
        doc.append(self._generate_difficulty_analysis(project_metrics, file_metrics))
        doc.append("")
        doc.append("---")
        doc.append("")
        
        # 4. Tech Stack
        # æŠ€æœ¯æ ˆ
        doc.append("## ğŸ› ï¸ æŠ€æœ¯æ ˆåˆ†æ")
        doc.append("")
        doc.append("### ä½¿ç”¨çš„æŠ€æœ¯")
        doc.append("")
        
        if tech_stack:
            for tech in tech_stack:
                doc.append(f"- âœ… **{tech}**")
        else:
            doc.append("- â„¹ï¸ æœªæ£€æµ‹åˆ°æ˜ç¡®çš„æŠ€æœ¯æ ˆæ ‡è¯†")
        
        doc.append("")
        doc.append("### å­¦ä¹ èµ„æºæ¨è")
        doc.append("")
        doc.append(self._generate_tech_resources(tech_stack))
        doc.append("")
        doc.append("---")
        doc.append("")
        
        # 5. Architecture Design
        # æ¶æ„è®¾è®¡
        doc.append("## ğŸ›ï¸ æ¶æ„è®¾è®¡")
        doc.append("")
        doc.append(self._generate_architecture_analysis(architecture, file_metrics))
        doc.append("")
        doc.append("---")
        doc.append("")
        
        # 6. Design Patterns
        # è®¾è®¡æ¨¡å¼
        doc.append("## ğŸ¨ è®¾è®¡æ¨¡å¼")
        doc.append("")
        doc.append(self._generate_pattern_analysis(file_metrics))
        doc.append("")
        doc.append("---")
        doc.append("")
        
        # 7. Complexity Analysis
        # å¤æ‚åº¦åˆ†æ
        doc.append("## ğŸ§® ä»£ç å¤æ‚åº¦")
        doc.append("")
        doc.append(self._generate_complexity_analysis(project_metrics, file_metrics))
        doc.append("")
        doc.append("---")
        doc.append("")
        
        # 8. File Structure Analysis
        # æ–‡ä»¶ç»“æ„åˆ†æ
        doc.append("## ğŸ“ æ–‡ä»¶ç»“æ„åˆ†æ")
        doc.append("")
        doc.append(self._generate_file_analysis(file_metrics))
        doc.append("")
        doc.append("---")
        doc.append("")
        
        # 9. Learning Recommendations
        # å­¦ä¹ å»ºè®®
        doc.append("## ğŸ’¡ å­¦ä¹ å»ºè®®")
        doc.append("")
        doc.append(self._generate_learning_recommendations(project_metrics, file_metrics, summary))
        doc.append("")
        doc.append("---")
        doc.append("")
        
        # 10. Code Quality Report
        # ä»£ç è´¨é‡æŠ¥å‘Š
        doc.append("## ğŸ” ä»£ç è´¨é‡æŠ¥å‘Š")
        doc.append("")
        doc.append(self._generate_quality_report(file_metrics, summary))
        doc.append("")
        doc.append("---")
        doc.append("")
        
        # Footer
        # é¡µè„š
        doc.append("## ğŸ“ é™„å½•")
        doc.append("")
        doc.append("### æœ¯è¯­è§£é‡Š")
        doc.append("")
        doc.append("- **åœˆå¤æ‚åº¦ (Cyclomatic Complexity)**: è¡¡é‡ä»£ç åˆ†æ”¯å’Œå¾ªç¯çš„æ•°é‡ï¼Œå€¼è¶Šé«˜ä»£ç è¶Šå¤æ‚")
        doc.append("- **è®¤çŸ¥å¤æ‚åº¦ (Cognitive Complexity)**: è¡¡é‡ä»£ç ç†è§£çš„éš¾åº¦ï¼Œè€ƒè™‘åµŒå¥—å’Œæ§åˆ¶æµ")
        doc.append("- **å¯ç»´æŠ¤æ€§æŒ‡æ•° (Maintainability Index)**: 0-100çš„åˆ†æ•°ï¼Œè¡¨ç¤ºä»£ç çš„å¯ç»´æŠ¤æ€§")
        doc.append("- **ä»£ç å¼‚å‘³ (Code Smell)**: ä»£ç ä¸­å¯èƒ½å­˜åœ¨çš„è®¾è®¡æˆ–å®ç°é—®é¢˜")
        doc.append("")
        doc.append("### ç›¸å…³é“¾æ¥")
        doc.append("")
        doc.append("- [Clean CodeåŸåˆ™](https://www.amazon.com/Clean-Code-Handbook-Software-Craftsmanship/dp/0132350882)")
        doc.append("- [è®¾è®¡æ¨¡å¼](https://refactoring.guru/design-patterns)")
        doc.append("- [ä»£ç å¤æ‚åº¦](https://en.wikipedia.org/wiki/Cyclomatic_complexity)")
        doc.append("")
        doc.append("---")
        doc.append("")
        doc.append(f"*ğŸ“… æ–‡æ¡£ç”Ÿæˆäº {datetime.now().strftime('%Yå¹´%mæœˆ%dæ—¥ %H:%M:%S')}*")
        doc.append("")
        doc.append("*ğŸ¤– ç”± AI Code Migration Platform è‡ªåŠ¨ç”Ÿæˆ*")
        
        return "\n".join(doc)
    
    def _generate_learning_roadmap(
        self,
        project_metrics: Dict[str, Any],
        file_metrics: List[Dict[str, Any]]
    ) -> str:
        """Generate learning roadmap"""
        difficulty = project_metrics['overall_difficulty']
        difficulty_info = self.difficulty_descriptions.get(difficulty, self.difficulty_descriptions['medium'])
        
        roadmap = []
        
        roadmap.append(f"### æ¨èå­¦ä¹ æ—¶é—´")
        roadmap.append("")
        roadmap.append(f"**{difficulty_info['learning_time']}**")
        roadmap.append("")
        roadmap.append(f"### å‰ç½®çŸ¥è¯†è¦æ±‚")
        roadmap.append("")
        roadmap.append(f"- {difficulty_info['prerequisites']}")
        roadmap.append("")
        
        roadmap.append("### å­¦ä¹ é˜¶æ®µ")
        roadmap.append("")
        roadmap.append("#### é˜¶æ®µ1: é¡¹ç›®ç»“æ„ç†è§£ (20%)")
        roadmap.append("")
        roadmap.append("- ğŸ“‚ äº†è§£é¡¹ç›®ç›®å½•ç»“æ„")
        roadmap.append("- ğŸ“‹ é˜…è¯»ä¸»è¦é…ç½®æ–‡ä»¶")
        roadmap.append("- ğŸ”— ç†è§£æ¨¡å—é—´çš„ä¾èµ–å…³ç³»")
        roadmap.append("")
        roadmap.append("**å»ºè®®æ—¶é•¿**: 1-2å°æ—¶")
        roadmap.append("")
        
        roadmap.append("#### é˜¶æ®µ2: æ ¸å¿ƒåŠŸèƒ½å­¦ä¹  (40%)")
        roadmap.append("")
        
        # Find most important files
        # æ‰¾åˆ°æœ€é‡è¦çš„æ–‡ä»¶
        important_files = sorted(
            file_metrics,
            key=lambda f: f['num_functions'] + f['num_classes'],
            reverse=True
        )[:5]
        
        roadmap.append("**é‡ç‚¹å­¦ä¹ æ–‡ä»¶**:")
        roadmap.append("")
        for i, f in enumerate(important_files, 1):
            file_name = Path(f['file_path']).name
            roadmap.append(f"{i}. `{file_name}` - {f['num_functions']} ä¸ªå‡½æ•°, {f['num_classes']} ä¸ªç±»")
        
        roadmap.append("")
        roadmap.append("**å»ºè®®æ—¶é•¿**: æ ¹æ®éš¾åº¦è€Œå®š")
        roadmap.append("")
        
        roadmap.append("#### é˜¶æ®µ3: è®¾è®¡æ¨¡å¼ç†è§£ (20%)")
        roadmap.append("")
        roadmap.append("- ğŸ¨ è¯†åˆ«ä»£ç ä¸­ä½¿ç”¨çš„è®¾è®¡æ¨¡å¼")
        roadmap.append("- ğŸ”„ ç†è§£æ¨¡å¼çš„åº”ç”¨åœºæ™¯")
        roadmap.append("- ğŸ’¡ å­¦ä¹ æœ€ä½³å®è·µ")
        roadmap.append("")
        roadmap.append("**å»ºè®®æ—¶é•¿**: 2-4å°æ—¶")
        roadmap.append("")
        
        roadmap.append("#### é˜¶æ®µ4: å®è·µä¸ä¼˜åŒ– (20%)")
        roadmap.append("")
        roadmap.append("- âœï¸ å°è¯•ä¿®æ”¹å’Œæ‰©å±•åŠŸèƒ½")
        roadmap.append("- ğŸ§ª ç¼–å†™å•å…ƒæµ‹è¯•")
        roadmap.append("- ğŸ”§ é‡æ„å’Œä¼˜åŒ–ä»£ç ")
        roadmap.append("")
        roadmap.append("**å»ºè®®æ—¶é•¿**: æ ¹æ®é¡¹ç›®å¤æ‚åº¦è€Œå®š")
        
        return "\n".join(roadmap)
    
    def _generate_difficulty_analysis(
        self,
        project_metrics: Dict[str, Any],
        file_metrics: List[Dict[str, Any]]
    ) -> str:
        """Generate difficulty analysis"""
        analysis = []
        
        difficulty = project_metrics['overall_difficulty']
        avg_complexity = project_metrics['avg_complexity']
        
        analysis.append(f"### æ•´ä½“éš¾åº¦ç­‰çº§: **{difficulty.upper()}**")
        analysis.append("")
        
        difficulty_info = self.difficulty_descriptions.get(difficulty, self.difficulty_descriptions['medium'])
        analysis.append(f"- **ä¸­æ–‡è¯´æ˜**: {difficulty_info['zh']}")
        analysis.append(f"- **English**: {difficulty_info['en']}")
        analysis.append("")
        
        analysis.append("### éš¾åº¦æ„æˆåˆ†æ")
        analysis.append("")
        analysis.append("| ç»´åº¦ | è¯„åˆ† | è¯´æ˜ |")
        analysis.append("|------|------|------|")
        
        # Code volume / ä»£ç é‡
        code_volume_score = min(10, project_metrics['total_lines'] / 1000)
        analysis.append(f"| ä»£ç é‡ | {code_volume_score:.1f}/10 | {project_metrics['total_lines']:,} è¡Œä»£ç  |")
        
        # Complexity / å¤æ‚åº¦
        complexity_score = min(10, avg_complexity)
        analysis.append(f"| å¤æ‚åº¦ | {complexity_score:.1f}/10 | å¹³å‡åœˆå¤æ‚åº¦ {avg_complexity:.1f} |")
        
        # Architecture / æ¶æ„
        arch_score = 5.0 + (project_metrics['total_classes'] / 20)
        analysis.append(f"| æ¶æ„è®¾è®¡ | {min(10, arch_score):.1f}/10 | {project_metrics['total_classes']} ä¸ªç±» |")
        
        # Dependencies / ä¾èµ–
        dep_score = 5.0
        analysis.append(f"| ä¾èµ–ç®¡ç† | {dep_score:.1f}/10 | ä¸­ç­‰å¤æ‚åº¦ |")
        
        analysis.append("")
        
        # Difficulty distribution
        # éš¾åº¦åˆ†å¸ƒ
        analysis.append("### æ–‡ä»¶éš¾åº¦åˆ†å¸ƒ")
        analysis.append("")
        
        # Count files by difficulty (we need to add this to file metrics)
        # æŒ‰éš¾åº¦ç»Ÿè®¡æ–‡ä»¶ï¼ˆéœ€è¦åœ¨æ–‡ä»¶æŒ‡æ ‡ä¸­æ·»åŠ ï¼‰
        easy_count = sum(1 for f in file_metrics if f['complexity_score'] <= 5)
        medium_count = sum(1 for f in file_metrics if 5 < f['complexity_score'] <= 10)
        hard_count = sum(1 for f in file_metrics if 10 < f['complexity_score'] <= 15)
        expert_count = sum(1 for f in file_metrics if f['complexity_score'] > 15)
        
        total = len(file_metrics)
        
        analysis.append("```")
        analysis.append(f"ç®€å• (Easy):    {'â–ˆ' * int(easy_count / total * 20) if total > 0 else ''} {easy_count} ä¸ªæ–‡ä»¶")
        analysis.append(f"ä¸­ç­‰ (Medium):  {'â–ˆ' * int(medium_count / total * 20) if total > 0 else ''} {medium_count} ä¸ªæ–‡ä»¶")
        analysis.append(f"å›°éš¾ (Hard):    {'â–ˆ' * int(hard_count / total * 20) if total > 0 else ''} {hard_count} ä¸ªæ–‡ä»¶")
        analysis.append(f"ä¸“å®¶ (Expert):  {'â–ˆ' * int(expert_count / total * 20) if total > 0 else ''} {expert_count} ä¸ªæ–‡ä»¶")
        analysis.append("```")
        
        return "\n".join(analysis)
    
    def _generate_tech_resources(self, tech_stack: List[str]) -> str:
        """Generate technology learning resources"""
        resources = []
        
        resource_map = {
            "Python/pip": "- [Pythonå®˜æ–¹æ–‡æ¡£](https://docs.python.org/zh-cn/3/)\n- [Pythonæ•™ç¨‹](https://www.runoob.com/python3/python3-tutorial.html)",
            "Node.js/npm": "- [Node.jså®˜æ–¹æ–‡æ¡£](https://nodejs.org/zh-cn/docs/)\n- [JavaScriptæ•™ç¨‹](https://javascript.info/)",
            "Java/Maven": "- [Javaå®˜æ–¹æ–‡æ¡£](https://docs.oracle.com/en/java/)\n- [Mavenæ•™ç¨‹](https://maven.apache.org/guides/)",
            "Java/Gradle": "- [Gradleå®˜æ–¹æ–‡æ¡£](https://docs.gradle.org/)\n- [Gradleæ•™ç¨‹](https://www.tutorialspoint.com/gradle/index.htm)",
            "Go": "- [Goå®˜æ–¹æ–‡æ¡£](https://go.dev/doc/)\n- [Goè¯­è¨€ä¹‹æ—…](https://tour.go-zh.org/)",
            "Rust/Cargo": "- [Rustå®˜æ–¹æ–‡æ¡£](https://www.rust-lang.org/zh-CN/learn)\n- [Rustç¨‹åºè®¾è®¡è¯­è¨€](https://kaisery.github.io/trpl-zh-cn/)"
        }
        
        for tech in tech_stack:
            if tech in resource_map:
                resources.append(f"**{tech}**:")
                resources.append(resource_map[tech])
                resources.append("")
        
        if not resources:
            resources.append("- é€šç”¨ç¼–ç¨‹èµ„æº: [GitHub](https://github.com)")
        
        return "\n".join(resources)
    
    def _generate_architecture_analysis(
        self,
        architecture: Dict[str, Any],
        file_metrics: List[Dict[str, Any]]
    ) -> str:
        """Generate architecture analysis"""
        analysis = []
        
        patterns = architecture.get('patterns', [])
        structure = architecture.get('structure', 'simple')
        
        analysis.append(f"### æ¶æ„ç±»å‹: **{structure.upper()}**")
        analysis.append("")
        
        if patterns:
            analysis.append("### æ£€æµ‹åˆ°çš„æ¶æ„æ¨¡å¼")
            analysis.append("")
            for pattern in patterns:
                analysis.append(f"- âœ… **{pattern}**")
            analysis.append("")
        
        analysis.append("### é¡¹ç›®ç»“æ„")
        analysis.append("")
        analysis.append("```")
        
        # Group files by directory
        # æŒ‰ç›®å½•åˆ†ç»„æ–‡ä»¶
        dir_structure = {}
        for f in file_metrics[:10]:  # Show top 10 files
            parts = Path(f['file_path']).parts
            if len(parts) > 1:
                dir_name = parts[-2] if len(parts) > 1 else "root"
                file_name = parts[-1]
                if dir_name not in dir_structure:
                    dir_structure[dir_name] = []
                dir_structure[dir_name].append(file_name)
        
        for dir_name, files in sorted(dir_structure.items()):
            analysis.append(f"ğŸ“ {dir_name}/")
            for file_name in files[:5]:  # Show top 5 files per directory
                analysis.append(f"  â”œâ”€ {file_name}")
            if len(files) > 5:
                analysis.append(f"  â””â”€ ... è¿˜æœ‰ {len(files) - 5} ä¸ªæ–‡ä»¶")
        
        analysis.append("```")
        
        return "\n".join(analysis)
    
    def _generate_pattern_analysis(self, file_metrics: List[Dict[str, Any]]) -> str:
        """Generate design pattern analysis"""
        analysis = []
        
        # This would need to be extracted from file metrics if we add pattern detection
        # è¿™éœ€è¦ä»æ–‡ä»¶æŒ‡æ ‡ä¸­æå–ï¼ˆå¦‚æœæˆ‘ä»¬æ·»åŠ äº†æ¨¡å¼æ£€æµ‹ï¼‰
        analysis.append("### å¸¸è§è®¾è®¡æ¨¡å¼")
        analysis.append("")
        analysis.append("ä»¥ä¸‹æ˜¯é¡¹ç›®ä¸­å¯èƒ½ä½¿ç”¨çš„è®¾è®¡æ¨¡å¼ï¼š")
        analysis.append("")
        
        # Check file names for pattern hints
        # æ£€æŸ¥æ–‡ä»¶åä¸­çš„æ¨¡å¼æç¤º
        detected_patterns = set()
        for f in file_metrics:
            file_name_lower = Path(f['file_path']).name.lower()
            
            if 'factory' in file_name_lower:
                detected_patterns.add('factory')
            if 'service' in file_name_lower:
                detected_patterns.add('service')
            if 'repository' in file_name_lower:
                detected_patterns.add('repository')
            if 'controller' in file_name_lower:
                detected_patterns.add('mvc')
            if 'observer' in file_name_lower or 'listener' in file_name_lower:
                detected_patterns.add('observer')
        
        if detected_patterns:
            for pattern in detected_patterns:
                if pattern in self.pattern_explanations:
                    info = self.pattern_explanations[pattern]
                    analysis.append(f"#### {pattern.upper()}")
                    analysis.append("")
                    analysis.append(f"- **è¯´æ˜**: {info['zh']}")
                    analysis.append(f"- **English**: {info['en']}")
                    analysis.append(f"- **ä½¿ç”¨åœºæ™¯**: {info['use_case']}")
                    analysis.append(f"- **éš¾åº¦**: {info['difficulty'].upper()}")
                    analysis.append("")
        else:
            analysis.append("- â„¹ï¸ æœªæ£€æµ‹åˆ°æ˜æ˜¾çš„è®¾è®¡æ¨¡å¼æ ‡è¯†")
            analysis.append("")
            analysis.append("è¿™å¹¶ä¸æ„å‘³ç€ä»£ç è´¨é‡ä¸å¥½ï¼Œå¯èƒ½ä½¿ç”¨äº†æ›´ç®€å•ç›´æ¥çš„å®ç°æ–¹å¼ã€‚")
        
        return "\n".join(analysis)
    
    def _generate_complexity_analysis(
        self,
        project_metrics: Dict[str, Any],
        file_metrics: List[Dict[str, Any]]
    ) -> str:
        """Generate complexity analysis"""
        analysis = []
        
        avg_complexity = project_metrics['avg_complexity']
        
        analysis.append(f"### æ•´ä½“å¤æ‚åº¦æŒ‡æ ‡")
        analysis.append("")
        analysis.append(f"- **å¹³å‡åœˆå¤æ‚åº¦**: {avg_complexity:.2f}")
        analysis.append(f"- **å¤æ‚åº¦è¯„çº§**: {'ğŸŸ¢ ä½' if avg_complexity <= 5 else 'ğŸŸ¡ ä¸­' if avg_complexity <= 10 else 'ğŸ”´ é«˜'}")
        analysis.append("")
        
        # Find most complex files
        # æ‰¾åˆ°æœ€å¤æ‚çš„æ–‡ä»¶
        complex_files = sorted(
            file_metrics,
            key=lambda f: f['complexity_score'],
            reverse=True
        )[:5]
        
        analysis.append("### æœ€å¤æ‚çš„æ–‡ä»¶ (Top 5)")
        analysis.append("")
        analysis.append("| æ–‡ä»¶ | å¤æ‚åº¦ | å¯ç»´æŠ¤æ€§ | å»ºè®® |")
        analysis.append("|------|--------|---------|------|")
        
        for f in complex_files:
            file_name = Path(f['file_path']).name
            complexity = f['complexity_score']
            maintainability = f['maintainability_index']
            
            suggestion = "âœ… è‰¯å¥½" if complexity <= 5 else "âš ï¸ è€ƒè™‘é‡æ„" if complexity <= 10 else "ğŸ”´ éœ€è¦é‡æ„"
            
            analysis.append(f"| `{file_name}` | {complexity:.1f} | {maintainability:.1f}/100 | {suggestion} |")
        
        analysis.append("")
        
        analysis.append("### å¤æ‚åº¦ç†è§£æŒ‡å—")
        analysis.append("")
        analysis.append("- **1-5**: ç®€å•æ˜“æ‡‚ï¼Œé€‚åˆæ–°æ‰‹å­¦ä¹ ")
        analysis.append("- **6-10**: ä¸­ç­‰å¤æ‚ï¼Œéœ€è¦ä¸€å®šç»éªŒ")
        analysis.append("- **11-20**: è¾ƒå¤æ‚ï¼Œéœ€è¦æ·±å…¥ç†è§£")
        analysis.append("- **20+**: éå¸¸å¤æ‚ï¼Œå»ºè®®é‡æ„")
        
        return "\n".join(analysis)
    
    def _generate_file_analysis(self, file_metrics: List[Dict[str, Any]]) -> str:
        """Generate file structure analysis"""
        analysis = []
        
        analysis.append("### æ–‡ä»¶ç»Ÿè®¡")
        analysis.append("")
        analysis.append("| æ–‡ä»¶ | è¡Œæ•° | å‡½æ•° | ç±» | å¤æ‚åº¦ |")
        analysis.append("|------|------|------|-----|--------|")
        
        # Show top 10 files by lines of code
        # æ˜¾ç¤ºä»£ç è¡Œæ•°æœ€å¤šçš„å‰10ä¸ªæ–‡ä»¶
        top_files = sorted(
            file_metrics,
            key=lambda f: f['lines_of_code'],
            reverse=True
        )[:10]
        
        for f in top_files:
            file_name = Path(f['file_path']).name
            analysis.append(f"| `{file_name}` | {f['lines_of_code']} | {f['num_functions']} | {f['num_classes']} | {f['complexity_score']:.1f} |")
        
        analysis.append("")
        
        if len(file_metrics) > 10:
            analysis.append(f"*... è¿˜æœ‰ {len(file_metrics) - 10} ä¸ªæ–‡ä»¶*")
        
        return "\n".join(analysis)
    
    def _generate_learning_recommendations(
        self,
        project_metrics: Dict[str, Any],
        file_metrics: List[Dict[str, Any]],
        summary: Dict[str, Any]
    ) -> str:
        """Generate personalized learning recommendations"""
        recommendations = []
        
        difficulty = project_metrics['overall_difficulty']
        avg_complexity = project_metrics['avg_complexity']
        
        recommendations.append("### å­¦ä¹ ç­–ç•¥å»ºè®®")
        recommendations.append("")
        
        if difficulty == "beginner":
            recommendations.append("#### ğŸ’š é€‚åˆåˆå­¦è€…")
            recommendations.append("")
            recommendations.append("è¿™ä¸ªé¡¹ç›®éå¸¸é€‚åˆä½œä¸ºå­¦ä¹ å…¥é—¨ï¼š")
            recommendations.append("")
            recommendations.append("1. **ä»ç®€å•æ–‡ä»¶å¼€å§‹**: å…ˆé˜…è¯»å¤æ‚åº¦ä½çš„æ–‡ä»¶")
            recommendations.append("2. **é€æ­¥æ·±å…¥**: ç†è§£ä¸€ä¸ªåŠŸèƒ½åå†å­¦ä¹ ä¸‹ä¸€ä¸ª")
            recommendations.append("3. **åŠ¨æ‰‹å®è·µ**: å°è¯•ä¿®æ”¹ä»£ç å¹¶è§‚å¯Ÿç»“æœ")
            recommendations.append("4. **æ·»åŠ æ³¨é‡Š**: ç”¨è‡ªå·±çš„è¯è§£é‡Šä»£ç é€»è¾‘")
        
        elif difficulty == "intermediate":
            recommendations.append("#### ğŸ’› ä¸­çº§å­¦ä¹ å»ºè®®")
            recommendations.append("")
            recommendations.append("1. **ç†è§£æ¶æ„**: å…ˆç†æ¸…æ¨¡å—é—´çš„å…³ç³»")
            recommendations.append("2. **å­¦ä¹ æ¨¡å¼**: è¯†åˆ«å’Œç†è§£ä½¿ç”¨çš„è®¾è®¡æ¨¡å¼")
            recommendations.append("3. **é˜…è¯»æµ‹è¯•**: å¦‚æœæœ‰æµ‹è¯•ä»£ç ï¼Œå®ƒä»¬æ˜¯å¾ˆå¥½çš„æ–‡æ¡£")
            recommendations.append("4. **é‡æ„ç»ƒä¹ **: å°è¯•ä¼˜åŒ–å¤æ‚çš„ä»£ç ")
        
        elif difficulty == "advanced":
            recommendations.append("#### ğŸ§¡ é«˜çº§å­¦ä¹ å»ºè®®")
            recommendations.append("")
            recommendations.append("1. **ç³»ç»Ÿæ€§å­¦ä¹ **: ä»æ¶æ„å±‚é¢ç†è§£æ•´ä½“è®¾è®¡")
            recommendations.append("2. **æ·±å…¥åˆ†æ**: ç ”ç©¶å…³é”®ç®—æ³•å’Œæ•°æ®ç»“æ„")
            recommendations.append("3. **æ€§èƒ½ä¼˜åŒ–**: æ€è€ƒä»£ç çš„æ€§èƒ½ç“¶é¢ˆ")
            recommendations.append("4. **æ‰©å±•åŠŸèƒ½**: å°è¯•æ·»åŠ æ–°åŠŸèƒ½")
        
        else:  # expert
            recommendations.append("#### â¤ï¸ ä¸“å®¶çº§å­¦ä¹ å»ºè®®")
            recommendations.append("")
            recommendations.append("1. **æ¶æ„æ¼”è¿›**: ç†è§£æ¶æ„çš„æ¼”åŒ–è¿‡ç¨‹")
            recommendations.append("2. **æœ€ä½³å®è·µ**: è¯†åˆ«å’Œå­¦ä¹ é«˜çº§ç¼–ç¨‹æŠ€å·§")
            recommendations.append("3. **æºç ç ”ç©¶**: æ·±å…¥ç ”ç©¶æ ¸å¿ƒå®ç°")
            recommendations.append("4. **è´¡çŒ®ä»£ç **: å‚ä¸é¡¹ç›®å¼€å‘å’Œä¼˜åŒ–")
        
        recommendations.append("")
        recommendations.append("### å­¦ä¹ èµ„æº")
        recommendations.append("")
        recommendations.append("- ğŸ“– é˜…è¯»é¡¹ç›®æ–‡æ¡£ï¼ˆå¦‚æœæœ‰ï¼‰")
        recommendations.append("- ğŸ¥ æœç´¢ç›¸å…³æŠ€æœ¯çš„è§†é¢‘æ•™ç¨‹")
        recommendations.append("- ğŸ’¬ åŠ å…¥ç›¸å…³æŠ€æœ¯ç¤¾åŒºè®¨è®º")
        recommendations.append("- ğŸ”§ ä½¿ç”¨è°ƒè¯•å™¨é€æ­¥æ‰§è¡Œä»£ç ")
        
        return "\n".join(recommendations)
    
    def _generate_quality_report(
        self,
        file_metrics: List[Dict[str, Any]],
        summary: Dict[str, Any]
    ) -> str:
        """Generate code quality report"""
        report = []
        
        total_smells = summary['total_code_smells']
        total_security = summary['total_security_issues']
        avg_maintainability = summary['avg_maintainability']
        health_score = summary['health_score']
        
        report.append(f"### æ•´ä½“å¥åº·åˆ†æ•°: {health_score}/100")
        report.append("")
        report.append(self._get_health_emoji(health_score))
        report.append("")
        
        report.append("### è´¨é‡æŒ‡æ ‡")
        report.append("")
        report.append("| æŒ‡æ ‡ | å€¼ | çŠ¶æ€ |")
        report.append("|------|----|----|")
        report.append(f"| å¹³å‡å¯ç»´æŠ¤æ€§ | {avg_maintainability:.1f}/100 | {self._get_status_emoji(avg_maintainability)} |")
        report.append(f"| ä»£ç å¼‚å‘³æ•°é‡ | {total_smells} | {self._get_smell_status(total_smells)} |")
        report.append(f"| å®‰å…¨é—®é¢˜æ•°é‡ | {total_security} | {self._get_security_status(total_security)} |")
        report.append("")
        
        # List code smells if any
        # åˆ—å‡ºä»£ç å¼‚å‘³ï¼ˆå¦‚æœæœ‰ï¼‰
        if total_smells > 0:
            report.append("### æ£€æµ‹åˆ°çš„ä»£ç å¼‚å‘³")
            report.append("")
            
            smell_count = 0
            for f in file_metrics:
                if f['code_smells']:
                    for smell in f['code_smells'][:3]:  # Show top 3 smells per file
                        file_name = Path(f['file_path']).name
                        report.append(f"- **{smell['type']}** in `{file_name}`: {smell['message']}")
                        smell_count += 1
                        if smell_count >= 10:  # Limit to 10 smells total
                            break
                if smell_count >= 10:
                    break
            
            if total_smells > 10:
                report.append(f"- *... è¿˜æœ‰ {total_smells - 10} ä¸ªé—®é¢˜*")
            report.append("")
        
        # List security issues if any
        # åˆ—å‡ºå®‰å…¨é—®é¢˜ï¼ˆå¦‚æœæœ‰ï¼‰
        if total_security > 0:
            report.append("### âš ï¸ æ£€æµ‹åˆ°çš„å®‰å…¨é—®é¢˜")
            report.append("")
            
            sec_count = 0
            for f in file_metrics:
                if f['security_issues']:
                    for issue in f['security_issues']:
                        file_name = Path(f['file_path']).name
                        report.append(f"- **{issue['severity'].upper()}** in `{file_name}`: {issue['message']}")
                        sec_count += 1
                        if sec_count >= 10:
                            break
                if sec_count >= 10:
                    break
            
            report.append("")
            report.append("**å»ºè®®**: ç«‹å³ä¿®å¤å®‰å…¨é—®é¢˜ï¼Œé¿å…æ½œåœ¨é£é™©ï¼")
            report.append("")
        
        report.append("### æ”¹è¿›å»ºè®®")
        report.append("")
        report.append(f"- {summary['recommendation']}")
        
        return "\n".join(report)
    
    def _get_health_emoji(self, score: float) -> str:
        """Get health emoji based on score"""
        if score >= 90:
            return "ğŸ‰ ä¼˜ç§€ï¼ä»£ç è´¨é‡éå¸¸é«˜"
        elif score >= 80:
            return "âœ… è‰¯å¥½ï¼ä»£ç è´¨é‡ä¸é”™"
        elif score >= 70:
            return "âš ï¸ ä¸€èˆ¬ï¼Œæœ‰æ”¹è¿›ç©ºé—´"
        elif score >= 60:
            return "ğŸ”´ è¾ƒå·®ï¼Œéœ€è¦é‡ç‚¹ä¼˜åŒ–"
        else:
            return "ğŸ’¥ ä¸¥é‡é—®é¢˜ï¼Œå»ºè®®å…¨é¢é‡æ„"
    
    def _get_status_emoji(self, value: float) -> str:
        """Get status emoji for maintainability"""
        if value >= 80:
            return "ğŸŸ¢ ä¼˜ç§€"
        elif value >= 60:
            return "ğŸŸ¡ è‰¯å¥½"
        else:
            return "ğŸ”´ éœ€æ”¹è¿›"
    
    def _get_smell_status(self, count: int) -> str:
        """Get status for code smells"""
        if count == 0:
            return "ğŸŸ¢ æ— "
        elif count <= 5:
            return "ğŸŸ¡ å°‘é‡"
        elif count <= 15:
            return "ğŸŸ  è¾ƒå¤š"
        else:
            return "ğŸ”´ å¾ˆå¤š"
    
    def _get_security_status(self, count: int) -> str:
        """Get status for security issues"""
        if count == 0:
            return "ğŸŸ¢ æ— "
        else:
            return f"ğŸ”´ {count} ä¸ª"
    
    def _generate_json_doc(self, results: Dict[str, Any], project_path: Path) -> Dict[str, Any]:
        """Generate JSON format documentation"""
        return {
            "project_name": results['project_metrics']['project_name'],
            "generated_at": datetime.now().isoformat(),
            "metrics": results['project_metrics'],
            "files": results['file_metrics'],
            "architecture": results['architecture'],
            "tech_stack": results['tech_stack'],
            "summary": results['summary']
        }

