"""
Multi-AI Orchestrator / å¤šAIç¼–æ’å™¨

Supports multiple AI models working concurrently with:
æ”¯æŒå¤šä¸ªAIæ¨¡å‹å¹¶å‘å·¥ä½œï¼ŒåŒ…å«:

- Intelligent model selection / æ™ºèƒ½æ¨¡å‹é€‰æ‹©
- Load balancing / è´Ÿè½½å‡è¡¡
- Automatic failover / è‡ªåŠ¨æ•…éšœè½¬ç§»
- Performance monitoring / æ€§èƒ½ç›‘æ§
- 5 different strategies / 5ç§ä¸åŒç­–ç•¥
"""

import asyncio
import time
from typing import List, Dict, Any, Optional
from collections import defaultdict
from loguru import logger
import random

from core.translators.base_translator import BaseTranslator
from core.translators.openai_translator import OpenAITranslator
from core.translators.anthropic_translator import AnthropicTranslator
from core.translators.local_translator import LocalTranslator
from core.translators.deepseek_translator import DeepSeekTranslator
from core.translators.gemini_translator import GeminiTranslator
from core.translators.qwen_translator import QwenTranslator


class MultiAIOrchestrator:
    """
    Multi-AI Orchestrator / å¤šAIç¼–æ’å™¨
    
    Features / åŠŸèƒ½:
    1. Multi-model concurrent translation / å¤šæ¨¡å‹å¹¶å‘ç¿»è¯‘
    2. Intelligent model selection / æ™ºèƒ½æ¨¡å‹é€‰æ‹©
    3. Load balancing / è´Ÿè½½å‡è¡¡
    4. Automatic failover / æ•…éšœè‡ªåŠ¨è½¬ç§»
    5. Performance monitoring / æ€§èƒ½ç›‘æ§
    
    Strategies / ç­–ç•¥:
    - quality_first: Auto-select best quality model / è´¨é‡ä¼˜å…ˆè‡ªåŠ¨é€‰æ‹©
    - fastest: Race mode - multiple AIs simultaneously / ç«é€Ÿæ¨¡å¼-å¤šAIåŒæ—¶
    - all_consensus: Vote on best result / æŠ•ç¥¨é€‰æ‹©æœ€ä½³ç»“æœ
    - round_robin: Load balancing / è´Ÿè½½å‡è¡¡è½®è¯¢
    - random: Random selection / éšæœºé€‰æ‹©
    """
    
    def __init__(self, config: Dict[str, Any] = None):
        self.config = config or {}
        
        # åˆå§‹åŒ–æ‰€æœ‰å¯ç”¨çš„ç¿»è¯‘å™¨
        self.translators = self._init_translators()
        
        # æ€§èƒ½ç»Ÿè®¡
        self.stats = defaultdict(lambda: {
            "success": 0,
            "failure": 0,
            "total_time": 0.0,
            "avg_time": 0.0
        })
        
        # ç­–ç•¥é…ç½®
        self.strategy = self.config.get("strategy", "round_robin")
        # ç­–ç•¥: "round_robin", "fastest", "random", "quality_first", "all_consensus"
        
        self.current_index = 0  # ç”¨äºè½®è¯¢
        
    def _init_translators(self) -> Dict[str, BaseTranslator]:
        """
        Initialize all available translators / åˆå§‹åŒ–æ‰€æœ‰å¯ç”¨çš„ç¿»è¯‘å™¨
        
        Tries to initialize translators for all AI models:
        å°è¯•åˆå§‹åŒ–æ‰€æœ‰AIæ¨¡å‹çš„ç¿»è¯‘å™¨:
        - GPT-4, GPT-4o (OpenAI)
        - Claude 3.5 Sonnet (Anthropic)
        - Gemini Pro (Google)
        - DeepSeek Coder (DeepSeek)
        - Qwen Coder (Alibaba)
        - CodeLlama (Local/Ollama)
        
        Returns:
            dict: Available translators / å¯ç”¨çš„ç¿»è¯‘å™¨å­—å…¸
        """
        translators = {}
        
        # å°è¯•åˆå§‹åŒ–å„ä¸ªç¿»è¯‘å™¨
        models = [
            ("gpt-4", lambda: OpenAITranslator("gpt-4-turbo")),
            ("gpt-4o", lambda: OpenAITranslator("gpt-4o")),
            ("claude-3.5", lambda: AnthropicTranslator("claude-3-5-sonnet-20241022")),
            ("deepseek", lambda: DeepSeekTranslator("deepseek-coder")),
            ("gemini", lambda: GeminiTranslator("gemini-pro")),
            ("qwen", lambda: QwenTranslator("qwen-coder-turbo")),
            ("codellama", lambda: LocalTranslator("codellama:13b")),
        ]
        
        for name, creator in models:
            try:
                translators[name] = creator()
                logger.info(f"âœ“ æˆåŠŸåˆå§‹åŒ–ç¿»è¯‘å™¨: {name}")
            except Exception as e:
                logger.warning(f"âœ— è·³è¿‡ç¿»è¯‘å™¨ {name}: {str(e)}")
        
        if not translators:
            raise ValueError("æ²¡æœ‰å¯ç”¨çš„ç¿»è¯‘å™¨ï¼è¯·è‡³å°‘é…ç½®ä¸€ä¸ª API Key")
        
        logger.info(f"å¯ç”¨ç¿»è¯‘å™¨: {list(translators.keys())}")
        return translators
    
    async def translate_with_strategy(
        self,
        source_code: str,
        source_language: str,
        target_language: str,
        context: Dict[str, Any] = None,
        preferred_models: List[str] = None
    ) -> str:
        """
        ä½¿ç”¨æŒ‡å®šç­–ç•¥ç¿»è¯‘ä»£ç 
        
        Args:
            source_code: æºä»£ç 
            source_language: æºè¯­è¨€
            target_language: ç›®æ ‡è¯­è¨€
            context: ä¸Šä¸‹æ–‡ä¿¡æ¯
            preferred_models: ä¼˜å…ˆä½¿ç”¨çš„æ¨¡å‹åˆ—è¡¨
            
        Returns:
            ç¿»è¯‘åçš„ä»£ç 
        """
        # è¿‡æ»¤å¯ç”¨æ¨¡å‹
        available_models = list(self.translators.keys())
        if preferred_models:
            available_models = [m for m in preferred_models if m in self.translators]
        
        if not available_models:
            raise ValueError("æ²¡æœ‰å¯ç”¨çš„ç¿»è¯‘æ¨¡å‹")
        
        # æ ¹æ®ç­–ç•¥é€‰æ‹©ç¿»è¯‘æ–¹å¼
        if self.strategy == "round_robin":
            return await self._translate_round_robin(
                source_code, source_language, target_language, context, available_models
            )
        
        elif self.strategy == "fastest":
            return await self._translate_race(
                source_code, source_language, target_language, context, available_models
            )
        
        elif self.strategy == "all_consensus":
            return await self._translate_consensus(
                source_code, source_language, target_language, context, available_models
            )
        
        elif self.strategy == "quality_first":
            return await self._translate_quality_first(
                source_code, source_language, target_language, context, available_models
            )
        
        else:  # random
            return await self._translate_random(
                source_code, source_language, target_language, context, available_models
            )
    
    async def _translate_round_robin(
        self,
        source_code: str,
        source_language: str,
        target_language: str,
        context: Dict[str, Any],
        models: List[str]
    ) -> str:
        """è½®è¯¢ç­–ç•¥ï¼šä¾æ¬¡ä½¿ç”¨ä¸åŒçš„æ¨¡å‹"""
        model_name = models[self.current_index % len(models)]
        self.current_index += 1
        
        return await self._translate_with_fallback(
            model_name, source_code, source_language, target_language, context, models
        )
    
    async def _translate_race(
        self,
        source_code: str,
        source_language: str,
        target_language: str,
        context: Dict[str, Any],
        models: List[str]
    ) -> str:
        """
        Racing strategy: Multiple models translate simultaneously, return fastest result
        ç«é€Ÿç­–ç•¥ï¼šå¤šä¸ªæ¨¡å‹åŒæ—¶ç¿»è¯‘ï¼Œè¿”å›æœ€å¿«çš„ç»“æœ
        
        This strategy launches multiple AI models in parallel and returns
        the first completed result, canceling other pending tasks.
        è¯¥ç­–ç•¥å¹¶è¡Œå¯åŠ¨å¤šä¸ªAIæ¨¡å‹ï¼Œè¿”å›ç¬¬ä¸€ä¸ªå®Œæˆçš„ç»“æœï¼Œå–æ¶ˆå…¶ä»–å¾…å¤„ç†ä»»åŠ¡ã€‚
        
        Pros / ä¼˜ç‚¹:
        - 3x faster speed / é€Ÿåº¦æå‡3å€
        - High availability / é«˜å¯ç”¨æ€§
        
        Cons / ç¼ºç‚¹:
        - Higher cost (multiple API calls) / æ›´é«˜æˆæœ¬ï¼ˆå¤šä¸ªAPIè°ƒç”¨ï¼‰
        - Higher network usage / æ›´é«˜ç½‘ç»œä½¿ç”¨
        
        Args:
            source_code: Source code to translate / è¦ç¿»è¯‘çš„æºä»£ç 
            source_language: Source programming language / æºç¼–ç¨‹è¯­è¨€
            target_language: Target programming language / ç›®æ ‡ç¼–ç¨‹è¯­è¨€
            context: Additional context (file path, classes, etc.) / é¢å¤–ä¸Šä¸‹æ–‡
            models: List of models to race / å‚ä¸ç«é€Ÿçš„æ¨¡å‹åˆ—è¡¨
            
        Returns:
            str: Translated code from fastest model / æœ€å¿«æ¨¡å‹ç¿»è¯‘çš„ä»£ç 
        """
        logger.info(f"ğŸ ç«é€Ÿæ¨¡å¼: ä½¿ç”¨ {len(models)} ä¸ªæ¨¡å‹åŒæ—¶ç¿»è¯‘")
        
        tasks = []
        for model_name in models:
            translator = self.translators[model_name]
            task = self._translate_with_stats(
                model_name, translator, source_code, source_language, target_language, context
            )
            tasks.append(task)
        
        # è¿”å›ç¬¬ä¸€ä¸ªå®Œæˆçš„ç»“æœ
        done, pending = await asyncio.wait(tasks, return_when=asyncio.FIRST_COMPLETED)
        
        # å–æ¶ˆå…¶ä»–ä»»åŠ¡
        for task in pending:
            task.cancel()
        
        # è·å–ç¬¬ä¸€ä¸ªå®Œæˆçš„ç»“æœ
        result = await list(done)[0]
        return result
    
    async def _translate_consensus(
        self,
        source_code: str,
        source_language: str,
        target_language: str,
        context: Dict[str, Any],
        models: List[str]
    ) -> str:
        """
        å…±è¯†ç­–ç•¥ï¼šå¤šä¸ªæ¨¡å‹åŒæ—¶ç¿»è¯‘ï¼Œç»¼åˆæ‰€æœ‰ç»“æœ
        é€‰æ‹©æœ€å¸¸è§çš„ç¿»è¯‘ç»“æœæˆ–è´¨é‡æœ€é«˜çš„
        """
        logger.info(f"ğŸ¤ å…±è¯†æ¨¡å¼: ä½¿ç”¨ {len(models)} ä¸ªæ¨¡å‹æŠ•ç¥¨")
        
        tasks = []
        for model_name in models[:3]:  # æœ€å¤šä½¿ç”¨3ä¸ªæ¨¡å‹ï¼Œé¿å…æˆæœ¬è¿‡é«˜
            translator = self.translators[model_name]
            task = self._translate_with_stats(
                model_name, translator, source_code, source_language, target_language, context
            )
            tasks.append(task)
        
        # ç­‰å¾…æ‰€æœ‰ç¿»è¯‘å®Œæˆ
        results = await asyncio.gather(*tasks, return_exceptions=True)
        
        # è¿‡æ»¤é”™è¯¯ç»“æœ
        valid_results = [r for r in results if not isinstance(r, Exception)]
        
        if not valid_results:
            raise ValueError("æ‰€æœ‰ç¿»è¯‘æ¨¡å‹éƒ½å¤±è´¥äº†")
        
        # ç®€å•ç­–ç•¥ï¼šè¿”å›ç¬¬ä¸€ä¸ªæˆåŠŸçš„ç»“æœ
        # TODO: å¯ä»¥å®ç°æ›´å¤æ‚çš„å…±è¯†ç®—æ³•ï¼Œå¦‚æŠ•ç¥¨ã€ç›¸ä¼¼åº¦æ¯”è¾ƒç­‰
        return valid_results[0]
    
    async def _translate_quality_first(
        self,
        source_code: str,
        source_language: str,
        target_language: str,
        context: Dict[str, Any],
        models: List[str]
    ) -> str:
        """è´¨é‡ä¼˜å…ˆç­–ç•¥ï¼šä¼˜å…ˆä½¿ç”¨è´¨é‡æœ€é«˜çš„æ¨¡å‹"""
        # æ¨¡å‹è´¨é‡æ’åº (æ ¹æ®ç»éªŒ)
        quality_order = ["claude-3.5", "gpt-4o", "gpt-4", "gemini", "deepseek", "qwen", "codellama"]
        
        # æŒ‰è´¨é‡æ’åºå¯ç”¨æ¨¡å‹
        sorted_models = sorted(
            models,
            key=lambda m: quality_order.index(m) if m in quality_order else 999
        )
        
        return await self._translate_with_fallback(
            sorted_models[0], source_code, source_language, target_language, context, sorted_models
        )
    
    async def _translate_random(
        self,
        source_code: str,
        source_language: str,
        target_language: str,
        context: Dict[str, Any],
        models: List[str]
    ) -> str:
        """éšæœºç­–ç•¥ï¼šéšæœºé€‰æ‹©ä¸€ä¸ªæ¨¡å‹"""
        model_name = random.choice(models)
        return await self._translate_with_fallback(
            model_name, source_code, source_language, target_language, context, models
        )
    
    async def _translate_with_fallback(
        self,
        primary_model: str,
        source_code: str,
        source_language: str,
        target_language: str,
        context: Dict[str, Any],
        fallback_models: List[str]
    ) -> str:
        """
        ä½¿ç”¨ä¸»æ¨¡å‹ç¿»è¯‘ï¼Œå¤±è´¥æ—¶è‡ªåŠ¨åˆ‡æ¢åˆ°å¤‡ç”¨æ¨¡å‹
        """
        models_to_try = [primary_model] + [m for m in fallback_models if m != primary_model]
        
        last_error = None
        for model_name in models_to_try:
            try:
                translator = self.translators[model_name]
                result = await self._translate_with_stats(
                    model_name, translator, source_code, source_language, target_language, context
                )
                return result
                
            except Exception as e:
                logger.warning(f"æ¨¡å‹ {model_name} ç¿»è¯‘å¤±è´¥: {str(e)}, å°è¯•ä¸‹ä¸€ä¸ª...")
                last_error = e
                continue
        
        # æ‰€æœ‰æ¨¡å‹éƒ½å¤±è´¥
        raise ValueError(f"æ‰€æœ‰ç¿»è¯‘æ¨¡å‹éƒ½å¤±è´¥äº†ã€‚æœ€åé”™è¯¯: {str(last_error)}")
    
    async def _translate_with_stats(
        self,
        model_name: str,
        translator: BaseTranslator,
        source_code: str,
        source_language: str,
        target_language: str,
        context: Dict[str, Any]
    ) -> str:
        """æ‰§è¡Œç¿»è¯‘å¹¶è®°å½•ç»Ÿè®¡ä¿¡æ¯"""
        start_time = time.time()
        
        try:
            result = await translator.translate(
                source_code, source_language, target_language, context
            )
            
            elapsed = time.time() - start_time
            
            # æ›´æ–°ç»Ÿè®¡
            self.stats[model_name]["success"] += 1
            self.stats[model_name]["total_time"] += elapsed
            total = self.stats[model_name]["success"] + self.stats[model_name]["failure"]
            self.stats[model_name]["avg_time"] = self.stats[model_name]["total_time"] / total
            
            logger.info(f"âœ“ {model_name} ç¿»è¯‘æˆåŠŸ (è€—æ—¶: {elapsed:.2f}s)")
            return result
            
        except Exception as e:
            elapsed = time.time() - start_time
            self.stats[model_name]["failure"] += 1
            logger.error(f"âœ— {model_name} ç¿»è¯‘å¤±è´¥: {str(e)} (è€—æ—¶: {elapsed:.2f}s)")
            raise
    
    def get_statistics(self) -> Dict[str, Any]:
        """è·å–æ€§èƒ½ç»Ÿè®¡"""
        return dict(self.stats)
    
    def get_available_models(self) -> List[str]:
        """è·å–æ‰€æœ‰å¯ç”¨çš„æ¨¡å‹"""
        return list(self.translators.keys())
    
    def set_strategy(self, strategy: str):
        """
        è®¾ç½®ç¿»è¯‘ç­–ç•¥
        
        Args:
            strategy: ç­–ç•¥åç§°
                - round_robin: è½®è¯¢ï¼ˆè´Ÿè½½å‡è¡¡ï¼‰
                - fastest: ç«é€Ÿï¼ˆå¤šä¸ªåŒæ—¶ç¿»è¯‘ï¼Œè¿”å›æœ€å¿«çš„ï¼‰
                - all_consensus: å…±è¯†ï¼ˆå¤šä¸ªç¿»è¯‘åç»¼åˆç»“æœï¼‰
                - quality_first: è´¨é‡ä¼˜å…ˆï¼ˆä¼˜å…ˆä½¿ç”¨é«˜è´¨é‡æ¨¡å‹ï¼‰
                - random: éšæœºé€‰æ‹©
        """
        valid_strategies = ["round_robin", "fastest", "all_consensus", "quality_first", "random"]
        
        if strategy not in valid_strategies:
            raise ValueError(f"æ— æ•ˆçš„ç­–ç•¥: {strategy}. å¯ç”¨ç­–ç•¥: {valid_strategies}")
        
        self.strategy = strategy
        logger.info(f"åˆ‡æ¢åˆ°ç­–ç•¥: {strategy}")

