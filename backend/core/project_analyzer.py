"""
Project Analyzer / é¡¹ç›®åˆ†æå™¨

Analyzes project structure for multiple programming languages.
è§£æå¤šç§ç¼–ç¨‹è¯­è¨€çš„é¡¹ç›®ç»“æ„ã€‚

Features / åŠŸèƒ½:
- Multi-language parsing / å¤šè¯­è¨€è§£æ
- Dependency extraction / ä¾èµ–æå–
- Project structure mapping / é¡¹ç›®ç»“æ„æ˜ å°„
- Build system detection / æ„å»ºç³»ç»Ÿæ£€æµ‹
"""

import os
from pathlib import Path
from typing import Dict, List, Any
import yaml
from loguru import logger

from models.schemas import ProjectInfo, FileInfo, SupportedLanguage

# Lazy import to avoid circular dependency / å»¶è¿Ÿå¯¼å…¥ä»¥é¿å…å¾ªç¯ä¾èµ–
_framework_detector = None

def get_framework_detector():
    """Get framework detector instance / è·å–æ¡†æ¶æ£€æµ‹å™¨å®ä¾‹"""
    global _framework_detector
    if _framework_detector is None:
        from .framework_detector import FrameworkDetector
        _framework_detector = FrameworkDetector()
    return _framework_detector


class ProjectAnalyzer:
    """é¡¹ç›®ç»“æ„åˆ†æå™¨"""
    
    def __init__(self):
        # åŠ è½½é…ç½®
        config_path = Path(__file__).parent.parent.parent / "config.yaml"
        with open(config_path, 'r', encoding='utf-8') as f:
            self.config = yaml.safe_load(f)
        
        # è¯­è¨€æ‰©å±•åæ˜ å°„
        self.language_extensions = self._build_extension_map()
        
        # æ’é™¤çš„ç›®å½•
        self.excluded_dirs = set(self.config.get('git', {}).get('excluded_dirs', []))
    
    def _build_extension_map(self) -> Dict[str, str]:
        """æ„å»ºæ–‡ä»¶æ‰©å±•ååˆ°è¯­è¨€çš„æ˜ å°„"""
        ext_map = {}
        for lang in self.config.get('supported_languages', []):
            lang_id = lang['id']
            for ext in lang.get('extensions', []):
                ext_map[ext] = lang_id
        return ext_map
    
    async def analyze(
        self,
        project_path: Path,
        language: SupportedLanguage
    ) -> ProjectInfo:
        """
        Analyze project structure including frameworks / åˆ†æé¡¹ç›®ç»“æ„ï¼ˆåŒ…æ‹¬æ¡†æ¶ï¼‰
        
        Args:
            project_path: Project path / é¡¹ç›®è·¯å¾„
            language: Source language / æºè¯­è¨€
            
        Returns:
            ProjectInfo: Project information / é¡¹ç›®ä¿¡æ¯
        """
        logger.info(f"ğŸ” å¼€å§‹åˆ†æé¡¹ç›®: {project_path}, è¯­è¨€: {language}")
        
        # Detect frameworks / æ£€æµ‹æ¡†æ¶
        logger.info("ğŸ“¦ æ£€æµ‹é¡¹ç›®æ¡†æ¶...")
        framework_detector = get_framework_detector()
        detected_frameworks = framework_detector.detect_frameworks(project_path)
        primary_framework = framework_detector.get_primary_framework()
        
        if primary_framework:
            logger.info(
                f"âœ… ä¸»è¦æ¡†æ¶: {primary_framework['name']} "
                f"(ç½®ä¿¡åº¦: {primary_framework['confidence']:.0%})"
            )
        
        # æ”¶é›†æ‰€æœ‰æºæ–‡ä»¶
        files = self._collect_source_files(project_path, language)
        
        # åˆ†ææ¯ä¸ªæ–‡ä»¶
        file_infos = []
        total_lines = 0
        
        for file_path in files:
            file_info = await self._analyze_file(file_path, language)
            file_infos.append(file_info)
            total_lines += file_info.lines
        
        # åˆ†æé¡¹ç›®ç»“æ„
        structure = self._analyze_structure(project_path, language)
        
        # Add frameworks info to structure / å°†æ¡†æ¶ä¿¡æ¯æ·»åŠ åˆ°ç»“æ„ä¸­
        structure['frameworks'] = {
            'detected': detected_frameworks,
            'primary': primary_framework,
            'count': len(detected_frameworks)
        }
        
        # åˆ†æä¾èµ–
        dependencies = await self._analyze_dependencies(project_path, language)
        
        project_info = ProjectInfo(
            name=project_path.name,
            language=language,
            total_files=len(file_infos),
            total_lines=total_lines,
            files=file_infos,
            dependencies=dependencies,
            structure=structure
        )
        
        logger.info(
            f"âœ… é¡¹ç›®åˆ†æå®Œæˆ: {len(file_infos)} ä¸ªæ–‡ä»¶, "
            f"{total_lines} è¡Œä»£ç , {len(detected_frameworks)} ä¸ªæ¡†æ¶"
        )
        
        return project_info
    
    def _collect_source_files(
        self,
        project_path: Path,
        language: SupportedLanguage
    ) -> List[Path]:
        """æ”¶é›†æºä»£ç æ–‡ä»¶"""
        files = []
        
        # è·å–è¯¥è¯­è¨€çš„æ‰©å±•å
        lang_config = next(
            (l for l in self.config['supported_languages'] if l['id'] == language.value),
            None
        )
        
        if not lang_config:
            logger.warning(f"æœªæ‰¾åˆ°è¯­è¨€é…ç½®: {language}")
            return files
        
        extensions = set(lang_config.get('extensions', []))
        
        # éå†ç›®å½•
        for root, dirs, filenames in os.walk(project_path):
            # è¿‡æ»¤æ’é™¤çš„ç›®å½•
            dirs[:] = [d for d in dirs if d not in self.excluded_dirs]
            
            # æ”¶é›†åŒ¹é…çš„æ–‡ä»¶
            for filename in filenames:
                file_ext = Path(filename).suffix
                if file_ext in extensions:
                    file_path = Path(root) / filename
                    files.append(file_path)
        
        logger.info(f"æ‰¾åˆ° {len(files)} ä¸ª {language} æºæ–‡ä»¶")
        return files
    
    async def _analyze_file(
        self,
        file_path: Path,
        language: SupportedLanguage
    ) -> FileInfo:
        """åˆ†æå•ä¸ªæ–‡ä»¶"""
        try:
            with open(file_path, 'r', encoding='utf-8', errors='ignore') as f:
                content = f.read()
            
            lines = content.count('\n') + 1
            size = file_path.stat().st_size
            
            # ä½¿ç”¨å¯¹åº”è¯­è¨€çš„è§£æå™¨
            parser = self._get_parser(language)
            parsed_info = parser.parse(content) if parser else {}
            
            return FileInfo(
                path=str(file_path),
                language=language.value,
                size=size,
                lines=lines,
                classes=parsed_info.get('classes', []),
                functions=parsed_info.get('functions', []),
                imports=parsed_info.get('imports', [])
            )
            
        except Exception as e:
            logger.warning(f"æ–‡ä»¶åˆ†æå¤±è´¥ {file_path}: {str(e)}")
            return FileInfo(
                path=str(file_path),
                language=language.value,
                size=0,
                lines=0
            )
    
    def _get_parser(self, language: SupportedLanguage):
        """è·å–è¯­è¨€è§£æå™¨"""
        # å¯¼å…¥å¯¹åº”çš„è§£æå™¨
        try:
            if language == SupportedLanguage.JAVA:
                from core.parsers.java_parser import JavaParser
                return JavaParser()
            elif language == SupportedLanguage.PYTHON:
                from core.parsers.python_parser import PythonParser
                return PythonParser()
            elif language == SupportedLanguage.JAVASCRIPT:
                from core.parsers.javascript_parser import JavaScriptParser
                return JavaScriptParser()
            # æ·»åŠ æ›´å¤šè¯­è¨€...
        except ImportError as e:
            logger.warning(f"è§£æå™¨å¯¼å…¥å¤±è´¥ {language}: {str(e)}")
        
        return None
    
    def _analyze_structure(
        self,
        project_path: Path,
        language: SupportedLanguage
    ) -> Dict[str, Any]:
        """åˆ†æé¡¹ç›®ç›®å½•ç»“æ„"""
        structure = {
            "root": str(project_path),
            "directories": [],
            "build_system": self._detect_build_system(project_path, language)
        }
        
        # æ„å»ºç›®å½•æ ‘
        for item in project_path.iterdir():
            if item.is_dir() and item.name not in self.excluded_dirs:
                structure["directories"].append(item.name)
        
        return structure
    
    def _detect_build_system(
        self,
        project_path: Path,
        language: SupportedLanguage
    ) -> str:
        """æ£€æµ‹æ„å»ºç³»ç»Ÿ"""
        if language == SupportedLanguage.JAVA:
            if (project_path / "pom.xml").exists():
                return "maven"
            elif (project_path / "build.gradle").exists():
                return "gradle"
        elif language == SupportedLanguage.PYTHON:
            if (project_path / "setup.py").exists():
                return "setuptools"
            elif (project_path / "pyproject.toml").exists():
                return "poetry"
        elif language == SupportedLanguage.JAVASCRIPT:
            if (project_path / "package.json").exists():
                return "npm"
        elif language == SupportedLanguage.GO:
            if (project_path / "go.mod").exists():
                return "go-modules"
        
        return "unknown"
    
    async def _analyze_dependencies(
        self,
        project_path: Path,
        language: SupportedLanguage
    ) -> Dict[str, str]:
        """åˆ†æé¡¹ç›®ä¾èµ–"""
        dependencies = {}
        
        try:
            if language == SupportedLanguage.JAVA:
                # è§£æ pom.xml æˆ– build.gradle
                pom_file = project_path / "pom.xml"
                if pom_file.exists():
                    dependencies = self._parse_maven_dependencies(pom_file)
                    
            elif language == SupportedLanguage.PYTHON:
                # è§£æ requirements.txt
                req_file = project_path / "requirements.txt"
                if req_file.exists():
                    dependencies = self._parse_requirements(req_file)
                    
            elif language == SupportedLanguage.JAVASCRIPT:
                # è§£æ package.json
                pkg_file = project_path / "package.json"
                if pkg_file.exists():
                    dependencies = self._parse_package_json(pkg_file)
                    
        except Exception as e:
            logger.warning(f"ä¾èµ–åˆ†æå¤±è´¥: {str(e)}")
        
        return dependencies
    
    def _parse_requirements(self, req_file: Path) -> Dict[str, str]:
        """è§£æ Python requirements.txt"""
        deps = {}
        with open(req_file, 'r') as f:
            for line in f:
                line = line.strip()
                if line and not line.startswith('#'):
                    if '==' in line:
                        name, version = line.split('==', 1)
                        deps[name.strip()] = version.strip()
                    else:
                        deps[line] = "latest"
        return deps
    
    def _parse_package_json(self, pkg_file: Path) -> Dict[str, str]:
        """è§£æ JavaScript package.json"""
        import json
        with open(pkg_file, 'r') as f:
            pkg_data = json.load(f)
        
        deps = {}
        deps.update(pkg_data.get('dependencies', {}))
        deps.update(pkg_data.get('devDependencies', {}))
        return deps
    
    def _parse_maven_dependencies(self, pom_file: Path) -> Dict[str, str]:
        """è§£æ Maven pom.xml (ç®€åŒ–ç‰ˆ)"""
        # è¿™é‡Œå¯ä»¥ä½¿ç”¨ XML è§£æåº“
        # ç®€åŒ–å®ç°
        return {}

