"""
Cost Estimator / æˆæœ¬ä¼°ç®—å™¨

Estimates the cost and time for code conversion before execution.
åœ¨æ‰§è¡Œå‰ä¼°ç®—ä»£ç è½¬æ¢çš„æˆæœ¬å’Œæ—¶é—´ã€‚

Features / åŠŸèƒ½:
- Cost estimation by AI model / æŒ‰AIæ¨¡å‹ä¼°ç®—æˆæœ¬
- Time estimation / æ—¶é—´ä¼°ç®—
- Alternative suggestions / æ›¿ä»£æ–¹æ¡ˆå»ºè®®
- Budget tracking / é¢„ç®—è¿½è¸ª
"""

from typing import Dict, List, Any, Optional
from dataclasses import dataclass
from datetime import datetime
from loguru import logger


@dataclass
class CostEstimate:
    """
    Cost estimation result / æˆæœ¬ä¼°ç®—ç»“æœ
    
    Attributes:
        total_tokens: Estimated total tokens / ä¼°ç®—çš„æ€»tokenæ•°
        input_tokens: Input tokens / è¾“å…¥tokenæ•°
        output_tokens: Output tokens / è¾“å‡ºtokenæ•°
        cost_usd: Estimated cost in USD / ä¼°ç®—æˆæœ¬ï¼ˆç¾å…ƒï¼‰
        time_minutes: Estimated time in minutes / ä¼°ç®—æ—¶é—´ï¼ˆåˆ†é’Ÿï¼‰
        ai_model: AI model used / ä½¿ç”¨çš„AIæ¨¡å‹
        alternative_options: Cheaper alternatives / æ›´ä¾¿å®œçš„æ›¿ä»£æ–¹æ¡ˆ
        savings_potential_usd: Potential savings / æ½œåœ¨èŠ‚çœé‡‘é¢
    """
    total_tokens: int
    input_tokens: int
    output_tokens: int
    cost_usd: float
    time_minutes: float
    ai_model: str
    alternative_options: List[Dict[str, Any]]
    savings_potential_usd: float


class CostEstimator:
    """
    Cost Estimator / æˆæœ¬ä¼°ç®—å™¨
    
    Provides cost and time estimates for code conversion.
    ä¸ºä»£ç è½¬æ¢æä¾›æˆæœ¬å’Œæ—¶é—´ä¼°ç®—ã€‚
    """
    
    # AI Model pricing (per 1K tokens) / AIæ¨¡å‹å®šä»·ï¼ˆæ¯1K tokensï¼‰
    # Updated as of 2024
    MODEL_PRICES = {
        "gpt-4": {
            "input": 0.03,
            "output": 0.06,
            "speed_factor": 1.0,
            "quality": 0.95
        },
        "gpt-4o": {
            "input": 0.005,
            "output": 0.015,
            "speed_factor": 1.5,
            "quality": 0.95
        },
        "claude-3.5-sonnet": {
            "input": 0.003,
            "output": 0.015,
            "speed_factor": 1.3,
            "quality": 0.96
        },
        "gemini-pro": {
            "input": 0.00025,
            "output": 0.0005,
            "speed_factor": 1.4,
            "quality": 0.88
        },
        "deepseek-coder": {
            "input": 0.0002,
            "output": 0.0002,
            "speed_factor": 1.0,
            "quality": 0.85
        },
        "qwen-coder": {
            "input": 0.0002,
            "output": 0.0002,
            "speed_factor": 1.1,
            "quality": 0.86
        },
        "codellama": {
            "input": 0.0,
            "output": 0.0,
            "speed_factor": 0.5,
            "quality": 0.75
        }
    }
    
    def __init__(self):
        """Initialize cost estimator / åˆå§‹åŒ–æˆæœ¬ä¼°ç®—å™¨"""
        self.conversion_history = []
    
    def estimate(
        self,
        lines_of_code: int,
        source_language: str,
        target_language: str,
        ai_model: str = "gpt-4o",
        strategy: str = "quality_first"
    ) -> CostEstimate:
        """
        Estimate conversion cost and time / ä¼°ç®—è½¬æ¢æˆæœ¬å’Œæ—¶é—´
        
        Calculation formula / è®¡ç®—å…¬å¼:
        - Average tokens per line: 10-15 (depends on language)
        - Translation requires: input tokens + output tokens
        - Output is typically 1.2x input size (code expansion)
        
        Args:
            lines_of_code: Number of lines of code / ä»£ç è¡Œæ•°
            source_language: Source language / æºè¯­è¨€
            target_language: Target language / ç›®æ ‡è¯­è¨€
            ai_model: AI model to use / ä½¿ç”¨çš„AIæ¨¡å‹
            strategy: Translation strategy / ç¿»è¯‘ç­–ç•¥
            
        Returns:
            CostEstimate: Cost estimation result / æˆæœ¬ä¼°ç®—ç»“æœ
        """
        # Get model pricing / è·å–æ¨¡å‹å®šä»·
        if ai_model not in self.MODEL_PRICES:
            logger.warning(f"Unknown model {ai_model}, using default pricing")
            ai_model = "gpt-4o"
        
        model_info = self.MODEL_PRICES[ai_model]
        
        # Calculate tokens / è®¡ç®—tokenæ•°
        # Different languages have different token densities
        # ä¸åŒè¯­è¨€æœ‰ä¸åŒçš„tokenå¯†åº¦
        token_multipliers = {
            "java": 12,      # Java is verbose
            "python": 10,
            "javascript": 11,
            "typescript": 12,
            "go": 10,
            "cpp": 13,
            "rust": 12
        }
        
        tokens_per_line = token_multipliers.get(source_language, 10)
        input_tokens = lines_of_code * tokens_per_line
        
        # Output is typically 1.2x input (code expansion during translation)
        # è¾“å‡ºé€šå¸¸æ˜¯è¾“å…¥çš„1.2å€ï¼ˆç¿»è¯‘è¿‡ç¨‹ä¸­çš„ä»£ç æ‰©å±•ï¼‰
        output_tokens = int(input_tokens * 1.2)
        
        total_tokens = input_tokens + output_tokens
        
        # Calculate cost / è®¡ç®—æˆæœ¬
        input_cost = (input_tokens / 1000) * model_info["input"]
        output_cost = (output_tokens / 1000) * model_info["output"]
        total_cost = input_cost + output_cost
        
        # Adjust for strategy / æ ¹æ®ç­–ç•¥è°ƒæ•´
        if strategy == "fastest":
            # Racing mode uses 3 models / ç«é€Ÿæ¨¡å¼ä½¿ç”¨3ä¸ªæ¨¡å‹
            total_cost *= 3
        elif strategy == "all_consensus":
            # Consensus mode uses 3 models / å…±è¯†æ¨¡å¼ä½¿ç”¨3ä¸ªæ¨¡å‹
            total_cost *= 3
        
        # Estimate time / ä¼°ç®—æ—¶é—´
        # Base: 2 minutes per 1000 lines / åŸºç¡€ï¼šæ¯1000è¡Œ2åˆ†é’Ÿ
        base_time = (lines_of_code / 1000) * 2
        speed_factor = model_info["speed_factor"]
        estimated_time = base_time / speed_factor
        
        # Find cheaper alternatives / æ‰¾åˆ°æ›´ä¾¿å®œçš„æ›¿ä»£æ–¹æ¡ˆ
        alternatives = self._find_alternatives(
            input_tokens,
            output_tokens,
            ai_model,
            total_cost
        )
        
        # Calculate savings potential / è®¡ç®—èŠ‚çœæ½œåŠ›
        if alternatives:
            cheapest_cost = min(alt["cost_usd"] for alt in alternatives)
            savings_potential = max(0, total_cost - cheapest_cost)
        else:
            savings_potential = 0.0
        
        estimate = CostEstimate(
            total_tokens=total_tokens,
            input_tokens=input_tokens,
            output_tokens=output_tokens,
            cost_usd=round(total_cost, 2),
            time_minutes=round(estimated_time, 1),
            ai_model=ai_model,
            alternative_options=alternatives,
            savings_potential_usd=round(savings_potential, 2)
        )
        
        logger.info(
            f"ğŸ’° Cost estimate: ${estimate.cost_usd} "
            f"({estimate.total_tokens:,} tokens, ~{estimate.time_minutes}min)"
        )
        
        return estimate
    
    def _find_alternatives(
        self,
        input_tokens: int,
        output_tokens: int,
        current_model: str,
        current_cost: float
    ) -> List[Dict[str, Any]]:
        """
        Find cheaper alternative models / æ‰¾åˆ°æ›´ä¾¿å®œçš„æ›¿ä»£æ¨¡å‹
        
        Args:
            input_tokens: Input tokens / è¾“å…¥tokenæ•°
            output_tokens: Output tokens / è¾“å‡ºtokenæ•°
            current_model: Current model / å½“å‰æ¨¡å‹
            current_cost: Current cost / å½“å‰æˆæœ¬
            
        Returns:
            List of alternative options / æ›¿ä»£æ–¹æ¡ˆåˆ—è¡¨
        """
        alternatives = []
        
        for model_name, model_info in self.MODEL_PRICES.items():
            if model_name == current_model:
                continue
            
            # Calculate cost for this model / è®¡ç®—æ­¤æ¨¡å‹çš„æˆæœ¬
            alt_cost = (
                (input_tokens / 1000) * model_info["input"] +
                (output_tokens / 1000) * model_info["output"]
            )
            
            if alt_cost < current_cost:
                savings = current_cost - alt_cost
                savings_percent = (savings / current_cost) * 100
                
                alternatives.append({
                    "model": model_name,
                    "cost_usd": round(alt_cost, 2),
                    "savings_usd": round(savings, 2),
                    "savings_percent": round(savings_percent, 1),
                    "quality_score": model_info["quality"],
                    "speed_factor": model_info["speed_factor"],
                    "recommendation": self._get_recommendation(
                        savings_percent,
                        model_info["quality"]
                    )
                })
        
        # Sort by savings / æŒ‰èŠ‚çœé‡‘é¢æ’åº
        alternatives.sort(key=lambda x: x["savings_usd"], reverse=True)
        
        return alternatives[:3]  # Return top 3 alternatives
    
    def _get_recommendation(self, savings_percent: float, quality: float) -> str:
        """
        Get recommendation text / è·å–æ¨èæ–‡æœ¬
        
        Args:
            savings_percent: Savings percentage / èŠ‚çœç™¾åˆ†æ¯”
            quality: Quality score / è´¨é‡åˆ†æ•°
            
        Returns:
            str: Recommendation text / æ¨èæ–‡æœ¬
        """
        if savings_percent > 80 and quality > 0.8:
            return "â­ å¼ºçƒˆæ¨èï¼šå¤§å¹…èŠ‚çœæˆæœ¬ï¼Œè´¨é‡ä»ç„¶å¾ˆå¥½"
        elif savings_percent > 50:
            return "âœ… æ¨èï¼šèŠ‚çœæˆæœ¬æ˜æ˜¾"
        elif quality > 0.9:
            return "ğŸ’ é«˜è´¨é‡é€‰é¡¹"
        else:
            return "âš–ï¸ å¹³è¡¡é€‰é¡¹"
    
    def estimate_batch(
        self,
        projects: List[Dict[str, Any]],
        ai_model: str = "gpt-4o"
    ) -> Dict[str, Any]:
        """
        Estimate cost for batch conversion / ä¼°ç®—æ‰¹é‡è½¬æ¢æˆæœ¬
        
        Args:
            projects: List of projects with metadata / é¡¹ç›®åˆ—è¡¨åŠå…ƒæ•°æ®
            ai_model: AI model to use / ä½¿ç”¨çš„AIæ¨¡å‹
            
        Returns:
            dict: Batch estimation result / æ‰¹é‡ä¼°ç®—ç»“æœ
        """
        total_cost = 0.0
        total_time = 0.0
        project_estimates = []
        
        for project in projects:
            estimate = self.estimate(
                lines_of_code=project["lines_of_code"],
                source_language=project["source_language"],
                target_language=project["target_language"],
                ai_model=ai_model
            )
            
            total_cost += estimate.cost_usd
            total_time += estimate.time_minutes
            
            project_estimates.append({
                "project_name": project.get("name", "Unknown"),
                "estimate": estimate
            })
        
        return {
            "total_projects": len(projects),
            "total_cost_usd": round(total_cost, 2),
            "total_time_minutes": round(total_time, 1),
            "total_time_hours": round(total_time / 60, 1),
            "average_cost_per_project": round(total_cost / len(projects), 2),
            "project_estimates": project_estimates
        }
    
    def track_actual_cost(
        self,
        task_id: str,
        actual_tokens: int,
        actual_cost: float,
        actual_time: float
    ):
        """
        Track actual conversion cost for learning / è¿½è¸ªå®é™…è½¬æ¢æˆæœ¬ç”¨äºå­¦ä¹ 
        
        Args:
            task_id: Task ID / ä»»åŠ¡ID
            actual_tokens: Actual tokens used / å®é™…ä½¿ç”¨çš„tokenæ•°
            actual_cost: Actual cost / å®é™…æˆæœ¬
            actual_time: Actual time / å®é™…æ—¶é—´
        """
        self.conversion_history.append({
            "task_id": task_id,
            "timestamp": datetime.now().isoformat(),
            "actual_tokens": actual_tokens,
            "actual_cost": actual_cost,
            "actual_time": actual_time
        })
        
        logger.info(
            f"ğŸ“Š Actual cost tracked: ${actual_cost} "
            f"({actual_tokens:,} tokens, {actual_time}min)"
        )
    
    def get_cost_report(self) -> Dict[str, Any]:
        """
        Get cost usage report / è·å–æˆæœ¬ä½¿ç”¨æŠ¥å‘Š
        
        Returns:
            dict: Cost report / æˆæœ¬æŠ¥å‘Š
        """
        if not self.conversion_history:
            return {
                "total_conversions": 0,
                "total_cost_usd": 0.0,
                "total_tokens": 0,
                "average_cost": 0.0
            }
        
        total_cost = sum(h["actual_cost"] for h in self.conversion_history)
        total_tokens = sum(h["actual_tokens"] for h in self.conversion_history)
        
        return {
            "total_conversions": len(self.conversion_history),
            "total_cost_usd": round(total_cost, 2),
            "total_tokens": total_tokens,
            "average_cost": round(total_cost / len(self.conversion_history), 2),
            "average_tokens": int(total_tokens / len(self.conversion_history)),
            "recent_conversions": self.conversion_history[-5:]  # Last 5
        }


# Global cost estimator instance / å…¨å±€æˆæœ¬ä¼°ç®—å™¨å®ä¾‹
_cost_estimator_instance = None

def get_cost_estimator() -> CostEstimator:
    """
    Get global cost estimator instance / è·å–å…¨å±€æˆæœ¬ä¼°ç®—å™¨å®ä¾‹
    
    Returns:
        CostEstimator: Cost estimator instance / æˆæœ¬ä¼°ç®—å™¨å®ä¾‹
    """
    global _cost_estimator_instance
    if _cost_estimator_instance is None:
        _cost_estimator_instance = CostEstimator()
    return _cost_estimator_instance

