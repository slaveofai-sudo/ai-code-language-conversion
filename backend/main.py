"""
AI Code Migration Platform - FastAPI Backend
AIä»£ç è¿ç§»å¹³å° - FastAPIåç«¯æœåŠ¡

This is the main entry point for the backend API server.
è¿™æ˜¯åç«¯APIæœåŠ¡å™¨çš„ä¸»å…¥å£æ–‡ä»¶ã€‚

Features / åŠŸèƒ½:
- RESTful API endpoints / REST APIç«¯ç‚¹
- Multi-AI orchestration / å¤šAIç¼–æ’
- Task management / ä»»åŠ¡ç®¡ç†
- Real-time progress tracking / å®æ—¶è¿›åº¦è¿½è¸ª
"""

from fastapi import FastAPI, HTTPException, UploadFile, File, BackgroundTasks, WebSocket, WebSocketDisconnect
from fastapi.middleware.cors import CORSMiddleware
from fastapi.responses import FileResponse, JSONResponse
from pydantic import BaseModel, HttpUrl
from typing import Optional, List
import uvicorn
from pathlib import Path
import os
import asyncio
from dotenv import load_dotenv

from core.git_manager import GitManager
from core.project_analyzer import ProjectAnalyzer
from core.translation_orchestrator import TranslationOrchestrator
from core.framework_mapper import FrameworkMapper
from core.runtime_configurator import RuntimeConfigurator
from core.cache_manager import get_cache_manager
from core.cost_estimator import get_cost_estimator
from core.test_generator import TestGenerator
from core.code_block_analyzer import CodeBlockAnalyzer
from core.code_inspector import CodeInspector
from core.learning_doc_generator import LearningDocGenerator
from core.code_optimizer import CodeOptimizer
from core.optimization_report_generator import OptimizationReportGenerator
from core.ai_model_manager import get_model_manager, AIModelConfig
from services.task_manager import TaskManager
from models.schemas import (
    ConversionRequest,
    ConversionResponse,
    TaskStatus,
    SupportedLanguage
)

# Load environment variables
load_dotenv()

# Initialize FastAPI app
app = FastAPI(
    title="AI Code Migration Platform",
    description="å¤šè¯­è¨€ä»£ç æ™ºèƒ½è½¬æ¢ç³»ç»Ÿ",
    version="1.0.0"
)

# CORS middleware
app.add_middleware(
    CORSMiddleware,
    allow_origins=os.getenv("ALLOWED_ORIGINS", "http://localhost:3000").split(","),
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)

# Initialize managers
git_manager = GitManager()
project_analyzer = ProjectAnalyzer()
translator = TranslationOrchestrator()
task_manager = TaskManager()
framework_mapper = FrameworkMapper()
runtime_configurator = RuntimeConfigurator()
cache_manager = get_cache_manager()
cost_estimator = get_cost_estimator()
test_generator = TestGenerator()
code_block_analyzer = CodeBlockAnalyzer()
code_inspector = CodeInspector()
learning_doc_generator = LearningDocGenerator()
code_optimizer = CodeOptimizer()
optimization_report_generator = OptimizationReportGenerator()
model_manager = get_model_manager()

# Create necessary directories
UPLOAD_DIR = Path(os.getenv("UPLOAD_DIR", "./data/uploads"))
OUTPUT_DIR = Path(os.getenv("OUTPUT_DIR", "./data/outputs"))
CACHE_DIR = Path(os.getenv("CACHE_DIR", "./data/cache"))

for dir_path in [UPLOAD_DIR, OUTPUT_DIR, CACHE_DIR]:
    dir_path.mkdir(parents=True, exist_ok=True)


@app.get("/")
async def root():
    """
    Health check endpoint / å¥åº·æ£€æŸ¥ç«¯ç‚¹
    
    Returns:
        dict: Service status information / æœåŠ¡çŠ¶æ€ä¿¡æ¯
    """
    return {
        "service": "AI Code Migration Platform",
        "status": "running",
        "version": "1.3.0"
    }


@app.get("/api/v1/languages")
async def get_supported_languages():
    """
    Get list of supported programming languages
    è·å–æ”¯æŒçš„ç¼–ç¨‹è¯­è¨€åˆ—è¡¨
    
    Returns:
        dict: List of supported languages with icons
              æ”¯æŒçš„è¯­è¨€åˆ—è¡¨ï¼ˆå«å›¾æ ‡ï¼‰
    """
    return {
        "languages": [
            {"id": "java", "name": "Java", "icon": "â˜•"},
            {"id": "python", "name": "Python", "icon": "ğŸ"},
            {"id": "javascript", "name": "JavaScript", "icon": "ğŸ“œ"},
            {"id": "typescript", "name": "TypeScript", "icon": "ğŸ“˜"},
            {"id": "go", "name": "Go", "icon": "ğŸ¹"},
            {"id": "cpp", "name": "C++", "icon": "âš™ï¸"},
            {"id": "rust", "name": "Rust", "icon": "ğŸ¦€"},
        ]
    }


@app.get("/api/v1/models")
async def get_ai_models():
    """
    Get list of available AI models
    è·å–å¯ç”¨çš„AIæ¨¡å‹åˆ—è¡¨
    
    Returns:
        dict: List of AI models with metadata (speed, quality, cost)
              AIæ¨¡å‹åˆ—è¡¨åŠå…ƒæ•°æ®ï¼ˆé€Ÿåº¦ã€è´¨é‡ã€æˆæœ¬ï¼‰
    """
    return {
        "models": [
            {
                "id": "gpt-4",
                "name": "GPT-4 Turbo",
                "provider": "OpenAI",
                "recommended": True,
                "speed": "medium",
                "quality": "excellent"
            },
            {
                "id": "gpt-4o",
                "name": "GPT-4o",
                "provider": "OpenAI",
                "recommended": True,
                "speed": "fast",
                "quality": "excellent"
            },
            {
                "id": "claude-3.5-sonnet",
                "name": "Claude 3.5 Sonnet",
                "provider": "Anthropic",
                "recommended": True,
                "speed": "fast",
                "quality": "excellent"
            },
            {
                "id": "codellama",
                "name": "CodeLlama 13B",
                "provider": "Local (Ollama)",
                "recommended": False,
                "speed": "slow",
                "quality": "good"
            }
        ]
    }


@app.get("/api/v1/frameworks")
async def get_supported_frameworks():
    """
    Get list of supported frameworks / è·å–æ”¯æŒçš„æ¡†æ¶åˆ—è¡¨
    
    Returns:
        dict: List of frameworks by language / æŒ‰è¯­è¨€åˆ†ç±»çš„æ¡†æ¶åˆ—è¡¨
    """
    return {
        "frameworks": {
            "java": [
                {"id": "spring-boot", "name": "Spring Boot", "type": "web", "recommended": True},
                {"id": "quarkus", "name": "Quarkus", "type": "web", "recommended": False},
                {"id": "micronaut", "name": "Micronaut", "type": "web", "recommended": False}
            ],
            "python": [
                {"id": "fastapi", "name": "FastAPI", "type": "web", "recommended": True},
                {"id": "django", "name": "Django", "type": "web", "recommended": True},
                {"id": "flask", "name": "Flask", "type": "web", "recommended": False}
            ],
            "javascript": [
                {"id": "express", "name": "Express", "type": "web", "recommended": True},
                {"id": "nestjs", "name": "NestJS", "type": "web", "recommended": True},
                {"id": "koa", "name": "Koa", "type": "web", "recommended": False}
            ],
            "typescript": [
                {"id": "nestjs", "name": "NestJS", "type": "web", "recommended": True},
                {"id": "express", "name": "Express (TS)", "type": "web", "recommended": True}
            ],
            "go": [
                {"id": "gin", "name": "Gin", "type": "web", "recommended": True},
                {"id": "echo", "name": "Echo", "type": "web", "recommended": True},
                {"id": "fiber", "name": "Fiber", "type": "web", "recommended": False}
            ]
        }
    }


@app.get("/api/v1/runtime-environments")
async def get_runtime_environments():
    """
    Get list of supported runtime environments / è·å–æ”¯æŒçš„è¿è¡Œç¯å¢ƒåˆ—è¡¨
    
    Returns:
        dict: List of runtime environments / è¿è¡Œç¯å¢ƒåˆ—è¡¨
    """
    return {
        "runtime_environments": [
            {
                "id": "docker",
                "name": "Docker",
                "description": "å®¹å™¨åŒ–éƒ¨ç½² / Containerized deployment",
                "icon": "ğŸ³",
                "recommended": True
            },
            {
                "id": "kubernetes",
                "name": "Kubernetes",
                "description": "K8sé›†ç¾¤éƒ¨ç½² / Kubernetes cluster",
                "icon": "â˜¸ï¸",
                "recommended": True
            },
            {
                "id": "aws",
                "name": "AWS",
                "description": "AWSäº‘å¹³å° / AWS cloud platform",
                "icon": "â˜ï¸",
                "recommended": False
            },
            {
                "id": "heroku",
                "name": "Heroku",
                "description": "Herokuå¹³å° / Heroku platform",
                "icon": "ğŸŸ£",
                "recommended": False
            },
            {
                "id": "systemd",
                "name": "Systemd",
                "description": "Linuxç³»ç»ŸæœåŠ¡ / Linux system service",
                "icon": "ğŸ§",
                "recommended": False
            }
        ]
    }


@app.post("/api/v1/frameworks/detect")
async def detect_frameworks(git_url: str, source_language: str):
    """
    Detect frameworks in a repository / æ£€æµ‹ä»“åº“ä¸­çš„æ¡†æ¶
    
    Args:
        git_url: Git repository URL / Gitä»“åº“URL
        source_language: Source language / æºè¯­è¨€
        
    Returns:
        dict: Detected frameworks / æ£€æµ‹åˆ°çš„æ¡†æ¶
    """
    try:
        # Clone repository temporarily / ä¸´æ—¶å…‹éš†ä»“åº“
        import tempfile
        with tempfile.TemporaryDirectory() as temp_dir:
            temp_path = Path(temp_dir)
            await git_manager.clone_repository(git_url, temp_path)
            
            # Detect frameworks / æ£€æµ‹æ¡†æ¶
            from core.framework_detector import FrameworkDetector
            detector = FrameworkDetector()
            detected = detector.detect_frameworks(temp_path)
            
            return {
                "success": True,
                "detected_frameworks": detected,
                "count": len(detected)
            }
    except Exception as e:
        raise HTTPException(status_code=500, detail=str(e))


@app.post("/api/v1/frameworks/suggest")
async def suggest_target_framework(
    source_framework: str,
    source_language: str,
    target_language: str
):
    """
    Suggest compatible target frameworks / å»ºè®®å…¼å®¹çš„ç›®æ ‡æ¡†æ¶
    
    Args:
        source_framework: Source framework / æºæ¡†æ¶
        source_language: Source language / æºè¯­è¨€
        target_language: Target language / ç›®æ ‡è¯­è¨€
        
    Returns:
        dict: Suggested target frameworks / å»ºè®®çš„ç›®æ ‡æ¡†æ¶
    """
    suggestions = framework_mapper.get_compatible_frameworks(
        source_framework,
        source_language,
        target_language
    )
    
    return {
        "success": True,
        "source_framework": source_framework,
        "target_language": target_language,
        "suggestions": suggestions
    }


@app.post("/api/v1/estimate")
async def estimate_conversion_cost(
    lines_of_code: int,
    source_language: str,
    target_language: str,
    ai_model: str = "gpt-4o",
    strategy: str = "quality_first"
):
    """
    Estimate conversion cost and time / ä¼°ç®—è½¬æ¢æˆæœ¬å’Œæ—¶é—´
    
    Args:
        lines_of_code: Number of lines of code / ä»£ç è¡Œæ•°
        source_language: Source language / æºè¯­è¨€
        target_language: Target language / ç›®æ ‡è¯­è¨€
        ai_model: AI model to use / ä½¿ç”¨çš„AIæ¨¡å‹
        strategy: Translation strategy / ç¿»è¯‘ç­–ç•¥
        
    Returns:
        dict: Cost estimation / æˆæœ¬ä¼°ç®—
    """
    estimate = cost_estimator.estimate(
        lines_of_code=lines_of_code,
        source_language=source_language,
        target_language=target_language,
        ai_model=ai_model,
        strategy=strategy
    )
    
    return {
        "success": True,
        "estimate": {
            "total_tokens": estimate.total_tokens,
            "input_tokens": estimate.input_tokens,
            "output_tokens": estimate.output_tokens,
            "cost_usd": estimate.cost_usd,
            "time_minutes": estimate.time_minutes,
            "ai_model": estimate.ai_model,
            "alternative_options": estimate.alternative_options,
            "savings_potential_usd": estimate.savings_potential_usd
        },
        "recommendations": {
            "cheapest": estimate.alternative_options[0] if estimate.alternative_options else None,
            "message": f"æ‚¨å¯ä»¥é€šè¿‡ä½¿ç”¨ {estimate.alternative_options[0]['model']} èŠ‚çœ ${estimate.savings_potential_usd}" if estimate.alternative_options else "å½“å‰å·²æ˜¯æœ€ä¼˜é€‰æ‹©"
        }
    }


@app.get("/api/v1/cost/report")
async def get_cost_report():
    """
    Get cost usage report / è·å–æˆæœ¬ä½¿ç”¨æŠ¥å‘Š
    
    Returns:
        dict: Cost report / æˆæœ¬æŠ¥å‘Š
    """
    report = cost_estimator.get_cost_report()
    return {
        "success": True,
        "report": report
    }


@app.get("/api/v1/cache/stats")
async def get_cache_stats():
    """
    Get cache statistics / è·å–ç¼“å­˜ç»Ÿè®¡
    
    Returns:
        dict: Cache statistics / ç¼“å­˜ç»Ÿè®¡
    """
    stats = cache_manager.get_stats()
    cache_size = await cache_manager.get_cache_size()
    
    return {
        "success": True,
        "stats": {
            **stats,
            "total_cached_items": cache_size
        }
    }


@app.post("/api/v1/cache/clear")
async def clear_cache():
    """
    Clear all cache / æ¸…ç©ºæ‰€æœ‰ç¼“å­˜
    
    Returns:
        dict: Success status / æˆåŠŸçŠ¶æ€
    """
    success = await cache_manager.clear_all()
    return {
        "success": success,
        "message": "ç¼“å­˜å·²æ¸…ç©º" if success else "æ¸…ç©ºç¼“å­˜å¤±è´¥"
    }


@app.websocket("/ws/task/{task_id}")
async def websocket_task_progress(websocket: WebSocket, task_id: str):
    """
    WebSocket endpoint for real-time task progress
    WebSocketç«¯ç‚¹ç”¨äºå®æ—¶ä»»åŠ¡è¿›åº¦
    
    Args:
        websocket: WebSocket connection / WebSocketè¿æ¥
        task_id: Task ID / ä»»åŠ¡ID
    """
    await websocket.accept()
    
    try:
        while True:
            # Get task status / è·å–ä»»åŠ¡çŠ¶æ€
            status = task_manager.get_task(task_id)
            
            if not status:
                await websocket.send_json({
                    "error": "Task not found",
                    "task_id": task_id
                })
                break
            
            # Send progress update / å‘é€è¿›åº¦æ›´æ–°
            await websocket.send_json({
                "task_id": task_id,
                "status": status.get("status"),
                "progress": status.get("progress", 0),
                "current_file": status.get("current_file", ""),
                "total_files": status.get("total_files", 0),
                "completed_files": status.get("completed_files", 0),
                "message": status.get("message", "Processing..."),
                "elapsed_time": status.get("elapsed_time", 0),
                "estimated_remaining": status.get("estimated_remaining", 0)
            })
            
            # Check if task is completed or failed / æ£€æŸ¥ä»»åŠ¡æ˜¯å¦å®Œæˆæˆ–å¤±è´¥
            if status.get("status") in ["completed", "failed", "cancelled"]:
                await websocket.send_json({
                    "task_id": task_id,
                    "status": status.get("status"),
                    "progress": 100 if status.get("status") == "completed" else status.get("progress", 0),
                    "message": "è½¬æ¢å®Œæˆ!" if status.get("status") == "completed" else "è½¬æ¢å¤±è´¥",
                    "result_url": status.get("result_url"),
                    "error": status.get("error")
                })
                break
            
            # Wait before next update / ç­‰å¾…ä¸‹æ¬¡æ›´æ–°
            await asyncio.sleep(1)
            
    except WebSocketDisconnect:
        logger.info(f"WebSocket disconnected for task {task_id}")
    except Exception as e:
        logger.error(f"WebSocket error: {e}")
        try:
            await websocket.send_json({
                "error": str(e),
                "task_id": task_id
            })
        except:
            pass


@app.post("/api/v1/convert")
async def convert_code(
    request: ConversionRequest,
    background_tasks: BackgroundTasks
):
    """
    Submit code conversion task / æäº¤ä»£ç è½¬æ¢ä»»åŠ¡
    
    Supports two input methods / æ”¯æŒä¸¤ç§è¾“å…¥æ–¹å¼:
    1. Git URL: Pull from remote repository / ç›´æ¥æ‹‰å–è¿œç¨‹ä»“åº“
    2. Upload: Upload ZIP file (via separate endpoint) / ä¸Šä¼ ZIPæ–‡ä»¶ï¼ˆé€šè¿‡å•ç‹¬ç«¯ç‚¹ï¼‰
    
    Args:
        request: Conversion request with source/target language and AI model
                 è½¬æ¢è¯·æ±‚ï¼ˆå«æºè¯­è¨€ã€ç›®æ ‡è¯­è¨€å’ŒAIæ¨¡å‹ï¼‰
        background_tasks: FastAPI background tasks for async execution
                         FastAPIåå°ä»»åŠ¡ç”¨äºå¼‚æ­¥æ‰§è¡Œ
    
    Returns:
        ConversionResponse: Task ID and status / ä»»åŠ¡IDå’ŒçŠ¶æ€
    """
    try:
        # åˆ›å»ºä»»åŠ¡
        task_id = task_manager.create_task(
            source_language=request.source_language,
            target_language=request.target_language,
            ai_model=request.ai_model
        )
        
        # åœ¨åå°æ‰§è¡Œè½¬æ¢
        background_tasks.add_task(
            execute_conversion,
            task_id=task_id,
            request=request
        )
        
        return ConversionResponse(
            task_id=task_id,
            status="queued",
            message="è½¬æ¢ä»»åŠ¡å·²åˆ›å»ºï¼Œæ­£åœ¨å¤„ç†ä¸­..."
        )
        
    except Exception as e:
        raise HTTPException(status_code=500, detail=str(e))


@app.post("/api/v1/upload")
async def upload_project(
    file: UploadFile = File(...),
    source_language: str = "java",
    target_language: str = "python",
    ai_model: str = "gpt-4"
):
    """ä¸Šä¼ é¡¹ç›®ZIPæ–‡ä»¶å¹¶å¼€å§‹è½¬æ¢"""
    try:
        # ä¿å­˜ä¸Šä¼ çš„æ–‡ä»¶
        upload_path = UPLOAD_DIR / f"{file.filename}"
        
        with open(upload_path, "wb") as f:
            content = await file.read()
            f.write(content)
        
        # åˆ›å»ºè½¬æ¢è¯·æ±‚
        request = ConversionRequest(
            source_type="upload",
            upload_path=str(upload_path),
            source_language=source_language,
            target_language=target_language,
            ai_model=ai_model
        )
        
        # åˆ›å»ºä»»åŠ¡
        task_id = task_manager.create_task(
            source_language=source_language,
            target_language=target_language,
            ai_model=ai_model
        )
        
        # å¼‚æ­¥æ‰§è¡Œ
        background_tasks = BackgroundTasks()
        background_tasks.add_task(execute_conversion, task_id, request)
        
        return {
            "task_id": task_id,
            "status": "processing",
            "message": f"æ–‡ä»¶ {file.filename} ä¸Šä¼ æˆåŠŸï¼Œå¼€å§‹è½¬æ¢..."
        }
        
    except Exception as e:
        raise HTTPException(status_code=500, detail=f"ä¸Šä¼ å¤±è´¥: {str(e)}")


@app.get("/api/v1/tasks/{task_id}")
async def get_task_status(task_id: str):
    """æŸ¥è¯¢ä»»åŠ¡çŠ¶æ€"""
    try:
        status = task_manager.get_task_status(task_id)
        
        if not status:
            raise HTTPException(status_code=404, detail="ä»»åŠ¡ä¸å­˜åœ¨")
        
        return status
        
    except HTTPException:
        raise
    except Exception as e:
        raise HTTPException(status_code=500, detail=str(e))


@app.get("/api/v1/tasks/{task_id}/download")
async def download_result(task_id: str):
    """ä¸‹è½½è½¬æ¢ç»“æœ"""
    try:
        status = task_manager.get_task_status(task_id)
        
        if not status:
            raise HTTPException(status_code=404, detail="ä»»åŠ¡ä¸å­˜åœ¨")
        
        if status["status"] != "completed":
            raise HTTPException(status_code=400, detail="ä»»åŠ¡å°šæœªå®Œæˆ")
        
        output_file = status.get("output_file")
        if not output_file or not Path(output_file).exists():
            raise HTTPException(status_code=404, detail="è¾“å‡ºæ–‡ä»¶ä¸å­˜åœ¨")
        
        return FileResponse(
            output_file,
            media_type="application/zip",
            filename=Path(output_file).name
        )
        
    except HTTPException:
        raise
    except Exception as e:
        raise HTTPException(status_code=500, detail=str(e))


@app.get("/api/v1/tasks")
async def list_tasks(limit: int = 20, offset: int = 0):
    """åˆ—å‡ºæ‰€æœ‰ä»»åŠ¡"""
    try:
        tasks = task_manager.list_tasks(limit=limit, offset=offset)
        return {"tasks": tasks, "total": len(tasks)}
    except Exception as e:
        raise HTTPException(status_code=500, detail=str(e))


async def execute_conversion(task_id: str, request: ConversionRequest):
    """
    Execute code conversion workflow / æ‰§è¡Œä»£ç è½¬æ¢çš„æ ¸å¿ƒæµç¨‹
    
    This is the main conversion pipeline that:
    è¿™æ˜¯ä¸»è¦çš„è½¬æ¢æµç¨‹ï¼ŒåŒ…æ‹¬:
    
    1. Fetches source code (Git clone or extract ZIP) / è·å–æºä»£ç ï¼ˆGitå…‹éš†æˆ–è§£å‹ZIPï¼‰
    2. Analyzes project structure / åˆ†æé¡¹ç›®ç»“æ„
    3. Translates code using AI models / ä½¿ç”¨AIæ¨¡å‹ç¿»è¯‘ä»£ç 
    4. Generates target project / ç”Ÿæˆç›®æ ‡é¡¹ç›®
    5. Packages output as ZIP / æ‰“åŒ…è¾“å‡ºä¸ºZIP
    
    Args:
        task_id: Unique task identifier / å”¯ä¸€ä»»åŠ¡æ ‡è¯†ç¬¦
        request: Conversion request details / è½¬æ¢è¯·æ±‚è¯¦æƒ…
    """
    try:
        # æ›´æ–°ä»»åŠ¡çŠ¶æ€
        task_manager.update_task(task_id, status="processing", progress=0)
        
        # Step 1: è·å–æºä»£ç 
        task_manager.update_task(task_id, progress=10, stage="è·å–æºä»£ç ...")
        
        if request.source_type == "git":
            # å…‹éš†Gitä»“åº“
            source_dir = await git_manager.clone_repository(
                request.git_url,
                UPLOAD_DIR / task_id
            )
        else:
            # è§£å‹ä¸Šä¼ çš„æ–‡ä»¶
            source_dir = await extract_upload(request.upload_path, task_id)
        
        # Step 2: åˆ†æé¡¹ç›®ç»“æ„
        task_manager.update_task(task_id, progress=20, stage="åˆ†æé¡¹ç›®ç»“æ„...")
        
        project_info = await project_analyzer.analyze(
            source_dir,
            request.source_language
        )
        
        # Step 3: AIç¿»è¯‘
        task_manager.update_task(task_id, progress=30, stage="AIç¿»è¯‘ä¸­...")
        
        translated_files = await translator.translate_project(
            project_info=project_info,
            source_language=request.source_language,
            target_language=request.target_language,
            ai_model=request.ai_model,
            task_id=task_id,
            progress_callback=lambda p: task_manager.update_task(
                task_id, progress=30 + int(p * 0.5)
            )
        )
        
        # Step 4: ç”Ÿæˆç›®æ ‡é¡¹ç›®
        task_manager.update_task(task_id, progress=80, stage="ç”Ÿæˆé¡¹ç›®æ–‡ä»¶...")
        
        output_dir = OUTPUT_DIR / task_id
        await translator.generate_project(
            translated_files,
            output_dir,
            request.target_language
        )
        
        # Step 5: æ‰“åŒ…è¾“å‡º
        task_manager.update_task(task_id, progress=90, stage="æ‰“åŒ…è¾“å‡º...")
        
        output_zip = await create_zip(output_dir, task_id)
        
        # å®Œæˆ
        task_manager.update_task(
            task_id,
            status="completed",
            progress=100,
            stage="è½¬æ¢å®Œæˆï¼",
            output_file=str(output_zip),
            result={
                "total_files": len(translated_files),
                "source_language": request.source_language,
                "target_language": request.target_language
            }
        )
        
    except Exception as e:
        # å¤±è´¥
        task_manager.update_task(
            task_id,
            status="failed",
            error=str(e)
        )


async def extract_upload(upload_path: str, task_id: str) -> Path:
    """è§£å‹ä¸Šä¼ çš„ZIPæ–‡ä»¶"""
    import zipfile
    
    extract_dir = UPLOAD_DIR / task_id
    extract_dir.mkdir(parents=True, exist_ok=True)
    
    with zipfile.ZipFile(upload_path, 'r') as zip_ref:
        zip_ref.extractall(extract_dir)
    
    return extract_dir


async def create_zip(directory: Path, task_id: str) -> Path:
    """åˆ›å»ºè¾“å‡ºZIPæ–‡ä»¶"""
    import zipfile
    
    output_zip = OUTPUT_DIR / f"{task_id}.zip"
    
    with zipfile.ZipFile(output_zip, 'w', zipfile.ZIP_DEFLATED) as zipf:
        for file_path in directory.rglob('*'):
            if file_path.is_file():
                zipf.write(
                    file_path,
                    file_path.relative_to(directory)
                )
    
    return output_zip


@app.post("/api/v1/generate-tests")
async def generate_tests(
    source_file: str,
    target_language: str,
    framework: Optional[str] = None
):
    """
    Generate unit tests for converted code
    ä¸ºè½¬æ¢åçš„ä»£ç ç”Ÿæˆå•å…ƒæµ‹è¯•
    
    Args:
        source_file: Path to converted source file / è½¬æ¢åçš„æºæ–‡ä»¶è·¯å¾„
        target_language: Target programming language / ç›®æ ‡ç¼–ç¨‹è¯­è¨€
        framework: Optional framework name / å¯é€‰çš„æ¡†æ¶åç§°
    
    Returns:
        dict: Generated test code and metadata / ç”Ÿæˆçš„æµ‹è¯•ä»£ç å’Œå…ƒæ•°æ®
    """
    try:
        source_path = Path(source_file)
        
        if not source_path.exists():
            raise HTTPException(status_code=404, detail=f"Source file not found: {source_file}")
        
        # Generate tests
        # ç”Ÿæˆæµ‹è¯•
        result = test_generator.generate_tests(
            source_file=source_path,
            target_language=target_language,
            framework=framework
        )
        
        # Save test file
        # ä¿å­˜æµ‹è¯•æ–‡ä»¶
        if result["status"] == "success":
            test_file_path = source_path.parent / "tests" / result["test_file_name"]
            test_file_path.parent.mkdir(parents=True, exist_ok=True)
            
            with open(test_file_path, 'w', encoding='utf-8') as f:
                f.write(result["test_code"])
            
            result["test_file_path"] = str(test_file_path)
        
        return JSONResponse(content={
            "status": "success",
            "result": result
        })
        
    except Exception as e:
        raise HTTPException(status_code=500, detail=str(e))


@app.post("/api/v1/analyze-blocks")
async def analyze_code_blocks(
    source_file: str,
    target_file: str,
    source_language: str,
    target_language: str,
    source_framework: Optional[str] = None,
    target_framework: Optional[str] = None,
    generate_report: bool = True
):
    """
    Analyze code migration at block level
    åœ¨ä»£ç å—çº§åˆ«åˆ†æä»£ç è¿ç§»
    
    Args:
        source_file: Path to source file / æºæ–‡ä»¶è·¯å¾„
        target_file: Path to target file / ç›®æ ‡æ–‡ä»¶è·¯å¾„
        source_language: Source programming language / æºç¼–ç¨‹è¯­è¨€
        target_language: Target programming language / ç›®æ ‡ç¼–ç¨‹è¯­è¨€
        source_framework: Source framework (optional) / æºæ¡†æ¶ï¼ˆå¯é€‰ï¼‰
        target_framework: Target framework (optional) / ç›®æ ‡æ¡†æ¶ï¼ˆå¯é€‰ï¼‰
        generate_report: Generate Markdown report / ç”ŸæˆMarkdownæŠ¥å‘Š
    
    Returns:
        dict: Code block analysis results / ä»£ç å—åˆ†æç»“æœ
    """
    try:
        source_path = Path(source_file)
        target_path = Path(target_file)
        
        if not source_path.exists():
            raise HTTPException(status_code=404, detail=f"Source file not found: {source_file}")
        
        if not target_path.exists():
            raise HTTPException(status_code=404, detail=f"Target file not found: {target_file}")
        
        # Analyze migration
        # åˆ†æè¿ç§»
        analysis = code_block_analyzer.analyze_migration(
            source_file=source_path,
            target_file=target_path,
            source_language=source_language,
            target_language=target_language,
            source_framework=source_framework,
            target_framework=target_framework
        )
        
        response_data = {
            "status": "success",
            "analysis": {
                "source_file": analysis.source_file,
                "target_file": analysis.target_file,
                "source_language": analysis.source_language,
                "target_language": analysis.target_language,
                "source_framework": analysis.source_framework,
                "target_framework": analysis.target_framework,
                "total_blocks": len(analysis.blocks),
                "statistics": analysis.statistics,
                "quality_metrics": analysis.quality_metrics,
                "recommendations": analysis.recommendations,
                "blocks": [
                    {
                        "id": block.id,
                        "type": block.type,
                        "source_code": block.source_code,
                        "target_code": block.target_code,
                        "mappings": block.mappings,
                        "conversion_notes": block.conversion_notes,
                        "quality_score": block.quality_score
                    }
                    for block in analysis.blocks
                ]
            }
        }
        
        # Generate Markdown report if requested
        # å¦‚æœéœ€è¦ï¼Œç”ŸæˆMarkdownæŠ¥å‘Š
        if generate_report:
            report_md = code_block_analyzer.generate_markdown_report(analysis)
            report_file_path = target_path.parent / f"{target_path.stem}_analysis.md"
            
            with open(report_file_path, 'w', encoding='utf-8') as f:
                f.write(report_md)
            
            response_data["report_file"] = str(report_file_path)
        
        return JSONResponse(content=response_data)
        
    except Exception as e:
        raise HTTPException(status_code=500, detail=str(e))


@app.post("/api/v1/convert-with-analysis")
async def convert_with_full_analysis(
    request: ConversionRequest,
    background_tasks: BackgroundTasks,
    generate_tests: bool = True,
    generate_analysis: bool = True
):
    """
    Convert code with full analysis (tests + code block analysis)
    è¿›è¡Œå®Œæ•´åˆ†æçš„ä»£ç è½¬æ¢ï¼ˆæµ‹è¯• + ä»£ç å—åˆ†æï¼‰
    
    This endpoint performs code conversion and automatically generates:
    è¿™ä¸ªç«¯ç‚¹æ‰§è¡Œä»£ç è½¬æ¢å¹¶è‡ªåŠ¨ç”Ÿæˆ:
    - Unit tests for converted code / è½¬æ¢åä»£ç çš„å•å…ƒæµ‹è¯•
    - Detailed code block analysis / è¯¦ç»†çš„ä»£ç å—åˆ†æ
    - Quality metrics and recommendations / è´¨é‡æŒ‡æ ‡å’Œå»ºè®®
    
    Args:
        request: Conversion request with all parameters / åŒ…å«æ‰€æœ‰å‚æ•°çš„è½¬æ¢è¯·æ±‚
        background_tasks: FastAPI background tasks / FastAPIåå°ä»»åŠ¡
        generate_tests: Whether to generate tests / æ˜¯å¦ç”Ÿæˆæµ‹è¯•
        generate_analysis: Whether to generate block analysis / æ˜¯å¦ç”Ÿæˆå—çº§åˆ†æ
    
    Returns:
        dict: Task ID and status / ä»»åŠ¡IDå’ŒçŠ¶æ€
    """
    # Create conversion task (same as /api/v1/convert)
    # åˆ›å»ºè½¬æ¢ä»»åŠ¡ï¼ˆä¸ /api/v1/convert ç›¸åŒï¼‰
    task_id = task_manager.create_task()
    
    async def conversion_with_analysis_task():
        try:
            # Perform regular conversion first
            # å…ˆæ‰§è¡Œå¸¸è§„è½¬æ¢
            # ... (conversion logic same as /api/v1/convert)
            
            # After conversion, generate tests and analysis
            # è½¬æ¢åï¼Œç”Ÿæˆæµ‹è¯•å’Œåˆ†æ
            output_dir = OUTPUT_DIR / task_id
            
            if generate_tests:
                task_manager.update_task(
                    task_id,
                    stage="ç”Ÿæˆå•å…ƒæµ‹è¯•...",
                    progress=85
                )
                
                # Generate tests for all converted files
                # ä¸ºæ‰€æœ‰è½¬æ¢åçš„æ–‡ä»¶ç”Ÿæˆæµ‹è¯•
                for file_path in output_dir.rglob(f"*.{_get_file_extension(request.target_language)}"):
                    try:
                        test_result = test_generator.generate_tests(
                            source_file=file_path,
                            target_language=request.target_language,
                            framework=request.target_framework
                        )
                        
                        if test_result["status"] == "success":
                            # Save test file
                            # ä¿å­˜æµ‹è¯•æ–‡ä»¶
                            test_file_path = file_path.parent / "tests" / test_result["test_file_name"]
                            test_file_path.parent.mkdir(parents=True, exist_ok=True)
                            
                            with open(test_file_path, 'w', encoding='utf-8') as f:
                                f.write(test_result["test_code"])
                    
                    except Exception as e:
                        logger.warning(f"æµ‹è¯•ç”Ÿæˆå¤±è´¥ {file_path}: {e}")
            
            if generate_analysis:
                task_manager.update_task(
                    task_id,
                    stage="ç”Ÿæˆä»£ç å—åˆ†ææŠ¥å‘Š...",
                    progress=95
                )
                
                # TODO: Implement full analysis generation for all files
                # å¾…å®ç°ï¼šä¸ºæ‰€æœ‰æ–‡ä»¶ç”Ÿæˆå®Œæ•´åˆ†æ
            
            task_manager.update_task(
                task_id,
                status="completed",
                progress=100,
                stage="è½¬æ¢å®Œæˆï¼ˆåŒ…å«æµ‹è¯•å’Œåˆ†æï¼‰ï¼"
            )
        
        except Exception as e:
            task_manager.update_task(
                task_id,
                status="failed",
                error=str(e)
            )
    
    # Add to background tasks
    # æ·»åŠ åˆ°åå°ä»»åŠ¡
    background_tasks.add_task(conversion_with_analysis_task)
    
    return JSONResponse(content={
        "task_id": task_id,
        "status": "processing",
        "message": "ä»£ç è½¬æ¢ä»»åŠ¡å·²åˆ›å»ºï¼ˆåŒ…å«æµ‹è¯•å’Œåˆ†æï¼‰"
    })


def _get_file_extension(language: str) -> str:
    """Get file extension for a programming language"""
    extensions = {
        "python": "py",
        "java": "java",
        "javascript": "js",
        "typescript": "ts",
        "go": "go",
        "rust": "rs",
        "cpp": "cpp",
        "csharp": "cs"
    }
    return extensions.get(language, "txt")


@app.post("/api/v1/inspect-project")
async def inspect_project(
    git_url: Optional[str] = None,
    local_path: Optional[str] = None,
    generate_learning_doc: bool = True,
    output_format: str = "markdown"
):
    """
    Inspect project code and generate learning documentation
    æ£€æµ‹é¡¹ç›®ä»£ç å¹¶ç”Ÿæˆå­¦ä¹ æ–‡æ¡£
    
    This endpoint analyzes code complexity, detects patterns, and generates
    comprehensive learning documentation.
    æ­¤ç«¯ç‚¹åˆ†æä»£ç å¤æ‚åº¦ã€æ£€æµ‹æ¨¡å¼å¹¶ç”Ÿæˆå…¨é¢çš„å­¦ä¹ æ–‡æ¡£ã€‚
    
    Args:
        git_url: Git repository URL / Gitä»“åº“URL
        local_path: Local project path / æœ¬åœ°é¡¹ç›®è·¯å¾„
        generate_learning_doc: Generate learning documentation / ç”Ÿæˆå­¦ä¹ æ–‡æ¡£
        output_format: Output format (markdown, json) / è¾“å‡ºæ ¼å¼
    
    Returns:
        dict: Inspection results and learning documentation
              æ£€æµ‹ç»“æœå’Œå­¦ä¹ æ–‡æ¡£
    """
    try:
        # Determine project path
        # ç¡®å®šé¡¹ç›®è·¯å¾„
        if git_url:
            # Clone repository
            # å…‹éš†ä»“åº“
            task_id = task_manager.create_task()
            clone_dir = UPLOAD_DIR / task_id
            clone_dir.mkdir(parents=True, exist_ok=True)
            
            logger.info(f"å…‹éš†ä»“åº“: {git_url}")
            repo_path = git_manager.clone_repo(git_url, str(clone_dir))
            project_path = Path(repo_path)
        
        elif local_path:
            project_path = Path(local_path)
            if not project_path.exists():
                raise HTTPException(status_code=404, detail=f"Project path not found: {local_path}")
        
        else:
            raise HTTPException(status_code=400, detail="Either git_url or local_path must be provided")
        
        logger.info(f"å¼€å§‹æ£€æµ‹é¡¹ç›®: {project_path}")
        
        # Inspect project
        # æ£€æµ‹é¡¹ç›®
        inspection_results = code_inspector.inspect_project(project_path)
        
        response_data = {
            "status": "success",
            "project_path": str(project_path),
            "inspection_results": {
                "project_metrics": {
                    "project_name": inspection_results['project_metrics'].project_name,
                    "total_files": inspection_results['project_metrics'].total_files,
                    "total_lines": inspection_results['project_metrics'].total_lines,
                    "total_functions": inspection_results['project_metrics'].total_functions,
                    "total_classes": inspection_results['project_metrics'].total_classes,
                    "languages": inspection_results['project_metrics'].languages,
                    "avg_complexity": inspection_results['project_metrics'].avg_complexity,
                    "overall_difficulty": inspection_results['project_metrics'].overall_difficulty,
                },
                "architecture": inspection_results['architecture'],
                "tech_stack": inspection_results['tech_stack'],
                "summary": inspection_results['summary']
            }
        }
        
        # Generate learning documentation if requested
        # å¦‚æœéœ€è¦ï¼Œç”Ÿæˆå­¦ä¹ æ–‡æ¡£
        if generate_learning_doc:
            logger.info("ç”Ÿæˆå­¦ä¹ æ–‡æ¡£...")
            
            # Convert dataclasses to dicts for the generator
            # ä¸ºç”Ÿæˆå™¨è½¬æ¢æ•°æ®ç±»ä¸ºå­—å…¸
            results_for_doc = {
                "project_metrics": {
                    "project_name": inspection_results['project_metrics'].project_name,
                    "total_files": inspection_results['project_metrics'].total_files,
                    "total_lines": inspection_results['project_metrics'].total_lines,
                    "total_functions": inspection_results['project_metrics'].total_functions,
                    "total_classes": inspection_results['project_metrics'].total_classes,
                    "languages": inspection_results['project_metrics'].languages,
                    "avg_complexity": inspection_results['project_metrics'].avg_complexity,
                    "overall_difficulty": inspection_results['project_metrics'].overall_difficulty,
                },
                "file_metrics": [
                    {
                        "file_path": f.file_path,
                        "language": f.language,
                        "lines_of_code": f.lines_of_code,
                        "num_functions": f.num_functions,
                        "num_classes": f.num_classes,
                        "num_imports": f.num_imports,
                        "complexity_score": f.complexity_score,
                        "maintainability_index": f.maintainability_index,
                        "code_smells": f.code_smells,
                        "security_issues": f.security_issues
                    }
                    for f in inspection_results['file_metrics']
                ],
                "architecture": inspection_results['architecture'],
                "tech_stack": inspection_results['tech_stack'],
                "summary": inspection_results['summary']
            }
            
            learning_doc = learning_doc_generator.generate_learning_doc(
                results_for_doc,
                project_path,
                output_format=output_format
            )
            
            # Save learning documentation
            # ä¿å­˜å­¦ä¹ æ–‡æ¡£
            if output_format == "markdown":
                doc_filename = f"{inspection_results['project_metrics'].project_name}_å­¦ä¹ æ–‡æ¡£.md"
            else:
                doc_filename = f"{inspection_results['project_metrics'].project_name}_å­¦ä¹ æ–‡æ¡£.json"
            
            doc_path = project_path / doc_filename
            
            with open(doc_path, 'w', encoding='utf-8') as f:
                f.write(learning_doc)
            
            response_data["learning_doc"] = {
                "content": learning_doc if output_format == "json" else learning_doc[:1000] + "..." if len(learning_doc) > 1000 else learning_doc,
                "file_path": str(doc_path),
                "format": output_format
            }
            
            logger.info(f"å­¦ä¹ æ–‡æ¡£å·²ä¿å­˜: {doc_path}")
        
        return JSONResponse(content=response_data)
    
    except Exception as e:
        logger.error(f"é¡¹ç›®æ£€æµ‹å¤±è´¥: {e}")
        raise HTTPException(status_code=500, detail=str(e))


@app.get("/api/v1/inspect-project/{task_id}/download")
async def download_learning_doc(task_id: str):
    """
    Download generated learning documentation
    ä¸‹è½½ç”Ÿæˆçš„å­¦ä¹ æ–‡æ¡£
    
    Args:
        task_id: Task ID / ä»»åŠ¡ID
    
    Returns:
        FileResponse: Learning documentation file
                     å­¦ä¹ æ–‡æ¡£æ–‡ä»¶
    """
    try:
        # Find the learning doc file
        # æŸ¥æ‰¾å­¦ä¹ æ–‡æ¡£æ–‡ä»¶
        project_dir = UPLOAD_DIR / task_id
        
        if not project_dir.exists():
            raise HTTPException(status_code=404, detail="Project not found")
        
        # Look for learning doc files
        # æŸ¥æ‰¾å­¦ä¹ æ–‡æ¡£æ–‡ä»¶
        doc_files = list(project_dir.glob("*å­¦ä¹ æ–‡æ¡£.*"))
        
        if not doc_files:
            raise HTTPException(status_code=404, detail="Learning documentation not found")
        
        doc_file = doc_files[0]
        
        return FileResponse(
            path=doc_file,
            filename=doc_file.name,
            media_type='application/octet-stream'
        )
    
    except Exception as e:
        logger.error(f"ä¸‹è½½å­¦ä¹ æ–‡æ¡£å¤±è´¥: {e}")
        raise HTTPException(status_code=500, detail=str(e))


@app.post("/api/v1/inspect-and-convert")
async def inspect_and_convert(
    request: ConversionRequest,
    background_tasks: BackgroundTasks,
    generate_learning_doc: bool = True
):
    """
    Inspect project and then convert it (combined workflow)
    æ£€æµ‹é¡¹ç›®ç„¶åè¿›è¡Œè½¬æ¢ï¼ˆç»„åˆå·¥ä½œæµï¼‰
    
    This endpoint first inspects the project to generate learning documentation,
    then performs the code conversion.
    æ­¤ç«¯ç‚¹é¦–å…ˆæ£€æµ‹é¡¹ç›®ä»¥ç”Ÿæˆå­¦ä¹ æ–‡æ¡£ï¼Œç„¶åæ‰§è¡Œä»£ç è½¬æ¢ã€‚
    
    Args:
        request: Conversion request / è½¬æ¢è¯·æ±‚
        background_tasks: Background tasks / åå°ä»»åŠ¡
        generate_learning_doc: Generate learning documentation / ç”Ÿæˆå­¦ä¹ æ–‡æ¡£
    
    Returns:
        dict: Task ID and status / ä»»åŠ¡IDå’ŒçŠ¶æ€
    """
    task_id = task_manager.create_task()
    
    async def inspect_and_convert_task():
        try:
            # Step 1: Inspect project
            # æ­¥éª¤1: æ£€æµ‹é¡¹ç›®
            if generate_learning_doc:
                task_manager.update_task(
                    task_id,
                    stage="æ£€æµ‹é¡¹ç›®å¹¶ç”Ÿæˆå­¦ä¹ æ–‡æ¡£...",
                    progress=10
                )
                
                # Clone or get project path
                # å…‹éš†æˆ–è·å–é¡¹ç›®è·¯å¾„
                if request.source_type == "git":
                    clone_dir = UPLOAD_DIR / task_id
                    clone_dir.mkdir(parents=True, exist_ok=True)
                    repo_path = git_manager.clone_repo(request.git_url, str(clone_dir))
                    project_path = Path(repo_path)
                else:
                    # Handle uploaded file
                    project_path = UPLOAD_DIR / task_id
                
                # Inspect project
                # æ£€æµ‹é¡¹ç›®
                inspection_results = code_inspector.inspect_project(project_path)
                
                # Generate learning doc
                # ç”Ÿæˆå­¦ä¹ æ–‡æ¡£
                results_for_doc = {
                    "project_metrics": {
                        "project_name": inspection_results['project_metrics'].project_name,
                        "total_files": inspection_results['project_metrics'].total_files,
                        "total_lines": inspection_results['project_metrics'].total_lines,
                        "total_functions": inspection_results['project_metrics'].total_functions,
                        "total_classes": inspection_results['project_metrics'].total_classes,
                        "languages": inspection_results['project_metrics'].languages,
                        "avg_complexity": inspection_results['project_metrics'].avg_complexity,
                        "overall_difficulty": inspection_results['project_metrics'].overall_difficulty,
                    },
                    "file_metrics": [
                        {
                            "file_path": f.file_path,
                            "language": f.language,
                            "lines_of_code": f.lines_of_code,
                            "num_functions": f.num_functions,
                            "num_classes": f.num_classes,
                            "num_imports": f.num_imports,
                            "complexity_score": f.complexity_score,
                            "maintainability_index": f.maintainability_index,
                            "code_smells": f.code_smells,
                            "security_issues": f.security_issues
                        }
                        for f in inspection_results['file_metrics']
                    ],
                    "architecture": inspection_results['architecture'],
                    "tech_stack": inspection_results['tech_stack'],
                    "summary": inspection_results['summary']
                }
                
                learning_doc = learning_doc_generator.generate_learning_doc(
                    results_for_doc,
                    project_path,
                    output_format="markdown"
                )
                
                doc_path = project_path / f"{inspection_results['project_metrics'].project_name}_å­¦ä¹ æ–‡æ¡£.md"
                with open(doc_path, 'w', encoding='utf-8') as f:
                    f.write(learning_doc)
            
            # Step 2: Perform conversion (same as regular conversion)
            # æ­¥éª¤2: æ‰§è¡Œè½¬æ¢ï¼ˆä¸å¸¸è§„è½¬æ¢ç›¸åŒï¼‰
            task_manager.update_task(
                task_id,
                stage="å¼€å§‹ä»£ç è½¬æ¢...",
                progress=30
            )
            
            # ... (conversion logic here - would call existing conversion workflow)
            # ... (è½¬æ¢é€»è¾‘ - è°ƒç”¨ç°æœ‰çš„è½¬æ¢å·¥ä½œæµç¨‹)
            
            task_manager.update_task(
                task_id,
                status="completed",
                progress=100,
                stage="æ£€æµ‹å’Œè½¬æ¢å®Œæˆï¼"
            )
        
        except Exception as e:
            task_manager.update_task(
                task_id,
                status="failed",
                error=str(e)
            )
    
    background_tasks.add_task(inspect_and_convert_task)
    
    return JSONResponse(content={
        "task_id": task_id,
        "status": "processing",
        "message": "é¡¹ç›®æ£€æµ‹å’Œè½¬æ¢ä»»åŠ¡å·²åˆ›å»º"
    })


@app.post("/api/v1/optimize-code")
async def optimize_code(
    file_path: Optional[str] = None,
    git_url: Optional[str] = None,
    target_file: Optional[str] = None,
    use_multi_ai: bool = True,
    ai_models: Optional[List[str]] = None,
    consensus_threshold: int = 2,
    output_format: str = "markdown"
):
    """
    Multi-AI code optimization analysis
    å¤šAIä»£ç ä¼˜åŒ–åˆ†æ
    
    This endpoint uses multiple AI models to analyze code and provide
    comprehensive optimization suggestions.
    æ­¤ç«¯ç‚¹ä½¿ç”¨å¤šä¸ªAIæ¨¡å‹åˆ†æä»£ç å¹¶æä¾›å…¨é¢çš„ä¼˜åŒ–å»ºè®®ã€‚
    
    Args:
        file_path: Path to local file / æœ¬åœ°æ–‡ä»¶è·¯å¾„
        git_url: Git repository URL / Gitä»“åº“URL
        target_file: Specific file in repo to analyze / ä»“åº“ä¸­è¦åˆ†æçš„ç‰¹å®šæ–‡ä»¶
        use_multi_ai: Use multiple AI models / ä½¿ç”¨å¤šä¸ªAIæ¨¡å‹
        ai_models: List of AI models to use / è¦ä½¿ç”¨çš„AIæ¨¡å‹åˆ—è¡¨
        consensus_threshold: Minimum AIs for consensus / å…±è¯†æ‰€éœ€çš„æœ€å°‘AIæ•°é‡
        output_format: Output format (markdown/json) / è¾“å‡ºæ ¼å¼
    
    Returns:
        dict: Optimization report / ä¼˜åŒ–æŠ¥å‘Š
    """
    try:
        logger.info("å¼€å§‹å¤šAIä»£ç ä¼˜åŒ–åˆ†æ")
        
        # Determine file to analyze
        # ç¡®å®šè¦åˆ†æçš„æ–‡ä»¶
        if file_path:
            target_path = Path(file_path)
            if not target_path.exists():
                raise HTTPException(status_code=404, detail=f"File not found: {file_path}")
        
        elif git_url:
            # Clone repository
            # å…‹éš†ä»“åº“
            task_id = task_manager.create_task()
            clone_dir = UPLOAD_DIR / task_id
            clone_dir.mkdir(parents=True, exist_ok=True)
            
            repo_path = git_manager.clone_repo(git_url, str(clone_dir))
            
            if target_file:
                target_path = Path(repo_path) / target_file
                if not target_path.exists():
                    raise HTTPException(status_code=404, detail=f"File not found in repo: {target_file}")
            else:
                # Find main file
                # æŸ¥æ‰¾ä¸»æ–‡ä»¶
                target_path = None
                for ext in ['.py', '.java', '.js', '.go']:
                    candidates = list(Path(repo_path).rglob(f'*{ext}'))
                    if candidates:
                        target_path = candidates[0]
                        break
                
                if not target_path:
                    raise HTTPException(status_code=404, detail="No code file found in repository")
        
        else:
            raise HTTPException(status_code=400, detail="Either file_path or git_url must be provided")
        
        # Detect language
        # æ£€æµ‹è¯­è¨€
        language = _detect_language_from_extension(target_path)
        
        # Initialize optimizer with specified AI models
        # ä½¿ç”¨æŒ‡å®šçš„AIæ¨¡å‹åˆå§‹åŒ–ä¼˜åŒ–å™¨
        if ai_models:
            optimizer = CodeOptimizer(ai_models=ai_models)
        else:
            optimizer = code_optimizer
        
        # Perform optimization analysis
        # æ‰§è¡Œä¼˜åŒ–åˆ†æ
        logger.info(f"ä½¿ç”¨ {len(optimizer.ai_models)} ä¸ªAIæ¨¡å‹åˆ†æ: {target_path}")
        
        optimization_report = await optimizer.analyze_and_optimize(
            target_path,
            language,
            use_multi_ai=use_multi_ai,
            consensus_threshold=consensus_threshold
        )
        
        # Generate report
        # ç”ŸæˆæŠ¥å‘Š
        report_content = optimization_report_generator.generate_report(
            optimization_report,
            output_format=output_format
        )
        
        # Save report
        # ä¿å­˜æŠ¥å‘Š
        report_filename = f"{target_path.stem}_optimization_report.{output_format}"
        report_path = target_path.parent / report_filename
        
        with open(report_path, 'w', encoding='utf-8') as f:
            f.write(report_content)
        
        logger.info(f"ä¼˜åŒ–æŠ¥å‘Šå·²ä¿å­˜: {report_path}")
        
        # Prepare response
        # å‡†å¤‡å“åº”
        response_data = {
            "status": "success",
            "file_analyzed": str(target_path),
            "language": language,
            "ai_models_used": optimizer.ai_models,
            "summary": {
                "total_suggestions": optimization_report.total_suggestions,
                "consensus_suggestions": len(optimization_report.consensus_suggestions),
                "unique_suggestions": len(optimization_report.unique_suggestions),
                "estimated_effort": optimization_report.estimated_effort,
                "expected_impact": optimization_report.expected_impact
            },
            "suggestions_by_category": optimization_report.suggestions_by_category,
            "suggestions_by_priority": optimization_report.suggestions_by_priority,
            "implementation_roadmap": optimization_report.implementation_roadmap,
            "report_file": str(report_path),
            "report_format": output_format
        }
        
        # Include report preview for markdown
        # ä¸ºmarkdownæ ¼å¼åŒ…å«æŠ¥å‘Šé¢„è§ˆ
        if output_format == "markdown":
            response_data["report_preview"] = report_content[:1500] + "..." if len(report_content) > 1500 else report_content
        else:
            response_data["report_content"] = report_content
        
        return JSONResponse(content=response_data)
    
    except Exception as e:
        logger.error(f"ä»£ç ä¼˜åŒ–åˆ†æå¤±è´¥: {e}")
        raise HTTPException(status_code=500, detail=str(e))


def _detect_language_from_extension(file_path: Path) -> str:
    """Detect language from file extension"""
    extension_map = {
        '.py': 'python',
        '.java': 'java',
        '.js': 'javascript',
        '.ts': 'typescript',
        '.go': 'go',
        '.rs': 'rust',
        '.cpp': 'cpp',
        '.c': 'c'
    }
    return extension_map.get(file_path.suffix, 'unknown')


# ============================================================================
# AI Model Management APIs / AIæ¨¡å‹ç®¡ç†æ¥å£
# ============================================================================

@app.get("/api/v1/ai-models")
async def list_ai_models(
    include_builtin: bool = True,
    include_custom: bool = True,
    enabled_only: bool = False
):
    """
    List all available AI models
    åˆ—å‡ºæ‰€æœ‰å¯ç”¨çš„AIæ¨¡å‹
    
    This endpoint returns all AI models, including both built-in and custom models.
    æ­¤ç«¯ç‚¹è¿”å›æ‰€æœ‰AIæ¨¡å‹ï¼ŒåŒ…æ‹¬å†…ç½®å’Œè‡ªå®šä¹‰æ¨¡å‹ã€‚
    
    Args:
        include_builtin: Include built-in models / åŒ…å«å†…ç½®æ¨¡å‹
        include_custom: Include custom models / åŒ…å«è‡ªå®šä¹‰æ¨¡å‹
        enabled_only: Only enabled models / åªè¿”å›å¯ç”¨çš„æ¨¡å‹
    
    Returns:
        dict: List of AI models / AIæ¨¡å‹åˆ—è¡¨
    """
    try:
        models = model_manager.list_models(
            include_builtin=include_builtin,
            include_custom=include_custom,
            enabled_only=enabled_only
        )
        
        # Convert to dict format / è½¬æ¢ä¸ºå­—å…¸æ ¼å¼
        models_data = []
        for model in models:
            model_dict = {
                "model_id": model.model_id,
                "model_name": model.model_name,
                "provider": model.provider,
                "model_type": model.model_type,
                "description": model.description,
                "tags": model.tags,
                "enabled": model.enabled,
                "is_builtin": model.model_id in model_manager.builtin_models,
                "created_at": model.created_at,
                "updated_at": model.updated_at
            }
            models_data.append(model_dict)
        
        return JSONResponse(content={
            "status": "success",
            "total": len(models_data),
            "models": models_data
        })
    
    except Exception as e:
        logger.error(f"åˆ—å‡ºAIæ¨¡å‹å¤±è´¥: {e}")
        raise HTTPException(status_code=500, detail=str(e))


@app.get("/api/v1/ai-models/{model_id}")
async def get_ai_model(model_id: str):
    """
    Get detailed information about a specific AI model
    è·å–ç‰¹å®šAIæ¨¡å‹çš„è¯¦ç»†ä¿¡æ¯
    
    Args:
        model_id: Model ID / æ¨¡å‹ID
    
    Returns:
        dict: Model configuration / æ¨¡å‹é…ç½®
    """
    try:
        model = model_manager.get_model(model_id)
        
        if not model:
            raise HTTPException(status_code=404, detail=f"Model not found: {model_id}")
        
        return JSONResponse(content={
            "status": "success",
            "model": {
                "model_id": model.model_id,
                "model_name": model.model_name,
                "provider": model.provider,
                "api_base_url": model.api_base_url,
                "api_key_env_var": model.api_key_env_var,
                "model_type": model.model_type,
                "max_tokens": model.max_tokens,
                "temperature": model.temperature,
                "top_p": model.top_p,
                "custom_headers": model.custom_headers,
                "request_format": model.request_format,
                "description": model.description,
                "tags": model.tags,
                "enabled": model.enabled,
                "is_builtin": model.model_id in model_manager.builtin_models,
                "created_at": model.created_at,
                "updated_at": model.updated_at
            }
        })
    
    except HTTPException:
        raise
    except Exception as e:
        logger.error(f"è·å–AIæ¨¡å‹å¤±è´¥: {e}")
        raise HTTPException(status_code=500, detail=str(e))


@app.post("/api/v1/ai-models")
async def add_ai_model(
    model_id: str,
    model_name: str,
    provider: str,
    api_base_url: str,
    api_key_env_var: str,
    model_type: str = "chat",
    max_tokens: int = 4096,
    temperature: float = 0.3,
    top_p: float = 1.0,
    custom_headers: Optional[Dict[str, str]] = None,
    request_format: str = "openai",
    request_template: Optional[Dict[str, Any]] = None,
    response_path: Optional[str] = None,
    description: str = "",
    tags: Optional[List[str]] = None,
    enabled: bool = True
):
    """
    Add a new custom AI model
    æ·»åŠ æ–°çš„è‡ªå®šä¹‰AIæ¨¡å‹
    
    This endpoint allows users to add their own AI models.
    æ­¤ç«¯ç‚¹å…è®¸ç”¨æˆ·æ·»åŠ è‡ªå·±çš„AIæ¨¡å‹ã€‚
    
    Args:
        model_id: Unique model ID / å”¯ä¸€æ¨¡å‹ID
        model_name: Display name / æ˜¾ç¤ºåç§°
        provider: Provider name / æä¾›å•†åç§°
        api_base_url: API base URL / APIåŸºç¡€URL
        api_key_env_var: Environment variable for API key / APIå¯†é’¥ç¯å¢ƒå˜é‡
        model_type: Model type (chat/completion/custom) / æ¨¡å‹ç±»å‹
        max_tokens: Maximum tokens / æœ€å¤§tokenæ•°
        temperature: Temperature / æ¸©åº¦
        top_p: Top P / Top P
        custom_headers: Custom HTTP headers / è‡ªå®šä¹‰HTTPå¤´
        request_format: Request format (openai/anthropic/google/custom) / è¯·æ±‚æ ¼å¼
        request_template: Custom request template / è‡ªå®šä¹‰è¯·æ±‚æ¨¡æ¿
        response_path: JSONPath to extract response / å“åº”æå–è·¯å¾„
        description: Model description / æ¨¡å‹æè¿°
        tags: Tags / æ ‡ç­¾
        enabled: Whether enabled / æ˜¯å¦å¯ç”¨
    
    Returns:
        dict: Success message / æˆåŠŸæ¶ˆæ¯
    """
    try:
        # Create model config / åˆ›å»ºæ¨¡å‹é…ç½®
        config = AIModelConfig(
            model_id=model_id,
            model_name=model_name,
            provider=provider,
            api_base_url=api_base_url,
            api_key_env_var=api_key_env_var,
            model_type=model_type,
            max_tokens=max_tokens,
            temperature=temperature,
            top_p=top_p,
            custom_headers=custom_headers or {},
            request_format=request_format,
            request_template=request_template,
            response_path=response_path,
            description=description,
            tags=tags or [],
            enabled=enabled
        )
        
        # Add model / æ·»åŠ æ¨¡å‹
        success = model_manager.add_model(config)
        
        if not success:
            raise HTTPException(status_code=500, detail="Failed to add model")
        
        return JSONResponse(content={
            "status": "success",
            "message": f"AIæ¨¡å‹å·²æ·»åŠ : {model_name}",
            "model_id": model_id
        })
    
    except ValueError as e:
        raise HTTPException(status_code=400, detail=str(e))
    except Exception as e:
        logger.error(f"æ·»åŠ AIæ¨¡å‹å¤±è´¥: {e}")
        raise HTTPException(status_code=500, detail=str(e))


@app.put("/api/v1/ai-models/{model_id}")
async def update_ai_model(
    model_id: str,
    model_name: Optional[str] = None,
    provider: Optional[str] = None,
    api_base_url: Optional[str] = None,
    api_key_env_var: Optional[str] = None,
    model_type: Optional[str] = None,
    max_tokens: Optional[int] = None,
    temperature: Optional[float] = None,
    top_p: Optional[float] = None,
    custom_headers: Optional[Dict[str, str]] = None,
    request_format: Optional[str] = None,
    description: Optional[str] = None,
    tags: Optional[List[str]] = None,
    enabled: Optional[bool] = None
):
    """
    Update a custom AI model
    æ›´æ–°è‡ªå®šä¹‰AIæ¨¡å‹
    
    Args:
        model_id: Model ID to update / è¦æ›´æ–°çš„æ¨¡å‹ID
        ...: Fields to update / è¦æ›´æ–°çš„å­—æ®µ
    
    Returns:
        dict: Success message / æˆåŠŸæ¶ˆæ¯
    """
    try:
        # Get existing model / è·å–ç°æœ‰æ¨¡å‹
        existing = model_manager.get_model(model_id)
        if not existing:
            raise HTTPException(status_code=404, detail=f"Model not found: {model_id}")
        
        if model_id in model_manager.builtin_models:
            raise HTTPException(status_code=400, detail="Cannot update built-in model")
        
        # Update fields / æ›´æ–°å­—æ®µ
        config = AIModelConfig(
            model_id=model_id,
            model_name=model_name or existing.model_name,
            provider=provider or existing.provider,
            api_base_url=api_base_url or existing.api_base_url,
            api_key_env_var=api_key_env_var or existing.api_key_env_var,
            model_type=model_type or existing.model_type,
            max_tokens=max_tokens if max_tokens is not None else existing.max_tokens,
            temperature=temperature if temperature is not None else existing.temperature,
            top_p=top_p if top_p is not None else existing.top_p,
            custom_headers=custom_headers if custom_headers is not None else existing.custom_headers,
            request_format=request_format or existing.request_format,
            request_template=existing.request_template,
            response_path=existing.response_path,
            description=description if description is not None else existing.description,
            tags=tags if tags is not None else existing.tags,
            enabled=enabled if enabled is not None else existing.enabled,
            created_at=existing.created_at
        )
        
        # Update model / æ›´æ–°æ¨¡å‹
        success = model_manager.update_model(model_id, config)
        
        if not success:
            raise HTTPException(status_code=500, detail="Failed to update model")
        
        return JSONResponse(content={
            "status": "success",
            "message": f"AIæ¨¡å‹å·²æ›´æ–°: {config.model_name}"
        })
    
    except HTTPException:
        raise
    except Exception as e:
        logger.error(f"æ›´æ–°AIæ¨¡å‹å¤±è´¥: {e}")
        raise HTTPException(status_code=500, detail=str(e))


@app.delete("/api/v1/ai-models/{model_id}")
async def delete_ai_model(model_id: str):
    """
    Delete a custom AI model
    åˆ é™¤è‡ªå®šä¹‰AIæ¨¡å‹
    
    Args:
        model_id: Model ID to delete / è¦åˆ é™¤çš„æ¨¡å‹ID
    
    Returns:
        dict: Success message / æˆåŠŸæ¶ˆæ¯
    """
    try:
        success = model_manager.remove_model(model_id)
        
        if not success:
            raise HTTPException(status_code=404, detail=f"Model not found or cannot be deleted: {model_id}")
        
        return JSONResponse(content={
            "status": "success",
            "message": f"AIæ¨¡å‹å·²åˆ é™¤: {model_id}"
        })
    
    except ValueError as e:
        raise HTTPException(status_code=400, detail=str(e))
    except Exception as e:
        logger.error(f"åˆ é™¤AIæ¨¡å‹å¤±è´¥: {e}")
        raise HTTPException(status_code=500, detail=str(e))


@app.post("/api/v1/ai-models/{model_id}/test")
async def test_ai_model(model_id: str, test_prompt: str = "Hello, how are you?"):
    """
    Test AI model connectivity and response
    æµ‹è¯•AIæ¨¡å‹è¿æ¥å’Œå“åº”
    
    This endpoint tests if the AI model is properly configured and working.
    æ­¤ç«¯ç‚¹æµ‹è¯•AIæ¨¡å‹æ˜¯å¦æ­£ç¡®é…ç½®å¹¶èƒ½æ­£å¸¸å·¥ä½œã€‚
    
    Args:
        model_id: Model ID to test / è¦æµ‹è¯•çš„æ¨¡å‹ID
        test_prompt: Test prompt / æµ‹è¯•æç¤ºè¯
    
    Returns:
        dict: Test result / æµ‹è¯•ç»“æœ
    """
    try:
        result = model_manager.test_model(model_id, test_prompt)
        
        return JSONResponse(content={
            "status": "success" if result["success"] else "failed",
            "test_result": result
        })
    
    except Exception as e:
        logger.error(f"æµ‹è¯•AIæ¨¡å‹å¤±è´¥: {e}")
        raise HTTPException(status_code=500, detail=str(e))


@app.post("/api/v1/ai-models/{model_id}/export")
async def export_ai_model(model_id: str):
    """
    Export AI model configuration for sharing
    å¯¼å‡ºAIæ¨¡å‹é…ç½®ç”¨äºåˆ†äº«
    
    Args:
        model_id: Model ID to export / è¦å¯¼å‡ºçš„æ¨¡å‹ID
    
    Returns:
        dict: Model configuration / æ¨¡å‹é…ç½®
    """
    try:
        config = model_manager.export_model(model_id)
        
        if not config:
            raise HTTPException(status_code=404, detail=f"Model not found: {model_id}")
        
        # Remove sensitive info / åˆ é™¤æ•æ„Ÿä¿¡æ¯
        config["api_key_env_var"] = "YOUR_API_KEY_ENV_VAR"
        
        return JSONResponse(content={
            "status": "success",
            "config": config,
            "instructions": "æ›¿æ¢ api_key_env_var ä¸ºæ‚¨è‡ªå·±çš„ç¯å¢ƒå˜é‡åï¼Œå¹¶è®¾ç½®ç›¸åº”çš„APIå¯†é’¥"
        })
    
    except HTTPException:
        raise
    except Exception as e:
        logger.error(f"å¯¼å‡ºAIæ¨¡å‹å¤±è´¥: {e}")
        raise HTTPException(status_code=500, detail=str(e))


@app.post("/api/v1/ai-models/import")
async def import_ai_model(config: Dict[str, Any]):
    """
    Import AI model configuration
    å¯¼å…¥AIæ¨¡å‹é…ç½®
    
    Args:
        config: Model configuration / æ¨¡å‹é…ç½®
    
    Returns:
        dict: Success message / æˆåŠŸæ¶ˆæ¯
    """
    try:
        success = model_manager.import_model(config)
        
        if not success:
            raise HTTPException(status_code=500, detail="Failed to import model")
        
        return JSONResponse(content={
            "status": "success",
            "message": f"AIæ¨¡å‹å·²å¯¼å…¥: {config.get('model_name', 'Unknown')}"
        })
    
    except Exception as e:
        logger.error(f"å¯¼å…¥AIæ¨¡å‹å¤±è´¥: {e}")
        raise HTTPException(status_code=500, detail=str(e))


if __name__ == "__main__":
    uvicorn.run(
        "main:app",
        host=os.getenv("HOST", "0.0.0.0"),
        port=int(os.getenv("PORT", 8000)),
        reload=os.getenv("DEBUG", "false").lower() == "true"
    )

